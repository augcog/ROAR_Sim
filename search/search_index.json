{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Documentation for ROAR-Simulator \u00a4 Quick Links \u00a4 If you are new to the project visit Quick Start If you are curious about ROAR Competition at Berkeley visit Berkeley ROAR If you are curious about Carla visit Carla Simulator For more information regarding DeCal Course visit Roar Decal . Quick Start \u00a4 Platforms Tested: Ubuntu 18.04, Windows 10 Approximate Time: ~10 minutes Windows \u00a4 Clone the repo git clone --recursive https://github.com/augcog/ROAR-Sim.git Download Carla Server package https://drive.google.com/drive/folders/1FlkNCNENaC3qrTub7mqra7EH7iSbRNiI put it OUTSIDE of the ROAR-Sim folder, doesn't matter where Check your file directory, it should be: ROAR-Sim data easy_map_waypoints.txt ROAR_simulation runner.py ... other files and folders Create virtual environment and install dependencies conda create -n ROAR python=3.7 conda activate ROAR pip install -r requirements.txt Enjoy Double click the CarlaUE4.exe file in the Carla Server package to launch the server python runner.py Linux \u00a4 Same as Windows, in step 6, just type in ./CarlaUE4.sh to start the server Contribute To ROAR Guide \u00a4 Communication \u00a4 Before starting a new contribution, it is important to let the community know what you plan on doing. This serves several purposes. It lets everyone know that you are going to start work on a feature or bug fix so that no one else does the same and duplicates your effort. It lets anyone who may already be working on the feature or bug fix know you intend to work on it, so they can tell you and you don't duplicate their effort. It gives others a chance to provide more information about what the feature or bug fix might need or how it may need to be implemented. You can let the community know by first opening an Issue on Github. An admin will tag a related Pull Request if this is a duplicated issue Documentation Style \u00a4 We use mkdocs and mkdocstrings to automatically generate documentation. This means that we require all Python code documentation to be written in Google Style The recommended method for enabling automatic Google Docstring framework generation is through PyCharm. Here's a tutorial on how to enable this feature in PyCharm Pull Request Style \u00a4 We ask that you fill out the pull request template as indicated in Github, to provide as much details as possible. Issue Style \u00a4 We ask that you fill out the correct issue template as indicated on Github. FAQ \u00a4 If you see an error such as WARNING: sensor object went out of the scope but the sensor is still alive in the simulation: Actor 69 (sensor.other.collision) Please restart the server If you see ERROR: Something bad happened. Safely exiting. Error:time-out of 2000ms while waiting for the simulator, make sure the simulator is ready and connected to 127.0.0.1:2000 Make sure your server has launched If you see error such as ERROR: name 'agent' is not defined. Need to restart Server or ERROR: Cannot spawn actor at ID [1]. Error: Spawn failed because of collision at spawn position. Need to restart Server Just restart the server My computer is getting very hot Yeah, this is normal. If it gets too hot, just turn off the server and let it cool down for a minute. Our suggestion is that when you are writing code, just turn the server off The simulation is very laggy One method to mitigate this is to start the simulator with the -quality-level=Low flag For example: ./CarlaUE4.sh -quality-level=Low on linux ./CarlaUE4.exe -quality-level=Low on windows Another method is to turn off the display (this will just make it SLIGHTLY faster), but this is only available on Linux DISPLAY= ./CarlaUE4.sh -opengl Last method is to understand and tryout Carla's Synchronized Mode You may modify the default values at ROAR_simulation/carla_client/carla_settings.py fixed_delta_seconds no_rendering_mode synchronoous_mode","title":"Home"},{"location":"#documentation-for-roar-simulator","text":"","title":"Documentation for ROAR-Simulator"},{"location":"#quick-links","text":"If you are new to the project visit Quick Start If you are curious about ROAR Competition at Berkeley visit Berkeley ROAR If you are curious about Carla visit Carla Simulator For more information regarding DeCal Course visit Roar Decal .","title":"Quick Links"},{"location":"#quick-start","text":"Platforms Tested: Ubuntu 18.04, Windows 10 Approximate Time: ~10 minutes","title":"Quick Start"},{"location":"#windows","text":"Clone the repo git clone --recursive https://github.com/augcog/ROAR-Sim.git Download Carla Server package https://drive.google.com/drive/folders/1FlkNCNENaC3qrTub7mqra7EH7iSbRNiI put it OUTSIDE of the ROAR-Sim folder, doesn't matter where Check your file directory, it should be: ROAR-Sim data easy_map_waypoints.txt ROAR_simulation runner.py ... other files and folders Create virtual environment and install dependencies conda create -n ROAR python=3.7 conda activate ROAR pip install -r requirements.txt Enjoy Double click the CarlaUE4.exe file in the Carla Server package to launch the server python runner.py","title":"Windows"},{"location":"#linux","text":"Same as Windows, in step 6, just type in ./CarlaUE4.sh to start the server","title":"Linux"},{"location":"#contribute-to-roar-guide","text":"","title":"Contribute To ROAR Guide"},{"location":"#communication","text":"Before starting a new contribution, it is important to let the community know what you plan on doing. This serves several purposes. It lets everyone know that you are going to start work on a feature or bug fix so that no one else does the same and duplicates your effort. It lets anyone who may already be working on the feature or bug fix know you intend to work on it, so they can tell you and you don't duplicate their effort. It gives others a chance to provide more information about what the feature or bug fix might need or how it may need to be implemented. You can let the community know by first opening an Issue on Github. An admin will tag a related Pull Request if this is a duplicated issue","title":"Communication"},{"location":"#documentation-style","text":"We use mkdocs and mkdocstrings to automatically generate documentation. This means that we require all Python code documentation to be written in Google Style The recommended method for enabling automatic Google Docstring framework generation is through PyCharm. Here's a tutorial on how to enable this feature in PyCharm","title":"Documentation Style"},{"location":"#pull-request-style","text":"We ask that you fill out the pull request template as indicated in Github, to provide as much details as possible.","title":"Pull Request Style"},{"location":"#issue-style","text":"We ask that you fill out the correct issue template as indicated on Github.","title":"Issue Style"},{"location":"#faq","text":"If you see an error such as WARNING: sensor object went out of the scope but the sensor is still alive in the simulation: Actor 69 (sensor.other.collision) Please restart the server If you see ERROR: Something bad happened. Safely exiting. Error:time-out of 2000ms while waiting for the simulator, make sure the simulator is ready and connected to 127.0.0.1:2000 Make sure your server has launched If you see error such as ERROR: name 'agent' is not defined. Need to restart Server or ERROR: Cannot spawn actor at ID [1]. Error: Spawn failed because of collision at spawn position. Need to restart Server Just restart the server My computer is getting very hot Yeah, this is normal. If it gets too hot, just turn off the server and let it cool down for a minute. Our suggestion is that when you are writing code, just turn the server off The simulation is very laggy One method to mitigate this is to start the simulator with the -quality-level=Low flag For example: ./CarlaUE4.sh -quality-level=Low on linux ./CarlaUE4.exe -quality-level=Low on windows Another method is to turn off the display (this will just make it SLIGHTLY faster), but this is only available on Linux DISPLAY= ./CarlaUE4.sh -opengl Last method is to understand and tryout Carla's Synchronized Mode You may modify the default values at ROAR_simulation/carla_client/carla_settings.py fixed_delta_seconds no_rendering_mode synchronoous_mode","title":"FAQ"},{"location":"pull_request_template/","text":"Description \u00a4 Please include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change. Fixes # (issue) Type of change \u00a4 Please delete options that are not relevant. Bug fix (non-breaking change which fixes an issue) New feature (non-breaking change which adds functionality) Breaking change (fix or feature that would cause existing functionality to not work as expected) This change requires a documentation update How Has This Been Tested? \u00a4 Please describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration Test A Test B Test Configuration : * Firmware version: * Hardware: * Toolchain: * SDK: Checklist: \u00a4 My code follows the style guidelines of this project I have performed a self-review of my own code I have commented my code, particularly in hard-to-understand areas I have made corresponding changes to the documentation My changes generate no new warnings I have added tests that prove my fix is effective or that my feature works New and existing unit tests pass locally with my changes Any dependent changes have been merged and published in downstream modules","title":"Description"},{"location":"pull_request_template/#description","text":"Please include a summary of the change and which issue is fixed. Please also include relevant motivation and context. List any dependencies that are required for this change. Fixes # (issue)","title":"Description"},{"location":"pull_request_template/#type-of-change","text":"Please delete options that are not relevant. Bug fix (non-breaking change which fixes an issue) New feature (non-breaking change which adds functionality) Breaking change (fix or feature that would cause existing functionality to not work as expected) This change requires a documentation update","title":"Type of change"},{"location":"pull_request_template/#how-has-this-been-tested","text":"Please describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration Test A Test B Test Configuration : * Firmware version: * Hardware: * Toolchain: * SDK:","title":"How Has This Been Tested?"},{"location":"pull_request_template/#checklist","text":"My code follows the style guidelines of this project I have performed a self-review of my own code I have commented my code, particularly in hard-to-understand areas I have made corresponding changes to the documentation My changes generate no new warnings I have added tests that prove my fix is effective or that my feature works New and existing unit tests pass locally with my changes Any dependent changes have been merged and published in downstream modules","title":"Checklist:"},{"location":"code_documentations/bridges/","text":"This file defines a basic Bridge for extensibility of the ROAR Autonomous software Bridge \u00a4 __init__ ( self ) special \u00a4 Source code in ROAR/bridges/bridge.py 26 27 def __init__ ( self ): self . logger = logging . Logger ( __name__ ) convert_control_from_agent_to_source ( self , control ) \u00a4 Source code in ROAR/bridges/bridge.py 77 78 79 @abstractmethod def convert_control_from_agent_to_source ( self , control : VehicleControl ) -> Any : pass convert_control_from_source_to_agent ( self , source ) \u00a4 Source code in ROAR/bridges/bridge.py 45 46 47 @abstractmethod def convert_control_from_source_to_agent ( self , source ) -> VehicleControl : pass convert_depth_from_source_to_agent ( self , source ) \u00a4 Source code in ROAR/bridges/bridge.py 53 54 55 @abstractmethod def convert_depth_from_source_to_agent ( self , source ) -> DepthData : pass convert_imu_from_source_to_agent ( self , source ) \u00a4 Source code in ROAR/bridges/bridge.py 61 62 63 @abstractmethod def convert_imu_from_source_to_agent ( self , source ) -> IMUData : pass convert_location_from_source_to_agent ( self , source ) \u00a4 Source code in ROAR/bridges/bridge.py 33 34 35 @abstractmethod def convert_location_from_source_to_agent ( self , source ) -> Location : pass convert_rgb_from_source_to_agent ( self , source ) \u00a4 Source code in ROAR/bridges/bridge.py 49 50 51 @abstractmethod def convert_rgb_from_source_to_agent ( self , source ) -> RGBData : pass convert_rotation_from_source_to_agent ( self , source ) \u00a4 Source code in ROAR/bridges/bridge.py 37 38 39 @abstractmethod def convert_rotation_from_source_to_agent ( self , source ) -> Rotation : pass convert_sensor_data_from_source_to_agent ( self , source ) \u00a4 Source code in ROAR/bridges/bridge.py 65 66 67 @abstractmethod def convert_sensor_data_from_source_to_agent ( self , source ) -> SensorsData : pass convert_transform_from_source_to_agent ( self , source ) \u00a4 Source code in ROAR/bridges/bridge.py 41 42 43 @abstractmethod def convert_transform_from_source_to_agent ( self , source ) -> Transform : pass convert_vector3d_from_agent_to_source ( self , vector3d ) \u00a4 Source code in ROAR/bridges/bridge.py 81 82 83 @abstractmethod def convert_vector3d_from_agent_to_source ( self , vector3d : Vector3D ) -> Any : pass convert_vector3d_from_source_to_agent ( self , source ) \u00a4 Source code in ROAR/bridges/bridge.py 57 58 59 @abstractmethod def convert_vector3d_from_source_to_agent ( self , source ) -> Vector3D : pass convert_vehicle_from_source_to_agent ( self , source ) \u00a4 Source code in ROAR/bridges/bridge.py 69 70 71 @abstractmethod def convert_vehicle_from_source_to_agent ( self , source ) -> Vehicle : pass","title":"Bridges"},{"location":"code_documentations/bridges/#ROAR.bridges.bridge.Bridge","text":"","title":"Bridge"},{"location":"code_documentations/bridges/#ROAR.bridges.bridge.Bridge.__init__","text":"Source code in ROAR/bridges/bridge.py 26 27 def __init__ ( self ): self . logger = logging . Logger ( __name__ )","title":"__init__()"},{"location":"code_documentations/bridges/#ROAR.bridges.bridge.Bridge.convert_control_from_agent_to_source","text":"Source code in ROAR/bridges/bridge.py 77 78 79 @abstractmethod def convert_control_from_agent_to_source ( self , control : VehicleControl ) -> Any : pass","title":"convert_control_from_agent_to_source()"},{"location":"code_documentations/bridges/#ROAR.bridges.bridge.Bridge.convert_control_from_source_to_agent","text":"Source code in ROAR/bridges/bridge.py 45 46 47 @abstractmethod def convert_control_from_source_to_agent ( self , source ) -> VehicleControl : pass","title":"convert_control_from_source_to_agent()"},{"location":"code_documentations/bridges/#ROAR.bridges.bridge.Bridge.convert_depth_from_source_to_agent","text":"Source code in ROAR/bridges/bridge.py 53 54 55 @abstractmethod def convert_depth_from_source_to_agent ( self , source ) -> DepthData : pass","title":"convert_depth_from_source_to_agent()"},{"location":"code_documentations/bridges/#ROAR.bridges.bridge.Bridge.convert_imu_from_source_to_agent","text":"Source code in ROAR/bridges/bridge.py 61 62 63 @abstractmethod def convert_imu_from_source_to_agent ( self , source ) -> IMUData : pass","title":"convert_imu_from_source_to_agent()"},{"location":"code_documentations/bridges/#ROAR.bridges.bridge.Bridge.convert_location_from_source_to_agent","text":"Source code in ROAR/bridges/bridge.py 33 34 35 @abstractmethod def convert_location_from_source_to_agent ( self , source ) -> Location : pass","title":"convert_location_from_source_to_agent()"},{"location":"code_documentations/bridges/#ROAR.bridges.bridge.Bridge.convert_rgb_from_source_to_agent","text":"Source code in ROAR/bridges/bridge.py 49 50 51 @abstractmethod def convert_rgb_from_source_to_agent ( self , source ) -> RGBData : pass","title":"convert_rgb_from_source_to_agent()"},{"location":"code_documentations/bridges/#ROAR.bridges.bridge.Bridge.convert_rotation_from_source_to_agent","text":"Source code in ROAR/bridges/bridge.py 37 38 39 @abstractmethod def convert_rotation_from_source_to_agent ( self , source ) -> Rotation : pass","title":"convert_rotation_from_source_to_agent()"},{"location":"code_documentations/bridges/#ROAR.bridges.bridge.Bridge.convert_sensor_data_from_source_to_agent","text":"Source code in ROAR/bridges/bridge.py 65 66 67 @abstractmethod def convert_sensor_data_from_source_to_agent ( self , source ) -> SensorsData : pass","title":"convert_sensor_data_from_source_to_agent()"},{"location":"code_documentations/bridges/#ROAR.bridges.bridge.Bridge.convert_transform_from_source_to_agent","text":"Source code in ROAR/bridges/bridge.py 41 42 43 @abstractmethod def convert_transform_from_source_to_agent ( self , source ) -> Transform : pass","title":"convert_transform_from_source_to_agent()"},{"location":"code_documentations/bridges/#ROAR.bridges.bridge.Bridge.convert_vector3d_from_agent_to_source","text":"Source code in ROAR/bridges/bridge.py 81 82 83 @abstractmethod def convert_vector3d_from_agent_to_source ( self , vector3d : Vector3D ) -> Any : pass","title":"convert_vector3d_from_agent_to_source()"},{"location":"code_documentations/bridges/#ROAR.bridges.bridge.Bridge.convert_vector3d_from_source_to_agent","text":"Source code in ROAR/bridges/bridge.py 57 58 59 @abstractmethod def convert_vector3d_from_source_to_agent ( self , source ) -> Vector3D : pass","title":"convert_vector3d_from_source_to_agent()"},{"location":"code_documentations/bridges/#ROAR.bridges.bridge.Bridge.convert_vehicle_from_source_to_agent","text":"Source code in ROAR/bridges/bridge.py 69 70 71 @abstractmethod def convert_vehicle_from_source_to_agent ( self , source ) -> Vehicle : pass","title":"convert_vehicle_from_source_to_agent()"},{"location":"code_documentations/roar_autonomous_system/agents/","text":"Documentation for Agents \u00a4 Agent \u00a4 Abstract Agent class that define the minimum of a ROAR agent. Inherited agent can perform different duties. __init__ ( self , vehicle , agent_settings , imu = None ) special \u00a4 Initialize cameras, output folder, and logging utilities Parameters: Name Type Description Default vehicle Vehicle Vehicle instance required agent_settings AgentConfig User specified settings for Agent required imu Optional[ROAR.roar_autonomous_system.utilities_module.data_structures_models.IMUData] IMU data (will be deprecated to be passed in like this) None Source code in ROAR/roar_autonomous_system/agent_module/agent.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def __init__ ( self , vehicle : Vehicle , agent_settings : AgentConfig , imu : Optional [ IMUData ] = None ): \"\"\" Initialize cameras, output folder, and logging utilities Args: vehicle: Vehicle instance agent_settings: User specified settings for Agent imu: IMU data (will be deprecated to be passed in like this) \"\"\" self . logger = logging . getLogger ( __name__ ) self . vehicle = vehicle self . agent_settings = agent_settings self . front_rgb_camera = agent_settings . front_rgb_cam self . front_depth_camera = agent_settings . front_depth_cam self . rear_rgb_camera = agent_settings . rear_rgb_cam self . imu = imu self . output_folder_path = \\ Path ( self . agent_settings . output_data_folder_path ) self . front_depth_camera_output_folder_path = \\ self . output_folder_path / \"front_depth\" self . front_rgb_camera_output_folder_path = \\ self . output_folder_path / \"front_rgb\" self . rear_rgb_camera_output_folder_path = \\ self . output_folder_path / \"rear_rgb\" self . should_save_sensor_data = self . agent_settings . save_sensor_data self . local_planner : Optional [ LocalPlanner ] = None self . behavior_planner : Optional [ BehaviorPlanner ] = None self . mission_planner : Optional [ MissionPlanner ] = None self . time_counter = 0 self . transform_history : List [ Transform ] = [] self . init_cam () init_cam ( self ) \u00a4 Initialize the cameras by calculating the camera intrinsics and ensuring that the output folder path exists Returns: Type Description None None Source code in ROAR/roar_autonomous_system/agent_module/agent.py 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 def init_cam ( self ) -> None : \"\"\" Initialize the cameras by calculating the camera intrinsics and ensuring that the output folder path exists Returns: None \"\"\" if self . front_rgb_camera is not None : self . front_rgb_camera . intrinsics_matrix = ( self . front_rgb_camera . calculate_intrinsic_matrix () ) if self . front_depth_camera is not None : self . front_depth_camera . intrinsics_matrix = ( self . front_depth_camera . calculate_intrinsic_matrix () ) if self . rear_rgb_camera is not None : self . rear_rgb_camera . intrinsics_matrix = ( self . rear_rgb_camera . calculate_intrinsic_matrix () ) if self . should_save_sensor_data : self . front_depth_camera_output_folder_path . mkdir ( parents = True , exist_ok = True ) self . front_rgb_camera_output_folder_path . mkdir ( parents = True , exist_ok = True ) self . rear_rgb_camera_output_folder_path . mkdir ( parents = True , exist_ok = True ) run_step ( self , sensors_data , vehicle ) \u00a4 Receive Sensor Data and vehicle state information on every step and return a control Parameters: Name Type Description Default sensors_data SensorsData sensor data on this frame required vehicle Vehicle vehicle state on this frame required Returns: Type Description VehicleControl Vehicle Control Source code in ROAR/roar_autonomous_system/agent_module/agent.py 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 @abstractmethod def run_step ( self , sensors_data : SensorsData , vehicle : Vehicle ) -> VehicleControl : \"\"\" Receive Sensor Data and vehicle state information on every step and return a control Args: sensors_data: sensor data on this frame vehicle: vehicle state on this frame Returns: Vehicle Control \"\"\" self . time_counter += 1 self . sync_data ( sensors_data = sensors_data , vehicle = vehicle ) if self . should_save_sensor_data : self . save_sensor_data () return VehicleControl () save_sensor_data ( self ) \u00a4 Failure-safe saving function that saves all the sensor data of the current frame Returns: Type Description None None Source code in ROAR/roar_autonomous_system/agent_module/agent.py 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 def save_sensor_data ( self ) -> None : \"\"\" Failure-safe saving function that saves all the sensor data of the current frame Returns: None \"\"\" try : cv2 . imwrite (( self . front_rgb_camera_output_folder_path / f \"frame_ { self . time_counter } .png\" ) . as_posix (), self . front_rgb_camera . data ) np . save (( self . front_depth_camera_output_folder_path / f \"frame_ { self . time_counter } \" ) . as_posix (), self . front_depth_camera . data ) cv2 . imwrite (( self . rear_rgb_camera_output_folder_path / f \"frame_ { self . time_counter } .png\" ) . as_posix (), self . rear_rgb_camera . data ) except Exception as e : self . logger . error ( f \"Failed to save at Frame { self . time_counter } . Error: { e } \" ) sync_data ( self , sensors_data , vehicle ) \u00a4 Sync agent's state by updating Sensor Data and vehicle information Parameters: Name Type Description Default sensors_data SensorsData the new frame's sensor data required vehicle Vehicle the new frame's vehicle state required Returns: Type Description None None Source code in ROAR/roar_autonomous_system/agent_module/agent.py 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 def sync_data ( self , sensors_data : SensorsData , vehicle : Vehicle ) -> None : \"\"\" Sync agent's state by updating Sensor Data and vehicle information Args: sensors_data: the new frame's sensor data vehicle: the new frame's vehicle state Returns: None \"\"\" self . vehicle = vehicle self . transform_history . append ( self . vehicle . transform ) if self . front_rgb_camera is not None : self . front_rgb_camera . data = ( sensors_data . front_rgb . data if sensors_data . front_rgb is not None else None ) if self . front_depth_camera is not None : self . front_depth_camera . data = ( sensors_data . front_depth . data if sensors_data . front_depth is not None else None ) if self . rear_rgb_camera is not None : self . rear_rgb_camera . data = ( sensors_data . rear_rgb . data if sensors_data . rear_rgb is not None else None ) if self . imu is not None : self . imu = sensors_data . imu_data","title":"Agents"},{"location":"code_documentations/roar_autonomous_system/agents/#documentation-for-agents","text":"","title":"Documentation for Agents"},{"location":"code_documentations/roar_autonomous_system/agents/#ROAR.roar_autonomous_system.agent_module.agent.Agent","text":"Abstract Agent class that define the minimum of a ROAR agent. Inherited agent can perform different duties.","title":"Agent"},{"location":"code_documentations/roar_autonomous_system/agents/#ROAR.roar_autonomous_system.agent_module.agent.Agent.__init__","text":"Initialize cameras, output folder, and logging utilities Parameters: Name Type Description Default vehicle Vehicle Vehicle instance required agent_settings AgentConfig User specified settings for Agent required imu Optional[ROAR.roar_autonomous_system.utilities_module.data_structures_models.IMUData] IMU data (will be deprecated to be passed in like this) None Source code in ROAR/roar_autonomous_system/agent_module/agent.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def __init__ ( self , vehicle : Vehicle , agent_settings : AgentConfig , imu : Optional [ IMUData ] = None ): \"\"\" Initialize cameras, output folder, and logging utilities Args: vehicle: Vehicle instance agent_settings: User specified settings for Agent imu: IMU data (will be deprecated to be passed in like this) \"\"\" self . logger = logging . getLogger ( __name__ ) self . vehicle = vehicle self . agent_settings = agent_settings self . front_rgb_camera = agent_settings . front_rgb_cam self . front_depth_camera = agent_settings . front_depth_cam self . rear_rgb_camera = agent_settings . rear_rgb_cam self . imu = imu self . output_folder_path = \\ Path ( self . agent_settings . output_data_folder_path ) self . front_depth_camera_output_folder_path = \\ self . output_folder_path / \"front_depth\" self . front_rgb_camera_output_folder_path = \\ self . output_folder_path / \"front_rgb\" self . rear_rgb_camera_output_folder_path = \\ self . output_folder_path / \"rear_rgb\" self . should_save_sensor_data = self . agent_settings . save_sensor_data self . local_planner : Optional [ LocalPlanner ] = None self . behavior_planner : Optional [ BehaviorPlanner ] = None self . mission_planner : Optional [ MissionPlanner ] = None self . time_counter = 0 self . transform_history : List [ Transform ] = [] self . init_cam ()","title":"__init__()"},{"location":"code_documentations/roar_autonomous_system/agents/#ROAR.roar_autonomous_system.agent_module.agent.Agent.init_cam","text":"Initialize the cameras by calculating the camera intrinsics and ensuring that the output folder path exists Returns: Type Description None None Source code in ROAR/roar_autonomous_system/agent_module/agent.py 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 def init_cam ( self ) -> None : \"\"\" Initialize the cameras by calculating the camera intrinsics and ensuring that the output folder path exists Returns: None \"\"\" if self . front_rgb_camera is not None : self . front_rgb_camera . intrinsics_matrix = ( self . front_rgb_camera . calculate_intrinsic_matrix () ) if self . front_depth_camera is not None : self . front_depth_camera . intrinsics_matrix = ( self . front_depth_camera . calculate_intrinsic_matrix () ) if self . rear_rgb_camera is not None : self . rear_rgb_camera . intrinsics_matrix = ( self . rear_rgb_camera . calculate_intrinsic_matrix () ) if self . should_save_sensor_data : self . front_depth_camera_output_folder_path . mkdir ( parents = True , exist_ok = True ) self . front_rgb_camera_output_folder_path . mkdir ( parents = True , exist_ok = True ) self . rear_rgb_camera_output_folder_path . mkdir ( parents = True , exist_ok = True )","title":"init_cam()"},{"location":"code_documentations/roar_autonomous_system/agents/#ROAR.roar_autonomous_system.agent_module.agent.Agent.run_step","text":"Receive Sensor Data and vehicle state information on every step and return a control Parameters: Name Type Description Default sensors_data SensorsData sensor data on this frame required vehicle Vehicle vehicle state on this frame required Returns: Type Description VehicleControl Vehicle Control Source code in ROAR/roar_autonomous_system/agent_module/agent.py 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 @abstractmethod def run_step ( self , sensors_data : SensorsData , vehicle : Vehicle ) -> VehicleControl : \"\"\" Receive Sensor Data and vehicle state information on every step and return a control Args: sensors_data: sensor data on this frame vehicle: vehicle state on this frame Returns: Vehicle Control \"\"\" self . time_counter += 1 self . sync_data ( sensors_data = sensors_data , vehicle = vehicle ) if self . should_save_sensor_data : self . save_sensor_data () return VehicleControl ()","title":"run_step()"},{"location":"code_documentations/roar_autonomous_system/agents/#ROAR.roar_autonomous_system.agent_module.agent.Agent.save_sensor_data","text":"Failure-safe saving function that saves all the sensor data of the current frame Returns: Type Description None None Source code in ROAR/roar_autonomous_system/agent_module/agent.py 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 def save_sensor_data ( self ) -> None : \"\"\" Failure-safe saving function that saves all the sensor data of the current frame Returns: None \"\"\" try : cv2 . imwrite (( self . front_rgb_camera_output_folder_path / f \"frame_ { self . time_counter } .png\" ) . as_posix (), self . front_rgb_camera . data ) np . save (( self . front_depth_camera_output_folder_path / f \"frame_ { self . time_counter } \" ) . as_posix (), self . front_depth_camera . data ) cv2 . imwrite (( self . rear_rgb_camera_output_folder_path / f \"frame_ { self . time_counter } .png\" ) . as_posix (), self . rear_rgb_camera . data ) except Exception as e : self . logger . error ( f \"Failed to save at Frame { self . time_counter } . Error: { e } \" )","title":"save_sensor_data()"},{"location":"code_documentations/roar_autonomous_system/agents/#ROAR.roar_autonomous_system.agent_module.agent.Agent.sync_data","text":"Sync agent's state by updating Sensor Data and vehicle information Parameters: Name Type Description Default sensors_data SensorsData the new frame's sensor data required vehicle Vehicle the new frame's vehicle state required Returns: Type Description None None Source code in ROAR/roar_autonomous_system/agent_module/agent.py 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 def sync_data ( self , sensors_data : SensorsData , vehicle : Vehicle ) -> None : \"\"\" Sync agent's state by updating Sensor Data and vehicle information Args: sensors_data: the new frame's sensor data vehicle: the new frame's vehicle state Returns: None \"\"\" self . vehicle = vehicle self . transform_history . append ( self . vehicle . transform ) if self . front_rgb_camera is not None : self . front_rgb_camera . data = ( sensors_data . front_rgb . data if sensors_data . front_rgb is not None else None ) if self . front_depth_camera is not None : self . front_depth_camera . data = ( sensors_data . front_depth . data if sensors_data . front_depth is not None else None ) if self . rear_rgb_camera is not None : self . rear_rgb_camera . data = ( sensors_data . rear_rgb . data if sensors_data . rear_rgb is not None else None ) if self . imu is not None : self . imu = sensors_data . imu_data","title":"sync_data()"},{"location":"code_documentations/roar_autonomous_system/controls/","text":"Controller \u00a4 __init__ ( self , vehicle ) special \u00a4 Parameters: Name Type Description Default vehicle Vehicle Vehicle instance required Source code in ROAR/roar_autonomous_system/control_module/controller.py 12 13 14 15 16 17 18 19 20 def __init__ ( self , vehicle : Vehicle ): \"\"\" Args: vehicle: Vehicle instance \"\"\" self . vehicle = vehicle self . logger = logging . getLogger ( __name__ ) run_step ( self , vehicle , next_waypoint , ** kwargs ) \u00a4 Abstract function for run step Parameters: Name Type Description Default vehicle Vehicle new vehicle state required next_waypoint Transform next waypoint required **kwargs {} Returns: Type Description VehicleControl VehicleControl Source code in ROAR/roar_autonomous_system/control_module/controller.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @abstractmethod def run_step ( self , vehicle : Vehicle , next_waypoint : Transform , ** kwargs ) \\ -> VehicleControl : \"\"\" Abstract function for run step Args: vehicle: new vehicle state next_waypoint: next waypoint **kwargs: Returns: VehicleControl \"\"\" self . sync_data ( vehicle = vehicle ) return VehicleControl () sync_data ( self , vehicle ) \u00a4 default sync data function Parameters: Name Type Description Default vehicle Vehicle new vehicle state required Returns: Type Description None None Source code in ROAR/roar_autonomous_system/control_module/controller.py 39 40 41 42 43 44 45 46 47 48 49 def sync_data ( self , vehicle : Vehicle ) -> None : \"\"\" default sync data function Args: vehicle: new vehicle state Returns: None \"\"\" self . vehicle = vehicle VehicleMPCController \u00a4 __init__ ( self , vehicle , route_file_path , target_speed = inf , steps_ahead = 10 , max_throttle = 1 , max_steering = 1 , dt = 0.1 ) special \u00a4 Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 def __init__ ( self , vehicle : Vehicle , route_file_path : Path , # read in route target_speed = float ( \"inf\" ), steps_ahead = 10 , max_throttle = 1 , max_steering = 1 , dt = 0.1 ): super () . __init__ ( vehicle ) self . logger = logging . getLogger ( __name__ ) # Read in route file self . track_DF = pd . read_csv ( route_file_path , header = None ) # Fit the route to a curve spline_points = 10000 self . pts_2D = self . track_DF . loc [:, [ 0 , 1 ]] . values tck , u = splprep ( self . pts_2D . T , u = None , s = 2.0 , per = 1 , k = 3 ) u_new = np . linspace ( u . min (), u . max (), spline_points ) x_new , y_new = splev ( u_new , tck , der = 0 ) self . pts_2D = np . c_ [ x_new , y_new ] # Modified parm self . prev_cte = 0 self . target_speed = target_speed self . state_vars = ( 'x' , 'y' , 'v' , '\u03c8' , 'cte' , 'e\u03c8' ) self . steps_ahead = steps_ahead self . dt = dt # Cost function coefficients self . cte_coeff = 100 # 100 self . epsi_coeff = 100 # 100 self . speed_coeff = 0.4 # 0.2 self . acc_coeff = 1 # 1 self . steer_coeff = 0.1 # 0.1 self . consec_acc_coeff = 50 self . consec_steer_coeff = 50 # Front wheel L self . Lf = 2.5 # How the polynomial fitting the desired curve is fitted self . steps_poly = 30 # modify to 3 when using 3D data self . poly_degree = 3 # Bounds for the optimizer self . bounds = ( 6 * self . steps_ahead * [( None , None )] + self . steps_ahead * [( 0 , max_throttle )] # throttle bounds + self . steps_ahead * [( - max_steering , max_steering )] # steer bounds ) # State 0 placeholder num_vars = ( len ( self . state_vars ) + 2 ) # State variables and two actuators self . state0 = np . zeros ( self . steps_ahead * num_vars ) # Lambdify and minimize stuff self . evaluator = 'numpy' self . tolerance = 1 self . cost_func , self . cost_grad_func , self . constr_funcs = \\ self . get_func_constraints_and_bounds () # To keep the previous state self . steer = 0 self . throttle = 0 self . logger . debug ( \"MPC Controller initiated\" ) clip_throttle ( throttle , curr_speed , target_speed ) staticmethod \u00a4 Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 410 411 412 413 414 415 416 @staticmethod def clip_throttle ( throttle , curr_speed , target_speed ): return np . clip ( throttle - 0.01 * ( curr_speed - target_speed ), 0.4 , 0.9 ) create_array_of_symbols ( str_symbol , N ) staticmethod \u00a4 Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 398 399 400 @staticmethod def create_array_of_symbols ( str_symbol , N ): return sym . symbols ( ' {symbol} 0: {N} ' . format ( symbol = str_symbol , N = N )) generate_fun ( self , symb_fun , vars_ , init , poly ) \u00a4 Generates a function of the form fun(x, *args) Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 317 318 319 320 321 322 def generate_fun ( self , symb_fun , vars_ , init , poly ): \"\"\" Generates a function of the form `fun(x, *args)` \"\"\" args = init + poly return sym . lambdify (( vars_ , * args ), symb_fun , self . evaluator ) generate_grad ( self , symb_fun , vars_ , init , poly ) \u00a4 TODO: add comments Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 324 325 326 327 328 329 330 331 332 333 def generate_grad ( self , symb_fun , vars_ , init , poly ): \"\"\" TODO: add comments \"\"\" args = init + poly return sym . lambdify ( ( vars_ , * args ), derive_by_array ( symb_fun , vars_ + args )[: len ( vars_ )], self . evaluator ) get_closest_waypoint_index_2D ( self , car_location , waypoint_location ) \u00a4 Get the index of the closest waypoint in self.pts_2D Note: it may give wrong index when the route is overlapped Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 387 388 389 390 391 392 393 394 395 396 def get_closest_waypoint_index_2D ( self , car_location , waypoint_location ): \"\"\"Get the index of the closest waypoint in self.pts_2D Note: it may give wrong index when the route is overlapped \"\"\" location_arr = np . array ([ car_location . x , car_location . y ]) dists = np . linalg . norm ( self . pts_2D - location_arr , axis = 1 ) return np . argmin ( dists ) get_closest_waypoint_index_3D ( self , car_location , waypoint_location ) \u00a4 Get the index of the closest waypoint in self.track_DF car_location: current car location waypoint_location: next_waypoint Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 def get_closest_waypoint_index_3D ( self , car_location , waypoint_location ): \"\"\"Get the index of the closest waypoint in self.track_DF car_location: current car location waypoint_location: next_waypoint \"\"\" index = self . track_DF . loc [( self . track_DF [ 0 ] == waypoint_location . x ) & ( self . track_DF [ 1 ] == waypoint_location . y )] . index if len ( index ) > 0 : return index [ 0 ] else : location_arr = np . array ([ car_location . x , car_location . y , car_location . z , ]) dists = np . linalg . norm ( self . track_DF - location_arr , axis = 1 ) return np . argmin ( dists ) get_func_constraints_and_bounds ( self ) \u00a4 Defines MPC's cost function and constraints. Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 def get_func_constraints_and_bounds ( self ): \"\"\" Defines MPC's cost function and constraints. \"\"\" # Polynomial coefficients will also be symbolic variables poly = self . create_array_of_symbols ( 'poly' , self . poly_degree + 1 ) # Initialize the initial state x_init = sym . symbols ( 'x_init' ) y_init = sym . symbols ( 'y_init' ) \u03c8_init = sym . symbols ( '\u03c8_init' ) v_init = sym . symbols ( 'v_init' ) cte_init = sym . symbols ( 'cte_init' ) e\u03c8_init = sym . symbols ( 'e\u03c8_init' ) init = ( x_init , y_init , \u03c8_init , v_init , cte_init , e\u03c8_init ) # State variables x = self . create_array_of_symbols ( 'x' , self . steps_ahead ) y = self . create_array_of_symbols ( 'y' , self . steps_ahead ) \u03c8 = self . create_array_of_symbols ( '\u03c8' , self . steps_ahead ) v = self . create_array_of_symbols ( 'v' , self . steps_ahead ) cte = self . create_array_of_symbols ( 'cte' , self . steps_ahead ) e\u03c8 = self . create_array_of_symbols ( 'e\u03c8' , self . steps_ahead ) # Actuators a = self . create_array_of_symbols ( 'a' , self . steps_ahead ) \u03b4 = self . create_array_of_symbols ( '\u03b4' , self . steps_ahead ) vars_ = ( # Symbolic arrays (but NOT actuators) * x , * y , * \u03c8 , * v , * cte , * e\u03c8 , # Symbolic arrays (actuators) * a , * \u03b4 , ) cost = 0 for t in range ( self . steps_ahead ): cost += ( # Reference state penalties self . cte_coeff * cte [ t ] ** 2 + self . epsi_coeff * e\u03c8 [ t ] ** 2 + + self . speed_coeff * ( v [ t ] - self . target_speed ) ** 2 # Actuator penalties + self . acc_coeff * a [ t ] ** 2 + self . steer_coeff * \u03b4 [ t ] ** 2 ) # Penalty for differences in consecutive actuators for t in range ( self . steps_ahead - 1 ): cost += ( self . consec_acc_coeff * ( a [ t + 1 ] - a [ t ]) ** 2 + self . consec_steer_coeff * ( \u03b4 [ t + 1 ] - \u03b4 [ t ]) ** 2 ) # Initialize constraints eq_constr = _EqualityConstraints ( self . steps_ahead , self . state_vars ) eq_constr [ 'x' ][ 0 ] = x [ 0 ] - x_init eq_constr [ 'y' ][ 0 ] = y [ 0 ] - y_init eq_constr [ '\u03c8' ][ 0 ] = \u03c8 [ 0 ] - \u03c8_init eq_constr [ 'v' ][ 0 ] = v [ 0 ] - v_init eq_constr [ 'cte' ][ 0 ] = cte [ 0 ] - cte_init eq_constr [ 'e\u03c8' ][ 0 ] = e\u03c8 [ 0 ] - e\u03c8_init for t in range ( 1 , self . steps_ahead ): curve = sum ( poly [ - ( i + 1 )] * x [ t - 1 ] ** i for i in range ( len ( poly ))) # The desired \u03c8 is equal to the derivative of the polynomial # curve at # point x[t-1] \u03c8des = sum ( poly [ - ( i + 1 )] * i * x [ t - 1 ] ** ( i - 1 ) for i in range ( 1 , len ( poly ))) eq_constr [ 'x' ][ t ] = x [ t ] - ( x [ t - 1 ] + v [ t - 1 ] * sym . cos ( \u03c8 [ t - 1 ]) * self . dt ) eq_constr [ 'y' ][ t ] = y [ t ] - ( y [ t - 1 ] + v [ t - 1 ] * sym . sin ( \u03c8 [ t - 1 ]) * self . dt ) eq_constr [ '\u03c8' ][ t ] = \u03c8 [ t ] - ( \u03c8 [ t - 1 ] - v [ t - 1 ] * \u03b4 [ t - 1 ] / self . Lf * self . dt ) eq_constr [ 'v' ][ t ] = v [ t ] - ( v [ t - 1 ] + a [ t - 1 ] * self . dt ) eq_constr [ 'cte' ][ t ] = cte [ t ] - ( curve - y [ t - 1 ] + v [ t - 1 ] * sym . sin ( e\u03c8 [ t - 1 ]) * self . dt ) eq_constr [ 'e\u03c8' ][ t ] = e\u03c8 [ t ] - ( \u03c8 [ t - 1 ] - \u03c8des - v [ t - 1 ] * \u03b4 [ t - 1 ] / self . Lf * self . dt ) # Generate actual functions from cost_func = self . generate_fun ( cost , vars_ , init , poly ) cost_grad_func = self . generate_grad ( cost , vars_ , init , poly ) constr_funcs = [] for symbol in self . state_vars : for t in range ( self . steps_ahead ): func = self . generate_fun ( eq_constr [ symbol ][ t ], vars_ , init , poly ) grad_func = self . generate_grad ( eq_constr [ symbol ][ t ], vars_ , init , poly ) constr_funcs . append ( { 'type' : 'eq' , 'fun' : func , 'jac' : grad_func , 'args' : None }, ) return cost_func , cost_grad_func , constr_funcs get_state0 ( self , v , cte , epsi , a , delta , poly ) \u00a4 Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 def get_state0 ( self , v , cte , epsi , a , delta , poly ): a = a or 0 delta = delta or 0 x = np . linspace ( 0 , 1 , self . steps_ahead ) y = np . polyval ( poly , x ) psi = 0 self . state0 [: self . steps_ahead ] = x self . state0 [ self . steps_ahead : 2 * self . steps_ahead ] = y self . state0 [ 2 * self . steps_ahead : 3 * self . steps_ahead ] = psi self . state0 [ 3 * self . steps_ahead : 4 * self . steps_ahead ] = v self . state0 [ 4 * self . steps_ahead : 5 * self . steps_ahead ] = cte self . state0 [ 5 * self . steps_ahead : 6 * self . steps_ahead ] = epsi self . state0 [ 6 * self . steps_ahead : 7 * self . steps_ahead ] = a self . state0 [ 7 * self . steps_ahead : 8 * self . steps_ahead ] = delta return self . state0 minimize_cost ( self , bounds , x0 , init ) \u00a4 Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 353 354 355 356 357 358 359 360 361 362 363 364 365 366 def minimize_cost ( self , bounds , x0 , init ): for constr_func in self . constr_funcs : constr_func [ 'args' ] = init return minimize ( fun = self . cost_func , x0 = x0 , args = init , jac = self . cost_grad_func , bounds = bounds , constraints = self . constr_funcs , method = 'SLSQP' , tol = self . tolerance , ) run_step ( self , vehicle , next_waypoint , ** kwargs ) \u00a4 Abstract function for run step Parameters: Name Type Description Default vehicle Vehicle new vehicle state required next_waypoint Transform next waypoint required **kwargs {} Returns: Type Description VehicleControl VehicleControl Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 def run_step ( self , vehicle : Vehicle , next_waypoint : Transform , ** kwargs ) -> VehicleControl : super ( VehicleMPCController , self ) . run_step ( vehicle , next_waypoint ) # get vehicle location (x, y) # location = self.vehicle.transform.location location = vehicle . transform . location x , y = location . x , location . y # get vehicle rotation # rotation = self.vehicle.transform.rotation rotation = vehicle . transform . rotation \u03c8 = rotation . yaw / 180 * np . pi # transform into radient cos_\u03c8 = np . cos ( \u03c8 ) sin_\u03c8 = np . sin ( \u03c8 ) # get vehicle speed # v = Vehicle.get_speed(self.vehicle) v = Vehicle . get_speed ( vehicle ) # get next waypoint location wx , wy = next_waypoint . location . x , next_waypoint . location . y # debug logging # self.logger.debug(f\"car location: ({x}, {y})\") # self.logger.debug(f\"car \u03c8: {\u03c8}\") # self.logger.debug(f\"car speed: {v}\") # self.logger.debug(f\"next waypoint: ({wx}, {wy})\") ### 3D ### # get the index of next waypoint # waypoint_index = self.get_closest_waypoint_index_3D(location, # next_waypoint.location) # # find more waypoints index to fit a polynomial # waypoint_index_shifted = waypoint_index - 2 # indeces = waypoint_index_shifted + self.steps_poly * np.arange( # self.poly_degree + 1) # indeces = indeces % self.track_DF.shape[0] # # get waypoints for polynomial fitting # pts = np.array([[self.track_DF.iloc[i][0], self.track_DF.iloc[i][ # 1]] for i in indeces]) ### 2D ### index_2D = self . get_closest_waypoint_index_2D ( location , next_waypoint . location ) index_2D_shifted = index_2D - 5 indeces_2D = index_2D_shifted + self . steps_poly * np . arange ( self . poly_degree + 1 ) indeces_2D = indeces_2D % self . pts_2D . shape [ 0 ] pts = self . pts_2D [ indeces_2D ] # self.logger.debug(f'\\nwaypoint index:\\n {index_2D}') # self.logger.debug(f'\\nindeces:\\n {indeces_2D}') # transform waypoints from world to car coorinate pts_car = VehicleMPCController . transform_into_cars_coordinate_system ( pts , x , y , cos_\u03c8 , sin_\u03c8 ) # fit the polynomial poly = np . polyfit ( pts_car [:, 0 ], pts_car [:, 1 ], self . poly_degree ) # Debug # self.logger.debug(f'\\nwaypoint index:\\n {waypoint_index}') # self.logger.debug(f'\\nindeces:\\n {indeces}') # self.logger.debug(f'\\npts for poly_fit:\\n {pts}') # self.logger.debug(f'\\npts_car:\\n {pts_car}') ########### cte = poly [ - 1 ] e\u03c8 = - np . arctan ( poly [ - 2 ]) init = ( 0 , 0 , 0 , v , cte , e\u03c8 , * poly ) self . state0 = self . get_state0 ( v , cte , e\u03c8 , self . steer , self . throttle , poly ) result = self . minimize_cost ( self . bounds , self . state0 , init ) # self.steer = -0.6 * cte - 5.5 * (cte - self.prev_cte) # self.prev_cte = cte # self.throttle = VehicleMPCController.clip_throttle(self.throttle, # v, self.target_speed) control = VehicleControl () if 'success' in result . message : self . steer = result . x [ - self . steps_ahead ] self . throttle = result . x [ - 2 * self . steps_ahead ] else : self . logger . debug ( 'Unsuccessful optimization' ) control . steering = self . steer control . throttle = self . throttle return control sync_data ( self , vehicle ) \u00a4 default sync data function Parameters: Name Type Description Default vehicle new vehicle state required Returns: Type Description None None Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 208 209 def sync_data ( self , vehicle ) -> None : super ( VehicleMPCController , self ) . sync_data ( vehicle = vehicle ) transform_into_cars_coordinate_system ( pts , x , y , cos_\u03c8 , sin_\u03c8 ) staticmethod \u00a4 Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 402 403 404 405 406 407 408 @staticmethod def transform_into_cars_coordinate_system ( pts , x , y , cos_\u03c8 , sin_\u03c8 ): diff = ( pts - [ x , y ]) pts_car = np . zeros_like ( diff ) pts_car [:, 0 ] = cos_\u03c8 * diff [:, 0 ] + sin_\u03c8 * diff [:, 1 ] pts_car [:, 1 ] = sin_\u03c8 * diff [:, 0 ] - cos_\u03c8 * diff [:, 1 ] return pts_car This module contains PID controllers to perform lateral and longitudinal control. OPTIMIZED_LATERAL_PID_VALUES \u00a4 PIDLateralController \u00a4 PIDLateralController implements lateral control using a PID. __init__ ( self , vehicle , K_P = 1.0 , K_D = 0.0 , K_I = 0.0 , dt = 0.03 ) special \u00a4 Constructor method. :param vehicle: actor to apply to local planner logic onto :param K_P: Proportional term :param K_D: Differential term :param K_I: Integral term :param dt: time differential in seconds Source code in ROAR/roar_autonomous_system/control_module/pid_controller.py 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 def __init__ ( self , vehicle , K_P = 1.0 , K_D = 0.0 , K_I = 0.0 , dt = 0.03 ): \"\"\" Constructor method. :param vehicle: actor to apply to local planner logic onto :param K_P: Proportional term :param K_D: Differential term :param K_I: Integral term :param dt: time differential in seconds \"\"\" self . vehicle : Vehicle = vehicle self . k_p = K_P self . k_d = K_D self . k_i = K_I self . dt = dt self . _e_buffer = deque ( maxlen = 10 ) run_step ( self , target_waypoint ) \u00a4 Execute one step of lateral control to steer the vehicle towards a certain waypoin. :param target_waypoint: :return: steering control in the range [-1, 1] where: -1 maximum steering to left +1 maximum steering to right Source code in ROAR/roar_autonomous_system/control_module/pid_controller.py 244 245 246 247 248 249 250 251 252 253 254 255 def run_step ( self , target_waypoint : Transform ) -> float : \"\"\" Execute one step of lateral control to steer the vehicle towards a certain waypoin. :param target_waypoint: :return: steering control in the range [-1, 1] where: -1 maximum steering to left +1 maximum steering to right \"\"\" return self . _pid_control ( target_waypoint = target_waypoint , vehicle_transform = self . vehicle . transform ) PIDLongitudinalController \u00a4 PIDLongitudinalController implements longitudinal control using a PID. __init__ ( self , vehicle , K_P = 1.0 , K_D = 0.0 , K_I = 0.0 , dt = 0.03 ) special \u00a4 Constructor method. :param vehicle: actor to apply to local planner logic onto :param K_P: Proportional term :param K_D: Differential term :param K_I: Integral term :param dt: time differential in seconds Source code in ROAR/roar_autonomous_system/control_module/pid_controller.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 def __init__ ( self , vehicle : Vehicle , K_P = 1.0 , K_D = 0.0 , K_I = 0.0 , dt = 0.03 ): \"\"\" Constructor method. :param vehicle: actor to apply to local planner logic onto :param K_P: Proportional term :param K_D: Differential term :param K_I: Integral term :param dt: time differential in seconds \"\"\" self . vehicle = vehicle self . _k_p = K_P self . _k_d = K_D self . _k_i = K_I self . _dt = dt self . _error_buffer = deque ( maxlen = 10 ) run_step ( self , target_speed ) \u00a4 Execute one step of longitudinal control to reach a given target speed. :param target_speed: target speed in Km/h :return: throttle control Source code in ROAR/roar_autonomous_system/control_module/pid_controller.py 188 189 190 191 192 193 194 195 def run_step ( self , target_speed ): \"\"\" Execute one step of longitudinal control to reach a given target speed. :param target_speed: target speed in Km/h :return: throttle control \"\"\" current_speed = Vehicle . get_speed ( self . vehicle ) return self . _pid_control ( target_speed , current_speed ) PIDParam pydantic-model \u00a4 dt: float pydantic-field \u00a4 K_D: float pydantic-field \u00a4 K_I: float pydantic-field \u00a4 K_P: float pydantic-field \u00a4 __config__ \u00a4 __json_encoder__ ( obj ) special staticmethod \u00a4 default_lateral_param () staticmethod \u00a4 Source code in ROAR/roar_autonomous_system/control_module/pid_controller.py 30 31 32 @staticmethod def default_lateral_param (): return PIDParam ( K_P = 1.95 , K_D = 0.2 , K_I = 0.07 , dt = 1.0 / 20.0 ) default_longitudinal_param () staticmethod \u00a4 Source code in ROAR/roar_autonomous_system/control_module/pid_controller.py 34 35 36 @staticmethod def default_longitudinal_param (): return PIDParam ( K_P = 1 , K_D = 0 , K_I = 0.05 , dt = 1.0 / 20.0 ) VehiclePIDController \u00a4 VehiclePIDController is the combination of two PID controllers (lateral and longitudinal) to perform the low level control a vehicle from client side __init__ ( self , vehicle , args_lateral , args_longitudinal , target_speed = inf , max_throttle = 1 , max_steering = 1 ) special \u00a4 Parameters: Name Type Description Default vehicle Vehicle actor to apply to local planner logic onto required args_lateral PIDParam dictionary of arguments to set the lateral PID control required args_longitudinal PIDParam dictionary of arguments to set the longitudinal required target_speed target speedd in km/h inf max_throttle maximum throttle from, will be capped at 1 1 max_steering absolute maximum steering ranging from -1 - 1 1 Source code in ROAR/roar_autonomous_system/control_module/pid_controller.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 def __init__ ( self , vehicle : Vehicle , args_lateral : PIDParam , args_longitudinal : PIDParam , target_speed = float ( \"inf\" ), max_throttle = 1 , max_steering = 1 , ): \"\"\" Args: vehicle: actor to apply to local planner logic onto args_lateral: dictionary of arguments to set the lateral PID control args_longitudinal: dictionary of arguments to set the longitudinal target_speed: target speedd in km/h max_throttle: maximum throttle from, will be capped at 1 max_steering: absolute maximum steering ranging from -1 - 1 \"\"\" super () . __init__ ( vehicle ) self . logger = logging . getLogger ( __name__ ) self . max_throttle = max_throttle self . max_steer = max_steering self . target_speed = target_speed self . past_steering = self . vehicle . control . steering self . _lon_controller = PIDLongitudinalController ( self . vehicle , K_P = args_longitudinal . K_P , K_D = args_longitudinal . K_D , K_I = args_longitudinal . K_I , dt = args_longitudinal . dt , ) self . _lat_controller = PIDLateralController ( self . vehicle , K_P = args_lateral . K_P , K_D = args_lateral . K_D , K_I = args_lateral . K_I , dt = args_lateral . dt , ) self . logger . debug ( \"PID Controller initiated\" ) run_step ( self , vehicle , next_waypoint , ** kwargs ) \u00a4 Execute one step of control invoking both lateral and longitudinal PID controllers to reach a target waypoint at a given target_speed. Parameters: Name Type Description Default vehicle Vehicle New vehicle state required next_waypoint Transform target location encoded as a waypoint required **kwargs {} Returns: Type Description VehicleControl Next Vehicle Control Source code in ROAR/roar_autonomous_system/control_module/pid_controller.py 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 def run_step ( self , vehicle : Vehicle , next_waypoint : Transform , ** kwargs ) -> VehicleControl : \"\"\" Execute one step of control invoking both lateral and longitudinal PID controllers to reach a target waypoint at a given target_speed. Args: vehicle: New vehicle state next_waypoint: target location encoded as a waypoint **kwargs: Returns: Next Vehicle Control \"\"\" super ( VehiclePIDController , self ) . run_step ( vehicle , next_waypoint ) curr_speed = Vehicle . get_speed ( self . vehicle ) if curr_speed < 60 : self . _lat_controller . k_d = OPTIMIZED_LATERAL_PID_VALUES [ 60 ] . K_D self . _lat_controller . k_i = OPTIMIZED_LATERAL_PID_VALUES [ 60 ] . K_I self . _lat_controller . k_p = OPTIMIZED_LATERAL_PID_VALUES [ 60 ] . K_P elif curr_speed < 100 : self . _lat_controller . k_d = OPTIMIZED_LATERAL_PID_VALUES [ 100 ] . K_D self . _lat_controller . k_i = OPTIMIZED_LATERAL_PID_VALUES [ 100 ] . K_I self . _lat_controller . k_p = OPTIMIZED_LATERAL_PID_VALUES [ 100 ] . K_P elif curr_speed < 150 : self . _lat_controller . k_d = OPTIMIZED_LATERAL_PID_VALUES [ 150 ] . K_D self . _lat_controller . k_i = OPTIMIZED_LATERAL_PID_VALUES [ 150 ] . K_I self . _lat_controller . k_p = OPTIMIZED_LATERAL_PID_VALUES [ 150 ] . K_P acceptable_target_speed = self . target_speed if abs ( self . vehicle . control . steering ) < 0.05 : acceptable_target_speed += 20 # eco boost acceleration = self . _lon_controller . run_step ( acceptable_target_speed ) current_steering = self . _lat_controller . run_step ( next_waypoint ) control = VehicleControl () if acceleration >= 0.0 : control . throttle = min ( acceleration , self . max_throttle ) # control.brake = 0.0 else : control . throttle = 0 # control.brake = min(abs(acceleration), self.max_brake) # Steering regulation: changes cannot happen abruptly, can't steer too much. if current_steering > self . past_steering + 0.1 : current_steering = self . past_steering + 0.1 elif current_steering < self . past_steering - 0.1 : current_steering = self . past_steering - 0.1 if current_steering >= 0 : steering = min ( self . max_steer , current_steering ) else : steering = max ( - self . max_steer , current_steering ) if abs ( current_steering ) > 0.03 and curr_speed > 110 : # if i am doing a sharp (>0.5) turn, i do not want to step on full gas control . throttle = - 1 control . steering = steering self . past_steering = steering return control sync_data ( self , vehicle ) \u00a4 default sync data function Parameters: Name Type Description Default vehicle new vehicle state required Returns: Type Description None None Source code in ROAR/roar_autonomous_system/control_module/pid_controller.py 161 162 163 164 def sync_data ( self , vehicle ) -> None : super ( VehiclePIDController , self ) . sync_data ( vehicle = vehicle ) self . _lon_controller . vehicle = self . vehicle self . _lat_controller . vehicle = self . vehicle LatitunalPurePursuitController \u00a4 __init__ ( self , vehicle , look_ahead_gain , look_ahead_distance ) special \u00a4 Source code in ROAR/roar_autonomous_system/control_module/pure_pursuit_control.py 95 96 97 98 99 100 101 def __init__ ( self , vehicle : Vehicle , look_ahead_gain : float , look_ahead_distance : float ): self . vehicle = vehicle self . look_ahead_gain = look_ahead_gain self . look_ahead_distance = look_ahead_distance run_step ( self , vehicle , next_waypoint ) \u00a4 Source code in ROAR/roar_autonomous_system/control_module/pure_pursuit_control.py 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 def run_step ( self , vehicle : Vehicle , next_waypoint : Transform ) -> float : self . sync ( vehicle = vehicle ) target_y = next_waypoint . location . y target_x = next_waypoint . location . x angle_difference = math . atan2 ( target_y - self . vehicle . transform . location . y , target_x - self . vehicle . transform . location . x , ) - np . radians ( self . vehicle . transform . rotation . yaw ) curr_look_forward = ( self . look_ahead_gain * Vehicle . get_speed ( vehicle = vehicle ) + self . look_ahead_distance ) lateral_difference = math . atan2 ( 2.0 * self . vehicle . wheel_base * math . sin ( angle_difference ) / curr_look_forward , 1.0 , ) return VehicleControl . clamp ( lateral_difference , - 1 , 1 ) sync ( self , vehicle ) \u00a4 Source code in ROAR/roar_autonomous_system/control_module/pure_pursuit_control.py 124 125 def sync ( self , vehicle : Vehicle ): self . vehicle = vehicle LongitunalPurePursuitController \u00a4 __init__ ( self , vehicle , target_speed = 60 , kp = 0.1 ) special \u00a4 Source code in ROAR/roar_autonomous_system/control_module/pure_pursuit_control.py 76 77 78 79 def __init__ ( self , vehicle : Vehicle , target_speed = 60 , kp = 0.1 ): self . vehicle = vehicle self . target_speed = target_speed self . kp = kp run_step ( self , vehicle ) \u00a4 Source code in ROAR/roar_autonomous_system/control_module/pure_pursuit_control.py 81 82 83 84 85 86 87 88 def run_step ( self , vehicle : Vehicle ) -> float : self . sync ( vehicle = vehicle ) return float ( VehicleControl . clamp ( self . kp * ( self . target_speed - Vehicle . get_speed ( vehicle )), 0 , 1 ) ) sync ( self , vehicle ) \u00a4 Source code in ROAR/roar_autonomous_system/control_module/pure_pursuit_control.py 90 91 def sync ( self , vehicle : Vehicle ): self . vehicle = vehicle PurePursuitController \u00a4 __init__ ( self , vehicle , look_ahead_gain = 0.1 , look_ahead_distance = 2 , target_speed = 60 ) special \u00a4 Parameters: Name Type Description Default vehicle Vehicle Vehicle information required look_ahead_gain float Look ahead factor 0.1 look_ahead_distance float look ahead distance 2 target_speed desired longitudinal speed to maintain 60 Source code in ROAR/roar_autonomous_system/control_module/pure_pursuit_control.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , vehicle : Vehicle , look_ahead_gain : float = 0.1 , look_ahead_distance : float = 2 , target_speed = 60 , ): \"\"\" Args: vehicle: Vehicle information look_ahead_gain: Look ahead factor look_ahead_distance: look ahead distance target_speed: desired longitudinal speed to maintain \"\"\" super ( PurePursuitController , self ) . __init__ ( vehicle = vehicle ) self . target_speed = target_speed self . look_ahead_gain = look_ahead_gain self . look_ahead_distance = look_ahead_distance self . latitunal_controller = LatitunalPurePursuitController ( vehicle = self . vehicle , look_ahead_gain = look_ahead_gain , look_ahead_distance = look_ahead_distance , ) self . longitunal_controller = LongitunalPurePursuitController ( vehicle = self . vehicle , target_speed = target_speed ) run_step ( self , vehicle , next_waypoint , ** kwargs ) \u00a4 run one step of Pure Pursuit Control Parameters: Name Type Description Default vehicle Vehicle current vehicle state required next_waypoint Transform Next waypoint, Transform required **kwargs {} Returns: Type Description VehicleControl Vehicle Control Source code in ROAR/roar_autonomous_system/control_module/pure_pursuit_control.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 def run_step ( self , vehicle : Vehicle , next_waypoint : Transform , ** kwargs ) -> VehicleControl : \"\"\" run one step of Pure Pursuit Control Args: vehicle: current vehicle state next_waypoint: Next waypoint, Transform **kwargs: Returns: Vehicle Control \"\"\" control = VehicleControl ( throttle = self . longitunal_controller . run_step ( vehicle = vehicle ), steering = self . latitunal_controller . run_step ( vehicle = vehicle , next_waypoint = next_waypoint ), ) return control","title":"Control"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.controller.Controller","text":"","title":"Controller"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.controller.Controller.__init__","text":"Parameters: Name Type Description Default vehicle Vehicle Vehicle instance required Source code in ROAR/roar_autonomous_system/control_module/controller.py 12 13 14 15 16 17 18 19 20 def __init__ ( self , vehicle : Vehicle ): \"\"\" Args: vehicle: Vehicle instance \"\"\" self . vehicle = vehicle self . logger = logging . getLogger ( __name__ )","title":"__init__()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.controller.Controller.run_step","text":"Abstract function for run step Parameters: Name Type Description Default vehicle Vehicle new vehicle state required next_waypoint Transform next waypoint required **kwargs {} Returns: Type Description VehicleControl VehicleControl Source code in ROAR/roar_autonomous_system/control_module/controller.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @abstractmethod def run_step ( self , vehicle : Vehicle , next_waypoint : Transform , ** kwargs ) \\ -> VehicleControl : \"\"\" Abstract function for run step Args: vehicle: new vehicle state next_waypoint: next waypoint **kwargs: Returns: VehicleControl \"\"\" self . sync_data ( vehicle = vehicle ) return VehicleControl ()","title":"run_step()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.controller.Controller.sync_data","text":"default sync data function Parameters: Name Type Description Default vehicle Vehicle new vehicle state required Returns: Type Description None None Source code in ROAR/roar_autonomous_system/control_module/controller.py 39 40 41 42 43 44 45 46 47 48 49 def sync_data ( self , vehicle : Vehicle ) -> None : \"\"\" default sync data function Args: vehicle: new vehicle state Returns: None \"\"\" self . vehicle = vehicle","title":"sync_data()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.mpc_controller.VehicleMPCController","text":"","title":"VehicleMPCController"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.mpc_controller.VehicleMPCController.__init__","text":"Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 def __init__ ( self , vehicle : Vehicle , route_file_path : Path , # read in route target_speed = float ( \"inf\" ), steps_ahead = 10 , max_throttle = 1 , max_steering = 1 , dt = 0.1 ): super () . __init__ ( vehicle ) self . logger = logging . getLogger ( __name__ ) # Read in route file self . track_DF = pd . read_csv ( route_file_path , header = None ) # Fit the route to a curve spline_points = 10000 self . pts_2D = self . track_DF . loc [:, [ 0 , 1 ]] . values tck , u = splprep ( self . pts_2D . T , u = None , s = 2.0 , per = 1 , k = 3 ) u_new = np . linspace ( u . min (), u . max (), spline_points ) x_new , y_new = splev ( u_new , tck , der = 0 ) self . pts_2D = np . c_ [ x_new , y_new ] # Modified parm self . prev_cte = 0 self . target_speed = target_speed self . state_vars = ( 'x' , 'y' , 'v' , '\u03c8' , 'cte' , 'e\u03c8' ) self . steps_ahead = steps_ahead self . dt = dt # Cost function coefficients self . cte_coeff = 100 # 100 self . epsi_coeff = 100 # 100 self . speed_coeff = 0.4 # 0.2 self . acc_coeff = 1 # 1 self . steer_coeff = 0.1 # 0.1 self . consec_acc_coeff = 50 self . consec_steer_coeff = 50 # Front wheel L self . Lf = 2.5 # How the polynomial fitting the desired curve is fitted self . steps_poly = 30 # modify to 3 when using 3D data self . poly_degree = 3 # Bounds for the optimizer self . bounds = ( 6 * self . steps_ahead * [( None , None )] + self . steps_ahead * [( 0 , max_throttle )] # throttle bounds + self . steps_ahead * [( - max_steering , max_steering )] # steer bounds ) # State 0 placeholder num_vars = ( len ( self . state_vars ) + 2 ) # State variables and two actuators self . state0 = np . zeros ( self . steps_ahead * num_vars ) # Lambdify and minimize stuff self . evaluator = 'numpy' self . tolerance = 1 self . cost_func , self . cost_grad_func , self . constr_funcs = \\ self . get_func_constraints_and_bounds () # To keep the previous state self . steer = 0 self . throttle = 0 self . logger . debug ( \"MPC Controller initiated\" )","title":"__init__()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.mpc_controller.VehicleMPCController.clip_throttle","text":"Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 410 411 412 413 414 415 416 @staticmethod def clip_throttle ( throttle , curr_speed , target_speed ): return np . clip ( throttle - 0.01 * ( curr_speed - target_speed ), 0.4 , 0.9 )","title":"clip_throttle()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.mpc_controller.VehicleMPCController.create_array_of_symbols","text":"Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 398 399 400 @staticmethod def create_array_of_symbols ( str_symbol , N ): return sym . symbols ( ' {symbol} 0: {N} ' . format ( symbol = str_symbol , N = N ))","title":"create_array_of_symbols()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.mpc_controller.VehicleMPCController.generate_fun","text":"Generates a function of the form fun(x, *args) Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 317 318 319 320 321 322 def generate_fun ( self , symb_fun , vars_ , init , poly ): \"\"\" Generates a function of the form `fun(x, *args)` \"\"\" args = init + poly return sym . lambdify (( vars_ , * args ), symb_fun , self . evaluator )","title":"generate_fun()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.mpc_controller.VehicleMPCController.generate_grad","text":"TODO: add comments Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 324 325 326 327 328 329 330 331 332 333 def generate_grad ( self , symb_fun , vars_ , init , poly ): \"\"\" TODO: add comments \"\"\" args = init + poly return sym . lambdify ( ( vars_ , * args ), derive_by_array ( symb_fun , vars_ + args )[: len ( vars_ )], self . evaluator )","title":"generate_grad()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.mpc_controller.VehicleMPCController.get_closest_waypoint_index_2D","text":"Get the index of the closest waypoint in self.pts_2D Note: it may give wrong index when the route is overlapped Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 387 388 389 390 391 392 393 394 395 396 def get_closest_waypoint_index_2D ( self , car_location , waypoint_location ): \"\"\"Get the index of the closest waypoint in self.pts_2D Note: it may give wrong index when the route is overlapped \"\"\" location_arr = np . array ([ car_location . x , car_location . y ]) dists = np . linalg . norm ( self . pts_2D - location_arr , axis = 1 ) return np . argmin ( dists )","title":"get_closest_waypoint_index_2D()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.mpc_controller.VehicleMPCController.get_closest_waypoint_index_3D","text":"Get the index of the closest waypoint in self.track_DF car_location: current car location waypoint_location: next_waypoint Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 def get_closest_waypoint_index_3D ( self , car_location , waypoint_location ): \"\"\"Get the index of the closest waypoint in self.track_DF car_location: current car location waypoint_location: next_waypoint \"\"\" index = self . track_DF . loc [( self . track_DF [ 0 ] == waypoint_location . x ) & ( self . track_DF [ 1 ] == waypoint_location . y )] . index if len ( index ) > 0 : return index [ 0 ] else : location_arr = np . array ([ car_location . x , car_location . y , car_location . z , ]) dists = np . linalg . norm ( self . track_DF - location_arr , axis = 1 ) return np . argmin ( dists )","title":"get_closest_waypoint_index_3D()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.mpc_controller.VehicleMPCController.get_func_constraints_and_bounds","text":"Defines MPC's cost function and constraints. Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 def get_func_constraints_and_bounds ( self ): \"\"\" Defines MPC's cost function and constraints. \"\"\" # Polynomial coefficients will also be symbolic variables poly = self . create_array_of_symbols ( 'poly' , self . poly_degree + 1 ) # Initialize the initial state x_init = sym . symbols ( 'x_init' ) y_init = sym . symbols ( 'y_init' ) \u03c8_init = sym . symbols ( '\u03c8_init' ) v_init = sym . symbols ( 'v_init' ) cte_init = sym . symbols ( 'cte_init' ) e\u03c8_init = sym . symbols ( 'e\u03c8_init' ) init = ( x_init , y_init , \u03c8_init , v_init , cte_init , e\u03c8_init ) # State variables x = self . create_array_of_symbols ( 'x' , self . steps_ahead ) y = self . create_array_of_symbols ( 'y' , self . steps_ahead ) \u03c8 = self . create_array_of_symbols ( '\u03c8' , self . steps_ahead ) v = self . create_array_of_symbols ( 'v' , self . steps_ahead ) cte = self . create_array_of_symbols ( 'cte' , self . steps_ahead ) e\u03c8 = self . create_array_of_symbols ( 'e\u03c8' , self . steps_ahead ) # Actuators a = self . create_array_of_symbols ( 'a' , self . steps_ahead ) \u03b4 = self . create_array_of_symbols ( '\u03b4' , self . steps_ahead ) vars_ = ( # Symbolic arrays (but NOT actuators) * x , * y , * \u03c8 , * v , * cte , * e\u03c8 , # Symbolic arrays (actuators) * a , * \u03b4 , ) cost = 0 for t in range ( self . steps_ahead ): cost += ( # Reference state penalties self . cte_coeff * cte [ t ] ** 2 + self . epsi_coeff * e\u03c8 [ t ] ** 2 + + self . speed_coeff * ( v [ t ] - self . target_speed ) ** 2 # Actuator penalties + self . acc_coeff * a [ t ] ** 2 + self . steer_coeff * \u03b4 [ t ] ** 2 ) # Penalty for differences in consecutive actuators for t in range ( self . steps_ahead - 1 ): cost += ( self . consec_acc_coeff * ( a [ t + 1 ] - a [ t ]) ** 2 + self . consec_steer_coeff * ( \u03b4 [ t + 1 ] - \u03b4 [ t ]) ** 2 ) # Initialize constraints eq_constr = _EqualityConstraints ( self . steps_ahead , self . state_vars ) eq_constr [ 'x' ][ 0 ] = x [ 0 ] - x_init eq_constr [ 'y' ][ 0 ] = y [ 0 ] - y_init eq_constr [ '\u03c8' ][ 0 ] = \u03c8 [ 0 ] - \u03c8_init eq_constr [ 'v' ][ 0 ] = v [ 0 ] - v_init eq_constr [ 'cte' ][ 0 ] = cte [ 0 ] - cte_init eq_constr [ 'e\u03c8' ][ 0 ] = e\u03c8 [ 0 ] - e\u03c8_init for t in range ( 1 , self . steps_ahead ): curve = sum ( poly [ - ( i + 1 )] * x [ t - 1 ] ** i for i in range ( len ( poly ))) # The desired \u03c8 is equal to the derivative of the polynomial # curve at # point x[t-1] \u03c8des = sum ( poly [ - ( i + 1 )] * i * x [ t - 1 ] ** ( i - 1 ) for i in range ( 1 , len ( poly ))) eq_constr [ 'x' ][ t ] = x [ t ] - ( x [ t - 1 ] + v [ t - 1 ] * sym . cos ( \u03c8 [ t - 1 ]) * self . dt ) eq_constr [ 'y' ][ t ] = y [ t ] - ( y [ t - 1 ] + v [ t - 1 ] * sym . sin ( \u03c8 [ t - 1 ]) * self . dt ) eq_constr [ '\u03c8' ][ t ] = \u03c8 [ t ] - ( \u03c8 [ t - 1 ] - v [ t - 1 ] * \u03b4 [ t - 1 ] / self . Lf * self . dt ) eq_constr [ 'v' ][ t ] = v [ t ] - ( v [ t - 1 ] + a [ t - 1 ] * self . dt ) eq_constr [ 'cte' ][ t ] = cte [ t ] - ( curve - y [ t - 1 ] + v [ t - 1 ] * sym . sin ( e\u03c8 [ t - 1 ]) * self . dt ) eq_constr [ 'e\u03c8' ][ t ] = e\u03c8 [ t ] - ( \u03c8 [ t - 1 ] - \u03c8des - v [ t - 1 ] * \u03b4 [ t - 1 ] / self . Lf * self . dt ) # Generate actual functions from cost_func = self . generate_fun ( cost , vars_ , init , poly ) cost_grad_func = self . generate_grad ( cost , vars_ , init , poly ) constr_funcs = [] for symbol in self . state_vars : for t in range ( self . steps_ahead ): func = self . generate_fun ( eq_constr [ symbol ][ t ], vars_ , init , poly ) grad_func = self . generate_grad ( eq_constr [ symbol ][ t ], vars_ , init , poly ) constr_funcs . append ( { 'type' : 'eq' , 'fun' : func , 'jac' : grad_func , 'args' : None }, ) return cost_func , cost_grad_func , constr_funcs","title":"get_func_constraints_and_bounds()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.mpc_controller.VehicleMPCController.get_state0","text":"Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 def get_state0 ( self , v , cte , epsi , a , delta , poly ): a = a or 0 delta = delta or 0 x = np . linspace ( 0 , 1 , self . steps_ahead ) y = np . polyval ( poly , x ) psi = 0 self . state0 [: self . steps_ahead ] = x self . state0 [ self . steps_ahead : 2 * self . steps_ahead ] = y self . state0 [ 2 * self . steps_ahead : 3 * self . steps_ahead ] = psi self . state0 [ 3 * self . steps_ahead : 4 * self . steps_ahead ] = v self . state0 [ 4 * self . steps_ahead : 5 * self . steps_ahead ] = cte self . state0 [ 5 * self . steps_ahead : 6 * self . steps_ahead ] = epsi self . state0 [ 6 * self . steps_ahead : 7 * self . steps_ahead ] = a self . state0 [ 7 * self . steps_ahead : 8 * self . steps_ahead ] = delta return self . state0","title":"get_state0()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.mpc_controller.VehicleMPCController.minimize_cost","text":"Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 353 354 355 356 357 358 359 360 361 362 363 364 365 366 def minimize_cost ( self , bounds , x0 , init ): for constr_func in self . constr_funcs : constr_func [ 'args' ] = init return minimize ( fun = self . cost_func , x0 = x0 , args = init , jac = self . cost_grad_func , bounds = bounds , constraints = self . constr_funcs , method = 'SLSQP' , tol = self . tolerance , )","title":"minimize_cost()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.mpc_controller.VehicleMPCController.run_step","text":"Abstract function for run step Parameters: Name Type Description Default vehicle Vehicle new vehicle state required next_waypoint Transform next waypoint required **kwargs {} Returns: Type Description VehicleControl VehicleControl Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 def run_step ( self , vehicle : Vehicle , next_waypoint : Transform , ** kwargs ) -> VehicleControl : super ( VehicleMPCController , self ) . run_step ( vehicle , next_waypoint ) # get vehicle location (x, y) # location = self.vehicle.transform.location location = vehicle . transform . location x , y = location . x , location . y # get vehicle rotation # rotation = self.vehicle.transform.rotation rotation = vehicle . transform . rotation \u03c8 = rotation . yaw / 180 * np . pi # transform into radient cos_\u03c8 = np . cos ( \u03c8 ) sin_\u03c8 = np . sin ( \u03c8 ) # get vehicle speed # v = Vehicle.get_speed(self.vehicle) v = Vehicle . get_speed ( vehicle ) # get next waypoint location wx , wy = next_waypoint . location . x , next_waypoint . location . y # debug logging # self.logger.debug(f\"car location: ({x}, {y})\") # self.logger.debug(f\"car \u03c8: {\u03c8}\") # self.logger.debug(f\"car speed: {v}\") # self.logger.debug(f\"next waypoint: ({wx}, {wy})\") ### 3D ### # get the index of next waypoint # waypoint_index = self.get_closest_waypoint_index_3D(location, # next_waypoint.location) # # find more waypoints index to fit a polynomial # waypoint_index_shifted = waypoint_index - 2 # indeces = waypoint_index_shifted + self.steps_poly * np.arange( # self.poly_degree + 1) # indeces = indeces % self.track_DF.shape[0] # # get waypoints for polynomial fitting # pts = np.array([[self.track_DF.iloc[i][0], self.track_DF.iloc[i][ # 1]] for i in indeces]) ### 2D ### index_2D = self . get_closest_waypoint_index_2D ( location , next_waypoint . location ) index_2D_shifted = index_2D - 5 indeces_2D = index_2D_shifted + self . steps_poly * np . arange ( self . poly_degree + 1 ) indeces_2D = indeces_2D % self . pts_2D . shape [ 0 ] pts = self . pts_2D [ indeces_2D ] # self.logger.debug(f'\\nwaypoint index:\\n {index_2D}') # self.logger.debug(f'\\nindeces:\\n {indeces_2D}') # transform waypoints from world to car coorinate pts_car = VehicleMPCController . transform_into_cars_coordinate_system ( pts , x , y , cos_\u03c8 , sin_\u03c8 ) # fit the polynomial poly = np . polyfit ( pts_car [:, 0 ], pts_car [:, 1 ], self . poly_degree ) # Debug # self.logger.debug(f'\\nwaypoint index:\\n {waypoint_index}') # self.logger.debug(f'\\nindeces:\\n {indeces}') # self.logger.debug(f'\\npts for poly_fit:\\n {pts}') # self.logger.debug(f'\\npts_car:\\n {pts_car}') ########### cte = poly [ - 1 ] e\u03c8 = - np . arctan ( poly [ - 2 ]) init = ( 0 , 0 , 0 , v , cte , e\u03c8 , * poly ) self . state0 = self . get_state0 ( v , cte , e\u03c8 , self . steer , self . throttle , poly ) result = self . minimize_cost ( self . bounds , self . state0 , init ) # self.steer = -0.6 * cte - 5.5 * (cte - self.prev_cte) # self.prev_cte = cte # self.throttle = VehicleMPCController.clip_throttle(self.throttle, # v, self.target_speed) control = VehicleControl () if 'success' in result . message : self . steer = result . x [ - self . steps_ahead ] self . throttle = result . x [ - 2 * self . steps_ahead ] else : self . logger . debug ( 'Unsuccessful optimization' ) control . steering = self . steer control . throttle = self . throttle return control","title":"run_step()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.mpc_controller.VehicleMPCController.sync_data","text":"default sync data function Parameters: Name Type Description Default vehicle new vehicle state required Returns: Type Description None None Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 208 209 def sync_data ( self , vehicle ) -> None : super ( VehicleMPCController , self ) . sync_data ( vehicle = vehicle )","title":"sync_data()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.mpc_controller.VehicleMPCController.transform_into_cars_coordinate_system","text":"Source code in ROAR/roar_autonomous_system/control_module/mpc_controller.py 402 403 404 405 406 407 408 @staticmethod def transform_into_cars_coordinate_system ( pts , x , y , cos_\u03c8 , sin_\u03c8 ): diff = ( pts - [ x , y ]) pts_car = np . zeros_like ( diff ) pts_car [:, 0 ] = cos_\u03c8 * diff [:, 0 ] + sin_\u03c8 * diff [:, 1 ] pts_car [:, 1 ] = sin_\u03c8 * diff [:, 0 ] - cos_\u03c8 * diff [:, 1 ] return pts_car This module contains PID controllers to perform lateral and longitudinal control.","title":"transform_into_cars_coordinate_system()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pid_controller.OPTIMIZED_LATERAL_PID_VALUES","text":"","title":"OPTIMIZED_LATERAL_PID_VALUES"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pid_controller.PIDLateralController","text":"PIDLateralController implements lateral control using a PID.","title":"PIDLateralController"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pid_controller.PIDLateralController.__init__","text":"Constructor method. :param vehicle: actor to apply to local planner logic onto :param K_P: Proportional term :param K_D: Differential term :param K_I: Integral term :param dt: time differential in seconds Source code in ROAR/roar_autonomous_system/control_module/pid_controller.py 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 def __init__ ( self , vehicle , K_P = 1.0 , K_D = 0.0 , K_I = 0.0 , dt = 0.03 ): \"\"\" Constructor method. :param vehicle: actor to apply to local planner logic onto :param K_P: Proportional term :param K_D: Differential term :param K_I: Integral term :param dt: time differential in seconds \"\"\" self . vehicle : Vehicle = vehicle self . k_p = K_P self . k_d = K_D self . k_i = K_I self . dt = dt self . _e_buffer = deque ( maxlen = 10 )","title":"__init__()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pid_controller.PIDLateralController.run_step","text":"Execute one step of lateral control to steer the vehicle towards a certain waypoin. :param target_waypoint: :return: steering control in the range [-1, 1] where: -1 maximum steering to left +1 maximum steering to right Source code in ROAR/roar_autonomous_system/control_module/pid_controller.py 244 245 246 247 248 249 250 251 252 253 254 255 def run_step ( self , target_waypoint : Transform ) -> float : \"\"\" Execute one step of lateral control to steer the vehicle towards a certain waypoin. :param target_waypoint: :return: steering control in the range [-1, 1] where: -1 maximum steering to left +1 maximum steering to right \"\"\" return self . _pid_control ( target_waypoint = target_waypoint , vehicle_transform = self . vehicle . transform )","title":"run_step()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pid_controller.PIDLongitudinalController","text":"PIDLongitudinalController implements longitudinal control using a PID.","title":"PIDLongitudinalController"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pid_controller.PIDLongitudinalController.__init__","text":"Constructor method. :param vehicle: actor to apply to local planner logic onto :param K_P: Proportional term :param K_D: Differential term :param K_I: Integral term :param dt: time differential in seconds Source code in ROAR/roar_autonomous_system/control_module/pid_controller.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 def __init__ ( self , vehicle : Vehicle , K_P = 1.0 , K_D = 0.0 , K_I = 0.0 , dt = 0.03 ): \"\"\" Constructor method. :param vehicle: actor to apply to local planner logic onto :param K_P: Proportional term :param K_D: Differential term :param K_I: Integral term :param dt: time differential in seconds \"\"\" self . vehicle = vehicle self . _k_p = K_P self . _k_d = K_D self . _k_i = K_I self . _dt = dt self . _error_buffer = deque ( maxlen = 10 )","title":"__init__()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pid_controller.PIDLongitudinalController.run_step","text":"Execute one step of longitudinal control to reach a given target speed. :param target_speed: target speed in Km/h :return: throttle control Source code in ROAR/roar_autonomous_system/control_module/pid_controller.py 188 189 190 191 192 193 194 195 def run_step ( self , target_speed ): \"\"\" Execute one step of longitudinal control to reach a given target speed. :param target_speed: target speed in Km/h :return: throttle control \"\"\" current_speed = Vehicle . get_speed ( self . vehicle ) return self . _pid_control ( target_speed , current_speed )","title":"run_step()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pid_controller.PIDParam","text":"","title":"PIDParam"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pid_controller.PIDParam.dt","text":"","title":"dt"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pid_controller.PIDParam.K_D","text":"","title":"K_D"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pid_controller.PIDParam.K_I","text":"","title":"K_I"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pid_controller.PIDParam.K_P","text":"","title":"K_P"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pid_controller.PIDParam.__config__","text":"","title":"__config__"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pid_controller.PIDParam.__json_encoder__","text":"","title":"__json_encoder__()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pid_controller.PIDParam.default_lateral_param","text":"Source code in ROAR/roar_autonomous_system/control_module/pid_controller.py 30 31 32 @staticmethod def default_lateral_param (): return PIDParam ( K_P = 1.95 , K_D = 0.2 , K_I = 0.07 , dt = 1.0 / 20.0 )","title":"default_lateral_param()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pid_controller.PIDParam.default_longitudinal_param","text":"Source code in ROAR/roar_autonomous_system/control_module/pid_controller.py 34 35 36 @staticmethod def default_longitudinal_param (): return PIDParam ( K_P = 1 , K_D = 0 , K_I = 0.05 , dt = 1.0 / 20.0 )","title":"default_longitudinal_param()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pid_controller.VehiclePIDController","text":"VehiclePIDController is the combination of two PID controllers (lateral and longitudinal) to perform the low level control a vehicle from client side","title":"VehiclePIDController"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pid_controller.VehiclePIDController.__init__","text":"Parameters: Name Type Description Default vehicle Vehicle actor to apply to local planner logic onto required args_lateral PIDParam dictionary of arguments to set the lateral PID control required args_longitudinal PIDParam dictionary of arguments to set the longitudinal required target_speed target speedd in km/h inf max_throttle maximum throttle from, will be capped at 1 1 max_steering absolute maximum steering ranging from -1 - 1 1 Source code in ROAR/roar_autonomous_system/control_module/pid_controller.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 def __init__ ( self , vehicle : Vehicle , args_lateral : PIDParam , args_longitudinal : PIDParam , target_speed = float ( \"inf\" ), max_throttle = 1 , max_steering = 1 , ): \"\"\" Args: vehicle: actor to apply to local planner logic onto args_lateral: dictionary of arguments to set the lateral PID control args_longitudinal: dictionary of arguments to set the longitudinal target_speed: target speedd in km/h max_throttle: maximum throttle from, will be capped at 1 max_steering: absolute maximum steering ranging from -1 - 1 \"\"\" super () . __init__ ( vehicle ) self . logger = logging . getLogger ( __name__ ) self . max_throttle = max_throttle self . max_steer = max_steering self . target_speed = target_speed self . past_steering = self . vehicle . control . steering self . _lon_controller = PIDLongitudinalController ( self . vehicle , K_P = args_longitudinal . K_P , K_D = args_longitudinal . K_D , K_I = args_longitudinal . K_I , dt = args_longitudinal . dt , ) self . _lat_controller = PIDLateralController ( self . vehicle , K_P = args_lateral . K_P , K_D = args_lateral . K_D , K_I = args_lateral . K_I , dt = args_lateral . dt , ) self . logger . debug ( \"PID Controller initiated\" )","title":"__init__()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pid_controller.VehiclePIDController.run_step","text":"Execute one step of control invoking both lateral and longitudinal PID controllers to reach a target waypoint at a given target_speed. Parameters: Name Type Description Default vehicle Vehicle New vehicle state required next_waypoint Transform target location encoded as a waypoint required **kwargs {} Returns: Type Description VehicleControl Next Vehicle Control Source code in ROAR/roar_autonomous_system/control_module/pid_controller.py 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 def run_step ( self , vehicle : Vehicle , next_waypoint : Transform , ** kwargs ) -> VehicleControl : \"\"\" Execute one step of control invoking both lateral and longitudinal PID controllers to reach a target waypoint at a given target_speed. Args: vehicle: New vehicle state next_waypoint: target location encoded as a waypoint **kwargs: Returns: Next Vehicle Control \"\"\" super ( VehiclePIDController , self ) . run_step ( vehicle , next_waypoint ) curr_speed = Vehicle . get_speed ( self . vehicle ) if curr_speed < 60 : self . _lat_controller . k_d = OPTIMIZED_LATERAL_PID_VALUES [ 60 ] . K_D self . _lat_controller . k_i = OPTIMIZED_LATERAL_PID_VALUES [ 60 ] . K_I self . _lat_controller . k_p = OPTIMIZED_LATERAL_PID_VALUES [ 60 ] . K_P elif curr_speed < 100 : self . _lat_controller . k_d = OPTIMIZED_LATERAL_PID_VALUES [ 100 ] . K_D self . _lat_controller . k_i = OPTIMIZED_LATERAL_PID_VALUES [ 100 ] . K_I self . _lat_controller . k_p = OPTIMIZED_LATERAL_PID_VALUES [ 100 ] . K_P elif curr_speed < 150 : self . _lat_controller . k_d = OPTIMIZED_LATERAL_PID_VALUES [ 150 ] . K_D self . _lat_controller . k_i = OPTIMIZED_LATERAL_PID_VALUES [ 150 ] . K_I self . _lat_controller . k_p = OPTIMIZED_LATERAL_PID_VALUES [ 150 ] . K_P acceptable_target_speed = self . target_speed if abs ( self . vehicle . control . steering ) < 0.05 : acceptable_target_speed += 20 # eco boost acceleration = self . _lon_controller . run_step ( acceptable_target_speed ) current_steering = self . _lat_controller . run_step ( next_waypoint ) control = VehicleControl () if acceleration >= 0.0 : control . throttle = min ( acceleration , self . max_throttle ) # control.brake = 0.0 else : control . throttle = 0 # control.brake = min(abs(acceleration), self.max_brake) # Steering regulation: changes cannot happen abruptly, can't steer too much. if current_steering > self . past_steering + 0.1 : current_steering = self . past_steering + 0.1 elif current_steering < self . past_steering - 0.1 : current_steering = self . past_steering - 0.1 if current_steering >= 0 : steering = min ( self . max_steer , current_steering ) else : steering = max ( - self . max_steer , current_steering ) if abs ( current_steering ) > 0.03 and curr_speed > 110 : # if i am doing a sharp (>0.5) turn, i do not want to step on full gas control . throttle = - 1 control . steering = steering self . past_steering = steering return control","title":"run_step()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pid_controller.VehiclePIDController.sync_data","text":"default sync data function Parameters: Name Type Description Default vehicle new vehicle state required Returns: Type Description None None Source code in ROAR/roar_autonomous_system/control_module/pid_controller.py 161 162 163 164 def sync_data ( self , vehicle ) -> None : super ( VehiclePIDController , self ) . sync_data ( vehicle = vehicle ) self . _lon_controller . vehicle = self . vehicle self . _lat_controller . vehicle = self . vehicle","title":"sync_data()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pure_pursuit_control.LatitunalPurePursuitController","text":"","title":"LatitunalPurePursuitController"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pure_pursuit_control.LatitunalPurePursuitController.__init__","text":"Source code in ROAR/roar_autonomous_system/control_module/pure_pursuit_control.py 95 96 97 98 99 100 101 def __init__ ( self , vehicle : Vehicle , look_ahead_gain : float , look_ahead_distance : float ): self . vehicle = vehicle self . look_ahead_gain = look_ahead_gain self . look_ahead_distance = look_ahead_distance","title":"__init__()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pure_pursuit_control.LatitunalPurePursuitController.run_step","text":"Source code in ROAR/roar_autonomous_system/control_module/pure_pursuit_control.py 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 def run_step ( self , vehicle : Vehicle , next_waypoint : Transform ) -> float : self . sync ( vehicle = vehicle ) target_y = next_waypoint . location . y target_x = next_waypoint . location . x angle_difference = math . atan2 ( target_y - self . vehicle . transform . location . y , target_x - self . vehicle . transform . location . x , ) - np . radians ( self . vehicle . transform . rotation . yaw ) curr_look_forward = ( self . look_ahead_gain * Vehicle . get_speed ( vehicle = vehicle ) + self . look_ahead_distance ) lateral_difference = math . atan2 ( 2.0 * self . vehicle . wheel_base * math . sin ( angle_difference ) / curr_look_forward , 1.0 , ) return VehicleControl . clamp ( lateral_difference , - 1 , 1 )","title":"run_step()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pure_pursuit_control.LatitunalPurePursuitController.sync","text":"Source code in ROAR/roar_autonomous_system/control_module/pure_pursuit_control.py 124 125 def sync ( self , vehicle : Vehicle ): self . vehicle = vehicle","title":"sync()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pure_pursuit_control.LongitunalPurePursuitController","text":"","title":"LongitunalPurePursuitController"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pure_pursuit_control.LongitunalPurePursuitController.__init__","text":"Source code in ROAR/roar_autonomous_system/control_module/pure_pursuit_control.py 76 77 78 79 def __init__ ( self , vehicle : Vehicle , target_speed = 60 , kp = 0.1 ): self . vehicle = vehicle self . target_speed = target_speed self . kp = kp","title":"__init__()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pure_pursuit_control.LongitunalPurePursuitController.run_step","text":"Source code in ROAR/roar_autonomous_system/control_module/pure_pursuit_control.py 81 82 83 84 85 86 87 88 def run_step ( self , vehicle : Vehicle ) -> float : self . sync ( vehicle = vehicle ) return float ( VehicleControl . clamp ( self . kp * ( self . target_speed - Vehicle . get_speed ( vehicle )), 0 , 1 ) )","title":"run_step()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pure_pursuit_control.LongitunalPurePursuitController.sync","text":"Source code in ROAR/roar_autonomous_system/control_module/pure_pursuit_control.py 90 91 def sync ( self , vehicle : Vehicle ): self . vehicle = vehicle","title":"sync()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pure_pursuit_control.PurePursuitController","text":"","title":"PurePursuitController"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pure_pursuit_control.PurePursuitController.__init__","text":"Parameters: Name Type Description Default vehicle Vehicle Vehicle information required look_ahead_gain float Look ahead factor 0.1 look_ahead_distance float look ahead distance 2 target_speed desired longitudinal speed to maintain 60 Source code in ROAR/roar_autonomous_system/control_module/pure_pursuit_control.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , vehicle : Vehicle , look_ahead_gain : float = 0.1 , look_ahead_distance : float = 2 , target_speed = 60 , ): \"\"\" Args: vehicle: Vehicle information look_ahead_gain: Look ahead factor look_ahead_distance: look ahead distance target_speed: desired longitudinal speed to maintain \"\"\" super ( PurePursuitController , self ) . __init__ ( vehicle = vehicle ) self . target_speed = target_speed self . look_ahead_gain = look_ahead_gain self . look_ahead_distance = look_ahead_distance self . latitunal_controller = LatitunalPurePursuitController ( vehicle = self . vehicle , look_ahead_gain = look_ahead_gain , look_ahead_distance = look_ahead_distance , ) self . longitunal_controller = LongitunalPurePursuitController ( vehicle = self . vehicle , target_speed = target_speed )","title":"__init__()"},{"location":"code_documentations/roar_autonomous_system/controls/#ROAR.roar_autonomous_system.control_module.pure_pursuit_control.PurePursuitController.run_step","text":"run one step of Pure Pursuit Control Parameters: Name Type Description Default vehicle Vehicle current vehicle state required next_waypoint Transform Next waypoint, Transform required **kwargs {} Returns: Type Description VehicleControl Vehicle Control Source code in ROAR/roar_autonomous_system/control_module/pure_pursuit_control.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 def run_step ( self , vehicle : Vehicle , next_waypoint : Transform , ** kwargs ) -> VehicleControl : \"\"\" run one step of Pure Pursuit Control Args: vehicle: current vehicle state next_waypoint: Next waypoint, Transform **kwargs: Returns: Vehicle Control \"\"\" control = VehicleControl ( throttle = self . longitunal_controller . run_step ( vehicle = vehicle ), steering = self . latitunal_controller . run_step ( vehicle = vehicle , next_waypoint = next_waypoint ), ) return control","title":"run_step()"},{"location":"code_documentations/roar_autonomous_system/perceptions/","text":"detector \u00a4 Detector \u00a4 __init__ ( self , agent ) special \u00a4 Source code in ROAR/roar_autonomous_system/perception_module/detector.py 8 9 10 def __init__ ( self , agent : Agent ): self . agent = agent self . logger = logging . getLogger ( \"Base Detector\" ) run_step ( self ) \u00a4 Source code in ROAR/roar_autonomous_system/perception_module/detector.py 12 13 14 @abstractmethod def run_step ( self ) -> Any : return None ground_plane_point_cloud_detector \u00a4 GroundPlanePointCloudDetector \u00a4 __init__ ( self , max_ground_height_relative_to_vehcile = 5 , knn = 200 , std_ratio = 2 , nb_neighbors = 10 , ** kwargs ) special \u00a4 Source code in ROAR/roar_autonomous_system/perception_module/ground_plane_point_cloud_detector.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def __init__ ( self , max_ground_height_relative_to_vehcile = 5 , knn = 200 , std_ratio = 2 , nb_neighbors = 10 , ** kwargs ): \"\"\" Args: max_detectable_distance: maximum detectable distance in km depth_scaling_factor: scaling depth back to world scale. 1000 m = 1 km **kwargs: \"\"\" super () . __init__ ( ** kwargs ) self . logger = logging . getLogger ( \"Point Cloud Detector\" ) self . max_ground_height_relative_to_vehcile = max_ground_height_relative_to_vehcile self . knn = knn self . std_ratio = std_ratio self . nb_neighbors = nb_neighbors self . counter = 0 run_step ( self ) \u00a4 Source code in ROAR/roar_autonomous_system/perception_module/ground_plane_point_cloud_detector.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 def run_step ( self ) -> np . ndarray : points_3d = self . calculate_world_cords () # (Nx3) pcd = o3d . geometry . PointCloud () pcd . points = o3d . utility . Vector3dVector ( points_3d ) # - np.mean(points_3d, axis=0)) pcd . estimate_normals () pcd_tree = o3d . geometry . KDTreeFlann ( pcd ) # build KD tree for fast computation [ k , idx , _ ] = pcd_tree . search_knn_vector_3d ( self . agent . vehicle . transform . location . to_array (), knn = self . knn ) # find points around me points_near_me = np . asarray ( pcd . points )[ idx , :] # 200 x 3 normals = np . asarray ( pcd . normals ) u , s , vh = np . linalg . svd ( points_near_me , full_matrices = False ) # use svd to find normals of points avg_points_near_me_normal = vh [ 2 , :] abs_diff = np . linalg . norm ( normals - avg_points_near_me_normal , axis = 1 ) # anything below avg is plane planes = points_3d [ abs_diff < np . mean ( abs_diff )] ground = planes [ planes [:, 2 ] < self . agent . vehicle . transform . location . z + self . max_ground_height_relative_to_vehcile ] pcd . points = o3d . utility . Vector3dVector ( ground ) # - np.mean(planes, axis=0)) pcd , ids = pcd . remove_statistical_outlier ( nb_neighbors = self . nb_neighbors , std_ratio = self . std_ratio ) self . pcd . points = o3d . utility . Vector3dVector ( np . asarray ( points_3d ) - np . mean ( points_3d , axis = 0 )) if self . counter == 0 : self . vis . create_window ( window_name = \"Open3d\" , width = 400 , height = 400 ) self . vis . add_geometry ( self . pcd ) render_option : o3d . visualization . RenderOption = self . vis . get_render_option () render_option . show_coordinate_frame = True else : self . vis . update_geometry ( self . pcd ) render_option : o3d . visualization . RenderOption = self . vis . get_render_option () render_option . show_coordinate_frame = True self . vis . poll_events () self . vis . update_renderer () self . counter += 1 return np . asarray ( pcd . points ) point_cloud_detector \u00a4 PointCloudDetector \u00a4 __init__ ( self , max_detectable_distance = 0.05 , depth_scaling_factor = 1000 , max_points_to_convert = 10000 , ** kwargs ) special \u00a4 Parameters: Name Type Description Default max_detectable_distance maximum detectable distance in km 0.05 depth_scaling_factor scaling depth back to world scale. 1000 m = 1 km 1000 **kwargs {} Source code in ROAR/roar_autonomous_system/perception_module/point_cloud_detector.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 def __init__ ( self , max_detectable_distance = 0.05 , depth_scaling_factor = 1000 , max_points_to_convert = 10000 , ** kwargs ): \"\"\" Args: max_detectable_distance: maximum detectable distance in km depth_scaling_factor: scaling depth back to world scale. 1000 m = 1 km **kwargs: \"\"\" super () . __init__ ( ** kwargs ) self . max_detectable_distance = max_detectable_distance self . depth_scaling_factor = depth_scaling_factor self . max_points_to_convert = max_points_to_convert self . logger = logging . getLogger ( \"Point Cloud Detector\" ) self . pcd : o3d . geometry . PointCloud = o3d . geometry . PointCloud () self . vis = o3d . visualization . Visualizer () self . counter = 0 calculate_world_cords ( self ) \u00a4 Source code in ROAR/roar_autonomous_system/perception_module/point_cloud_detector.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 def calculate_world_cords ( self ): depth_img = self . agent . front_depth_camera . data . copy () coords = np . where ( depth_img < self . max_detectable_distance ) indices_to_select = np . random . choice ( np . shape ( coords )[ 1 ], size = min ([ self . max_points_to_convert , np . shape ( coords )[ 1 ]]), replace = False ) coords = ( coords [ 0 ][ indices_to_select ], coords [ 1 ][ indices_to_select ] ) raw_p2d = np . reshape ( self . _pix2xyz ( depth_img = depth_img , i = coords [ 0 ], j = coords [ 1 ]), ( 3 , np . shape ( coords )[ 1 ])) . T cords_y_minus_z_x = np . linalg . inv ( self . agent . front_depth_camera . intrinsics_matrix ) @ raw_p2d . T cords_xyz_1 = np . vstack ([ cords_y_minus_z_x [ 2 , :], cords_y_minus_z_x [ 0 , :], - cords_y_minus_z_x [ 1 , :], np . ones (( 1 , np . shape ( cords_y_minus_z_x )[ 1 ])) ]) points : np . ndarray = self . agent . vehicle . transform . get_matrix () @ self . agent . front_depth_camera . transform . get_matrix () @ cords_xyz_1 points = points . T [:, : 3 ] return points run_step ( self ) \u00a4 Source code in ROAR/roar_autonomous_system/perception_module/point_cloud_detector.py 30 31 32 def run_step ( self ) -> Optional [ np . ndarray ]: points_3d = self . calculate_world_cords () # (Nx3) return points_3d semantic_segmentation_detector \u00a4 SemanticSegmentationDetector \u00a4 GROUND \u00a4 OBSTACLE \u00a4 SKY \u00a4 __init__ ( self , sky_level = 0.9 , t = 0.05 , del_ang = 0.2 , fit_type = 'exp' , ** kwargs ) special \u00a4 Source code in ROAR/roar_autonomous_system/perception_module/semantic_segmentation_detector.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 def __init__ ( self , sky_level = 0.9 , t = 0.05 , del_ang = 0.2 , fit_type = 'exp' , ** kwargs ): super () . __init__ ( ** kwargs ) self . logger = logging . getLogger ( \"Ground Plane Detector\" ) self . sky_level = sky_level self . thresh = t self . fit_type = fit_type self . del_ang = del_ang self . roll_ang = 0 self . rot_axis = [ 0 , 0 , 1 ] self . orig_preds = None self . preds = None self . curr_segmentation : Optional [ np . ndarray ] = None self . logger . info ( \"Ground Plane Detector Initiated\" ) convert_to_log ( x ) staticmethod \u00a4 Source code in ROAR/roar_autonomous_system/perception_module/semantic_segmentation_detector.py 33 34 35 @staticmethod def convert_to_log ( x ): return np . clip ( 1 + np . log ( x + 1e-10 ) / 5.70378 , 0.005 , 1.0 ) get_roll_stats ( self , depth_image ) \u00a4 Source code in ROAR/roar_autonomous_system/perception_module/semantic_segmentation_detector.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 def get_roll_stats ( self , depth_image ): xyz = self . img_to_world ( depth_image ) . T xyz_samp = xyz [ np . random . choice ( xyz . shape [ 0 ], 400 , replace = False ), :] u , s , vt = np . linalg . svd ( xyz_samp - xyz_samp . mean ()) reg = vt [ 2 ] no_y = np . array ( reg , copy = True ) no_y [ 1 ] = 0 nvt , nx = np . linalg . norm ( reg ), np . linalg . norm ( no_y ) cos_ang = np . dot ( reg , no_y ) / ( nvt * nx ) unitcross = lambda a , b : np . cross ( a , b ) / np . linalg . norm ( np . cross ( a , b )) rot_axis = unitcross ( vt [ 2 ], no_y ) return np . arccos ( cos_ang ), rot_axis # radians gpd_mesh ( self , depth_image ) \u00a4 Source code in ROAR/roar_autonomous_system/perception_module/semantic_segmentation_detector.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 def gpd_mesh ( self , depth_image ): xs = [] data = [] max_depth = 0 for i in range ( depth_image . shape [ 0 ] - 1 , - 1 , - 1 ): j = np . argmax ( depth_image [ i , :]) d = depth_image [ i ][ j ] if d > 0.3 : break if d > max_depth and d > 0.01 : max_depth = d xs . append ( i ) data . append ( d ) xs = np . array ( xs [:: - 1 ], dtype = np . float64 ) data = np . array ( data [:: - 1 ], dtype = np . float64 ) if self . fit_type == 'lsq' : a , b , c , d = _Leastsq_Exp . fit ( xs / xs . max (), data ) pred_func = _Leastsq_Exp . construct_f ( a , b , c , d ) rows = np . meshgrid ( np . arange ( depth_image . shape [ 1 ]), np . arange ( depth_image . shape [ 0 ]) )[ 1 ] preds = pred_func ( rows / rows . max ()) preds [ preds > 1 ] = 0 return preds else : a , b , c , p , q = _Exponential_Model . fit ( xs , data ) pred_func = _Exponential_Model . construct_f ( a , b , c , p , q ) rows = np . meshgrid ( np . arange ( depth_image . shape [ 1 ]), np . arange ( depth_image . shape [ 0 ]) )[ 1 ] preds = pred_func ( rows ) preds [ preds > 1 ] = 0 return preds img_to_world ( self , depth_img , sky_level = 0.2 , depth_scaling_factor = 1000 ) \u00a4 Source code in ROAR/roar_autonomous_system/perception_module/semantic_segmentation_detector.py 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 def img_to_world ( self , depth_img , sky_level = 0.2 , depth_scaling_factor = 1000 ) -> np . ndarray : # (Intrinsic) K Matrix intrinsics_matrix = self . agent . front_depth_camera . intrinsics_matrix # get a 2 x N array for their indices bool_mat3 = ( 0.1 < depth_img ) * ( depth_img < sky_level ) # bool_mat2 = 0.1 < depth_img # bool_mat3 = bool_mat * bool_mat2 ground_loc = np . where ( bool_mat3 ) depth_val = depth_img [ bool_mat3 ] * depth_scaling_factor ground_loc = ground_loc * depth_val # compute raw_points raw_points = np . vstack ([ ground_loc , depth_val ]) # convert to cords_y_minus_z_x return np . linalg . inv ( intrinsics_matrix ) @ raw_points output_gpd ( self , d_frame ) \u00a4 Source code in ROAR/roar_autonomous_system/perception_module/semantic_segmentation_detector.py 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 def output_gpd ( self , d_frame ): # first im going to find out where is the sky sky = np . where ( d_frame > self . sky_level ) # then im going to find out where is the ground ground = np . where ( np . abs ( d_frame - self . preds ) < self . thresh ) result = np . zeros ( shape = ( d_frame . shape [ 0 ], d_frame . shape [ 1 ], 3 )) result [ ground ] = self . GROUND result [ sky ] = self . SKY # result = result.astype('uint8') # # try: # # new_roll_ang, self.rot_axis = self.get_roll_stats(d_frame) # this method is pretty slow # # if np.abs(self.roll_ang - new_roll_ang) > self.del_ang: # # print(f\"Recalibrating {self.agent.time_counter}\") # # self.roll_ang = new_roll_ang # # self.preds = self.roll_frame(self.orig_preds, self.roll_ang, -1 * self.rot_axis) # # except Exception as e: # # self.logger.error(f\"Failed to compute output: {e}\") # # result = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY) # # img = cv2.threshold(result, 127, 255, cv2.THRESH_BINARY)[1] # ret, thresh = cv2.threshold(result, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU) # # print(np.shape(img)) # # num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(image=thresh, connectivity=8,ltype=cv2.CV_16U) # img= (600 x 800) # _, labels = cv2.connectedComponents(image=thresh) # indicies = np.where(labels == 2) # print(np.shape(indicies)) # # # cv2.imshow(\"segmented\", result) # cv2.waitKey(1) return result reg_img_to_world ( self , depth_img , sky_level = 0.9 , depth_scaling_factor = 1000 ) \u00a4 Source code in ROAR/roar_autonomous_system/perception_module/semantic_segmentation_detector.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 def reg_img_to_world ( self , depth_img , sky_level = 0.9 , depth_scaling_factor = 1000 ) -> np . ndarray : # (Intrinsic) K Matrix intrinsics_matrix = self . agent . front_depth_camera . intrinsics_matrix # get a 2 x N array for their indices bool_mat = depth_img > ( depth_img . min () - 1 ) ground_loc = np . where ( bool_mat ) depth_val = depth_img [ bool_mat ] * depth_scaling_factor ground_loc = ground_loc * depth_val # compute raw_points raw_points = np . vstack ([ ground_loc , depth_val ]) return np . linalg . inv ( intrinsics_matrix ) @ raw_points roll_frame ( self , depth_image , ang , rot_axis , no_axis = False ) \u00a4 Source code in ROAR/roar_autonomous_system/perception_module/semantic_segmentation_detector.py 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 def roll_frame ( self , depth_image , ang , rot_axis , no_axis = False ): if no_axis : return depth_image xyz = self . reg_img_to_world ( depth_image ) . T xyz_mean = xyz . mean ( axis = 0 ) xyz = xyz - xyz_mean cos_ang = np . cos ( ang ) x , y , z = rot_axis c = cos_ang s = np . sqrt ( 1 - c * c ) C = 1 - c rmat = np . array ([[ x * x * C + c , x * y * C - z * s , x * z * C + y * s ], [ y * x * C + z * s , y * y * C + c , y * z * C - x * s ], [ z * x * C - y * s , z * y * C + x * s , z * z * C + c ]]) rot_xyz = rmat @ ( xyz . T ) rot_xyz = rot_xyz . T + xyz_mean return rot_xyz [:, 2 ] . reshape ( depth_image . shape ) / 1000 run_step ( self ) \u00a4 Source code in ROAR/roar_autonomous_system/perception_module/semantic_segmentation_detector.py 37 38 39 40 41 42 43 44 def run_step ( self ) -> Any : logged_depth = self . convert_to_log ( self . agent . front_depth_camera . data . copy ()) if self . orig_preds is None or self . preds is None : self . orig_preds = self . gpd_mesh ( logged_depth ) self . preds = np . copy ( self . orig_preds ) self . logger . debug ( \"Ground Plane Preds Computed\" ) else : self . curr_segmentation = self . output_gpd ( logged_depth )","title":"Perception"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.detector","text":"","title":"detector"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.detector.Detector","text":"","title":"Detector"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.detector.Detector.__init__","text":"Source code in ROAR/roar_autonomous_system/perception_module/detector.py 8 9 10 def __init__ ( self , agent : Agent ): self . agent = agent self . logger = logging . getLogger ( \"Base Detector\" )","title":"__init__()"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.detector.Detector.run_step","text":"Source code in ROAR/roar_autonomous_system/perception_module/detector.py 12 13 14 @abstractmethod def run_step ( self ) -> Any : return None","title":"run_step()"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.ground_plane_point_cloud_detector","text":"","title":"ground_plane_point_cloud_detector"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.ground_plane_point_cloud_detector.GroundPlanePointCloudDetector","text":"","title":"GroundPlanePointCloudDetector"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.ground_plane_point_cloud_detector.GroundPlanePointCloudDetector.__init__","text":"Source code in ROAR/roar_autonomous_system/perception_module/ground_plane_point_cloud_detector.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def __init__ ( self , max_ground_height_relative_to_vehcile = 5 , knn = 200 , std_ratio = 2 , nb_neighbors = 10 , ** kwargs ): \"\"\" Args: max_detectable_distance: maximum detectable distance in km depth_scaling_factor: scaling depth back to world scale. 1000 m = 1 km **kwargs: \"\"\" super () . __init__ ( ** kwargs ) self . logger = logging . getLogger ( \"Point Cloud Detector\" ) self . max_ground_height_relative_to_vehcile = max_ground_height_relative_to_vehcile self . knn = knn self . std_ratio = std_ratio self . nb_neighbors = nb_neighbors self . counter = 0","title":"__init__()"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.ground_plane_point_cloud_detector.GroundPlanePointCloudDetector.run_step","text":"Source code in ROAR/roar_autonomous_system/perception_module/ground_plane_point_cloud_detector.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 def run_step ( self ) -> np . ndarray : points_3d = self . calculate_world_cords () # (Nx3) pcd = o3d . geometry . PointCloud () pcd . points = o3d . utility . Vector3dVector ( points_3d ) # - np.mean(points_3d, axis=0)) pcd . estimate_normals () pcd_tree = o3d . geometry . KDTreeFlann ( pcd ) # build KD tree for fast computation [ k , idx , _ ] = pcd_tree . search_knn_vector_3d ( self . agent . vehicle . transform . location . to_array (), knn = self . knn ) # find points around me points_near_me = np . asarray ( pcd . points )[ idx , :] # 200 x 3 normals = np . asarray ( pcd . normals ) u , s , vh = np . linalg . svd ( points_near_me , full_matrices = False ) # use svd to find normals of points avg_points_near_me_normal = vh [ 2 , :] abs_diff = np . linalg . norm ( normals - avg_points_near_me_normal , axis = 1 ) # anything below avg is plane planes = points_3d [ abs_diff < np . mean ( abs_diff )] ground = planes [ planes [:, 2 ] < self . agent . vehicle . transform . location . z + self . max_ground_height_relative_to_vehcile ] pcd . points = o3d . utility . Vector3dVector ( ground ) # - np.mean(planes, axis=0)) pcd , ids = pcd . remove_statistical_outlier ( nb_neighbors = self . nb_neighbors , std_ratio = self . std_ratio ) self . pcd . points = o3d . utility . Vector3dVector ( np . asarray ( points_3d ) - np . mean ( points_3d , axis = 0 )) if self . counter == 0 : self . vis . create_window ( window_name = \"Open3d\" , width = 400 , height = 400 ) self . vis . add_geometry ( self . pcd ) render_option : o3d . visualization . RenderOption = self . vis . get_render_option () render_option . show_coordinate_frame = True else : self . vis . update_geometry ( self . pcd ) render_option : o3d . visualization . RenderOption = self . vis . get_render_option () render_option . show_coordinate_frame = True self . vis . poll_events () self . vis . update_renderer () self . counter += 1 return np . asarray ( pcd . points )","title":"run_step()"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.point_cloud_detector","text":"","title":"point_cloud_detector"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.point_cloud_detector.PointCloudDetector","text":"","title":"PointCloudDetector"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.point_cloud_detector.PointCloudDetector.__init__","text":"Parameters: Name Type Description Default max_detectable_distance maximum detectable distance in km 0.05 depth_scaling_factor scaling depth back to world scale. 1000 m = 1 km 1000 **kwargs {} Source code in ROAR/roar_autonomous_system/perception_module/point_cloud_detector.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 def __init__ ( self , max_detectable_distance = 0.05 , depth_scaling_factor = 1000 , max_points_to_convert = 10000 , ** kwargs ): \"\"\" Args: max_detectable_distance: maximum detectable distance in km depth_scaling_factor: scaling depth back to world scale. 1000 m = 1 km **kwargs: \"\"\" super () . __init__ ( ** kwargs ) self . max_detectable_distance = max_detectable_distance self . depth_scaling_factor = depth_scaling_factor self . max_points_to_convert = max_points_to_convert self . logger = logging . getLogger ( \"Point Cloud Detector\" ) self . pcd : o3d . geometry . PointCloud = o3d . geometry . PointCloud () self . vis = o3d . visualization . Visualizer () self . counter = 0","title":"__init__()"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.point_cloud_detector.PointCloudDetector.calculate_world_cords","text":"Source code in ROAR/roar_autonomous_system/perception_module/point_cloud_detector.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 def calculate_world_cords ( self ): depth_img = self . agent . front_depth_camera . data . copy () coords = np . where ( depth_img < self . max_detectable_distance ) indices_to_select = np . random . choice ( np . shape ( coords )[ 1 ], size = min ([ self . max_points_to_convert , np . shape ( coords )[ 1 ]]), replace = False ) coords = ( coords [ 0 ][ indices_to_select ], coords [ 1 ][ indices_to_select ] ) raw_p2d = np . reshape ( self . _pix2xyz ( depth_img = depth_img , i = coords [ 0 ], j = coords [ 1 ]), ( 3 , np . shape ( coords )[ 1 ])) . T cords_y_minus_z_x = np . linalg . inv ( self . agent . front_depth_camera . intrinsics_matrix ) @ raw_p2d . T cords_xyz_1 = np . vstack ([ cords_y_minus_z_x [ 2 , :], cords_y_minus_z_x [ 0 , :], - cords_y_minus_z_x [ 1 , :], np . ones (( 1 , np . shape ( cords_y_minus_z_x )[ 1 ])) ]) points : np . ndarray = self . agent . vehicle . transform . get_matrix () @ self . agent . front_depth_camera . transform . get_matrix () @ cords_xyz_1 points = points . T [:, : 3 ] return points","title":"calculate_world_cords()"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.point_cloud_detector.PointCloudDetector.run_step","text":"Source code in ROAR/roar_autonomous_system/perception_module/point_cloud_detector.py 30 31 32 def run_step ( self ) -> Optional [ np . ndarray ]: points_3d = self . calculate_world_cords () # (Nx3) return points_3d","title":"run_step()"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.semantic_segmentation_detector","text":"","title":"semantic_segmentation_detector"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.semantic_segmentation_detector.SemanticSegmentationDetector","text":"","title":"SemanticSegmentationDetector"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.semantic_segmentation_detector.SemanticSegmentationDetector.GROUND","text":"","title":"GROUND"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.semantic_segmentation_detector.SemanticSegmentationDetector.OBSTACLE","text":"","title":"OBSTACLE"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.semantic_segmentation_detector.SemanticSegmentationDetector.SKY","text":"","title":"SKY"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.semantic_segmentation_detector.SemanticSegmentationDetector.__init__","text":"Source code in ROAR/roar_autonomous_system/perception_module/semantic_segmentation_detector.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 def __init__ ( self , sky_level = 0.9 , t = 0.05 , del_ang = 0.2 , fit_type = 'exp' , ** kwargs ): super () . __init__ ( ** kwargs ) self . logger = logging . getLogger ( \"Ground Plane Detector\" ) self . sky_level = sky_level self . thresh = t self . fit_type = fit_type self . del_ang = del_ang self . roll_ang = 0 self . rot_axis = [ 0 , 0 , 1 ] self . orig_preds = None self . preds = None self . curr_segmentation : Optional [ np . ndarray ] = None self . logger . info ( \"Ground Plane Detector Initiated\" )","title":"__init__()"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.semantic_segmentation_detector.SemanticSegmentationDetector.convert_to_log","text":"Source code in ROAR/roar_autonomous_system/perception_module/semantic_segmentation_detector.py 33 34 35 @staticmethod def convert_to_log ( x ): return np . clip ( 1 + np . log ( x + 1e-10 ) / 5.70378 , 0.005 , 1.0 )","title":"convert_to_log()"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.semantic_segmentation_detector.SemanticSegmentationDetector.get_roll_stats","text":"Source code in ROAR/roar_autonomous_system/perception_module/semantic_segmentation_detector.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 def get_roll_stats ( self , depth_image ): xyz = self . img_to_world ( depth_image ) . T xyz_samp = xyz [ np . random . choice ( xyz . shape [ 0 ], 400 , replace = False ), :] u , s , vt = np . linalg . svd ( xyz_samp - xyz_samp . mean ()) reg = vt [ 2 ] no_y = np . array ( reg , copy = True ) no_y [ 1 ] = 0 nvt , nx = np . linalg . norm ( reg ), np . linalg . norm ( no_y ) cos_ang = np . dot ( reg , no_y ) / ( nvt * nx ) unitcross = lambda a , b : np . cross ( a , b ) / np . linalg . norm ( np . cross ( a , b )) rot_axis = unitcross ( vt [ 2 ], no_y ) return np . arccos ( cos_ang ), rot_axis # radians","title":"get_roll_stats()"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.semantic_segmentation_detector.SemanticSegmentationDetector.gpd_mesh","text":"Source code in ROAR/roar_autonomous_system/perception_module/semantic_segmentation_detector.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 def gpd_mesh ( self , depth_image ): xs = [] data = [] max_depth = 0 for i in range ( depth_image . shape [ 0 ] - 1 , - 1 , - 1 ): j = np . argmax ( depth_image [ i , :]) d = depth_image [ i ][ j ] if d > 0.3 : break if d > max_depth and d > 0.01 : max_depth = d xs . append ( i ) data . append ( d ) xs = np . array ( xs [:: - 1 ], dtype = np . float64 ) data = np . array ( data [:: - 1 ], dtype = np . float64 ) if self . fit_type == 'lsq' : a , b , c , d = _Leastsq_Exp . fit ( xs / xs . max (), data ) pred_func = _Leastsq_Exp . construct_f ( a , b , c , d ) rows = np . meshgrid ( np . arange ( depth_image . shape [ 1 ]), np . arange ( depth_image . shape [ 0 ]) )[ 1 ] preds = pred_func ( rows / rows . max ()) preds [ preds > 1 ] = 0 return preds else : a , b , c , p , q = _Exponential_Model . fit ( xs , data ) pred_func = _Exponential_Model . construct_f ( a , b , c , p , q ) rows = np . meshgrid ( np . arange ( depth_image . shape [ 1 ]), np . arange ( depth_image . shape [ 0 ]) )[ 1 ] preds = pred_func ( rows ) preds [ preds > 1 ] = 0 return preds","title":"gpd_mesh()"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.semantic_segmentation_detector.SemanticSegmentationDetector.img_to_world","text":"Source code in ROAR/roar_autonomous_system/perception_module/semantic_segmentation_detector.py 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 def img_to_world ( self , depth_img , sky_level = 0.2 , depth_scaling_factor = 1000 ) -> np . ndarray : # (Intrinsic) K Matrix intrinsics_matrix = self . agent . front_depth_camera . intrinsics_matrix # get a 2 x N array for their indices bool_mat3 = ( 0.1 < depth_img ) * ( depth_img < sky_level ) # bool_mat2 = 0.1 < depth_img # bool_mat3 = bool_mat * bool_mat2 ground_loc = np . where ( bool_mat3 ) depth_val = depth_img [ bool_mat3 ] * depth_scaling_factor ground_loc = ground_loc * depth_val # compute raw_points raw_points = np . vstack ([ ground_loc , depth_val ]) # convert to cords_y_minus_z_x return np . linalg . inv ( intrinsics_matrix ) @ raw_points","title":"img_to_world()"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.semantic_segmentation_detector.SemanticSegmentationDetector.output_gpd","text":"Source code in ROAR/roar_autonomous_system/perception_module/semantic_segmentation_detector.py 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 def output_gpd ( self , d_frame ): # first im going to find out where is the sky sky = np . where ( d_frame > self . sky_level ) # then im going to find out where is the ground ground = np . where ( np . abs ( d_frame - self . preds ) < self . thresh ) result = np . zeros ( shape = ( d_frame . shape [ 0 ], d_frame . shape [ 1 ], 3 )) result [ ground ] = self . GROUND result [ sky ] = self . SKY # result = result.astype('uint8') # # try: # # new_roll_ang, self.rot_axis = self.get_roll_stats(d_frame) # this method is pretty slow # # if np.abs(self.roll_ang - new_roll_ang) > self.del_ang: # # print(f\"Recalibrating {self.agent.time_counter}\") # # self.roll_ang = new_roll_ang # # self.preds = self.roll_frame(self.orig_preds, self.roll_ang, -1 * self.rot_axis) # # except Exception as e: # # self.logger.error(f\"Failed to compute output: {e}\") # # result = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY) # # img = cv2.threshold(result, 127, 255, cv2.THRESH_BINARY)[1] # ret, thresh = cv2.threshold(result, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU) # # print(np.shape(img)) # # num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(image=thresh, connectivity=8,ltype=cv2.CV_16U) # img= (600 x 800) # _, labels = cv2.connectedComponents(image=thresh) # indicies = np.where(labels == 2) # print(np.shape(indicies)) # # # cv2.imshow(\"segmented\", result) # cv2.waitKey(1) return result","title":"output_gpd()"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.semantic_segmentation_detector.SemanticSegmentationDetector.reg_img_to_world","text":"Source code in ROAR/roar_autonomous_system/perception_module/semantic_segmentation_detector.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 def reg_img_to_world ( self , depth_img , sky_level = 0.9 , depth_scaling_factor = 1000 ) -> np . ndarray : # (Intrinsic) K Matrix intrinsics_matrix = self . agent . front_depth_camera . intrinsics_matrix # get a 2 x N array for their indices bool_mat = depth_img > ( depth_img . min () - 1 ) ground_loc = np . where ( bool_mat ) depth_val = depth_img [ bool_mat ] * depth_scaling_factor ground_loc = ground_loc * depth_val # compute raw_points raw_points = np . vstack ([ ground_loc , depth_val ]) return np . linalg . inv ( intrinsics_matrix ) @ raw_points","title":"reg_img_to_world()"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.semantic_segmentation_detector.SemanticSegmentationDetector.roll_frame","text":"Source code in ROAR/roar_autonomous_system/perception_module/semantic_segmentation_detector.py 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 def roll_frame ( self , depth_image , ang , rot_axis , no_axis = False ): if no_axis : return depth_image xyz = self . reg_img_to_world ( depth_image ) . T xyz_mean = xyz . mean ( axis = 0 ) xyz = xyz - xyz_mean cos_ang = np . cos ( ang ) x , y , z = rot_axis c = cos_ang s = np . sqrt ( 1 - c * c ) C = 1 - c rmat = np . array ([[ x * x * C + c , x * y * C - z * s , x * z * C + y * s ], [ y * x * C + z * s , y * y * C + c , y * z * C - x * s ], [ z * x * C - y * s , z * y * C + x * s , z * z * C + c ]]) rot_xyz = rmat @ ( xyz . T ) rot_xyz = rot_xyz . T + xyz_mean return rot_xyz [:, 2 ] . reshape ( depth_image . shape ) / 1000","title":"roll_frame()"},{"location":"code_documentations/roar_autonomous_system/perceptions/#ROAR.roar_autonomous_system.perception_module.semantic_segmentation_detector.SemanticSegmentationDetector.run_step","text":"Source code in ROAR/roar_autonomous_system/perception_module/semantic_segmentation_detector.py 37 38 39 40 41 42 43 44 def run_step ( self ) -> Any : logged_depth = self . convert_to_log ( self . agent . front_depth_camera . data . copy ()) if self . orig_preds is None or self . preds is None : self . orig_preds = self . gpd_mesh ( logged_depth ) self . preds = np . copy ( self . orig_preds ) self . logger . debug ( \"Ground Plane Preds Computed\" ) else : self . curr_segmentation = self . output_gpd ( logged_depth )","title":"run_step()"},{"location":"code_documentations/roar_autonomous_system/visualizations/","text":"Visualizer \u00a4 GREEN \u00a4 GROUND \u00a4 __init__ ( self , agent , occupancy_grid_map = None , semantic_segmentation_detector = None , point_cloud_detector = None ) special \u00a4 Source code in ROAR/roar_autonomous_system/visualization_module/visualizer.py 20 21 22 23 24 25 26 27 28 29 def __init__ ( self , agent : Agent , occupancy_grid_map : Optional [ OccupancyGridMap ] = None , semantic_segmentation_detector : Optional [ SemanticSegmentationDetector ] = None , point_cloud_detector : Optional [ PointCloudDetector ] = None ): self . logger = logging . getLogger ( __name__ ) self . agent = agent self . occupancy_grid_map = occupancy_grid_map self . semantic_segmentation_detector = semantic_segmentation_detector self . point_cloud_detector = point_cloud_detector calculate_img_pos ( self , waypoint_transform , camera ) \u00a4 Calculate the 2D image coordinate from 3D world space Parameters: Name Type Description Default camera Camera required waypoint_transform Transform Desired point in 3D world space required Returns: Type Description ndarray Array if integers [X, Y, depth] Source code in ROAR/roar_autonomous_system/visualization_module/visualizer.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 @deprecated ( reason = \"Will no longer support single image to world calculation.\" ) def calculate_img_pos ( self , waypoint_transform : Transform , camera : Camera ) -> np . ndarray : \"\"\" Calculate the 2D image coordinate from 3D world space Args: camera: waypoint_transform: Desired point in 3D world space Returns: Array if integers [X, Y, depth] \"\"\" waypoint_location = waypoint_transform . location . to_array () # [x, y, z] waypoint_location = np . concatenate ( [ waypoint_location , [ 1 ]] ) # 4 x 1 array [X, Y, Z, 1] veh_cam_matrix = camera . transform . get_matrix () # 4 x 4 world_veh_matrix = self . agent . vehicle . transform . get_matrix () # 4 x 4 world_cam_matrix = np . linalg . inv ( np . dot ( world_veh_matrix , veh_cam_matrix )) cords_xyz = world_cam_matrix @ waypoint_location cords_y_minus_z_x = np . array ([ cords_xyz [ 1 ], - cords_xyz [ 2 ], cords_xyz [ 0 ]]) raw_p2d = camera . intrinsics_matrix @ cords_y_minus_z_x cam_cords = np . array ( [ raw_p2d [ 0 ] / raw_p2d [ 2 ], raw_p2d [ 1 ] / raw_p2d [ 2 ], raw_p2d [ 2 ]] ) return np . round ( cam_cords , 0 ) . astype ( np . int64 ) show_birds_eye_visualization ( self , focus_on_vehicle = True , view_size = 200 ) \u00a4 Source code in ROAR/roar_autonomous_system/visualization_module/visualizer.py 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 def show_birds_eye_visualization ( self , focus_on_vehicle : bool = True , view_size : int = 200 ): if self . occupancy_grid_map is None : self . logger . error ( \"No Occupancy Grid Map is connected\" ) else : if focus_on_vehicle : occu_cord = self . occupancy_grid_map . location_to_occu_cord ( location = self . agent . vehicle . transform . location ) map_copy = self . occupancy_grid_map . map . copy () x , y = occu_cord [ 0 ] map_copy [ y - self . occupancy_grid_map . vehicle_height // 2 : y + self . occupancy_grid_map . vehicle_height // 2 , x - self . occupancy_grid_map . vehicle_width // 2 : x + self . occupancy_grid_map . vehicle_width // 2 ] = 0 cv2 . imshow ( \"Occupancy Grid Map\" , map_copy [ y - view_size // 2 : y + view_size // 2 :, x - view_size // 2 : x + view_size // 2 ]) else : cv2 . imshow ( \"Occupancy Grid Map\" , self . occupancy_grid_map . map ) cv2 . waitKey ( 1 ) show_first_person_visualization ( self , show_num_waypoints = 0 , show_semantic_segmentation_obstacle = False , show_semantic_segmentation_sky = False , show_semantic_segmentation_ground = False , show_point_cloud_ground = False , ground_points = None ) \u00a4 Source code in ROAR/roar_autonomous_system/visualization_module/visualizer.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 def show_first_person_visualization ( self , show_num_waypoints : int = 0 , show_semantic_segmentation_obstacle : bool = False , show_semantic_segmentation_sky : bool = False , show_semantic_segmentation_ground : bool = False , show_point_cloud_ground : bool = False , ground_points : Optional [ np . ndarray ] = None ): rgb_img = self . agent . front_rgb_camera . data . copy () if show_semantic_segmentation_sky or show_semantic_segmentation_obstacle or show_semantic_segmentation_ground : if self . semantic_segmentation_detector is not None and \\ self . semantic_segmentation_detector . curr_segmentation is not None : if show_semantic_segmentation_sky : mask = np . all ( self . semantic_segmentation_detector . curr_segmentation == self . semantic_segmentation_detector . SKY , axis =- 1 ) rgb_img [ mask ] = self . semantic_segmentation_detector . SKY if show_semantic_segmentation_obstacle : mask = np . all ( self . semantic_segmentation_detector . curr_segmentation == self . semantic_segmentation_detector . OBSTACLE , axis =- 1 ) rgb_img [ mask ] = self . semantic_segmentation_detector . OBSTACLE if show_semantic_segmentation_ground : mask = np . all ( self . semantic_segmentation_detector . curr_segmentation == self . semantic_segmentation_detector . GROUND , axis =- 1 ) rgb_img [ mask ] = self . semantic_segmentation_detector . GROUND else : self . logger . error ( \"Semantic Segmentation Detector is not configured\" ) if show_point_cloud_ground and ground_points is not None : img_cords : np . ndarray = self . world_to_img_transform ( ground_points )[:, : 2 ] # ys = [342, 278, 271, 413 ,327 ,169 ,415, 747 ,507 ,311,311,311,311,311,311] # xs = [577, 513 ,531, 522 ,372 ,581, 470 ,484, 587, 523,524,525,526,527,528] # rgb_img[xs, ys] = [0, 0, 0] rgb_img [ img_cords [:, 1 ], img_cords [:, 0 ]] = [ 0 , 0 , 0 ] # TODO this aint working lol if self . agent . local_planner is not None and \\ 0 < show_num_waypoints < len ( self . agent . local_planner . way_points_queue ): img_positions = self . world_to_img_transform ( np . array ( [ self . agent . local_planner . way_points_queue [ i ] . location . to_array () for i in range ( show_num_waypoints )])) for y , x , _ in img_positions : rgb_img [ x - 2 : x + 2 , y - 2 : y + 2 ] = self . GREEN cv2 . imshow ( \"First Person View\" , rgb_img ) cv2 . waitKey ( 1 ) visualize ( self , next_waypoint_transform ) \u00a4 This function will allow multiple objects to be drawn on here. Parameters: Name Type Description Default next_waypoint_transform Transform Next Waypoint's Transform information required Returns: Type Description None None Source code in ROAR/roar_autonomous_system/visualization_module/visualizer.py 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 @deprecated ( reason = \"Will no longer support next waypoint visualization on a single display\" ) def visualize ( self , next_waypoint_transform : Transform ) -> None : \"\"\" This function will allow multiple objects to be drawn on here. Args: next_waypoint_transform: Next Waypoint's Transform information Returns: None \"\"\" next_waypoint_cam_pos = self . calculate_img_pos ( waypoint_transform = next_waypoint_transform , camera = self . agent . front_depth_camera , ) img = self . agent . front_rgb_camera . data . copy () start_point = ( 400 , 600 ) img = cv2 . arrowedLine ( img = img , pt1 = start_point , pt2 = ( next_waypoint_cam_pos [ 0 ], next_waypoint_cam_pos [ 1 ]), color = ( 0 , 255 , 0 ), thickness = 2 , ) cv2 . imshow ( \"Visualization\" , img ) cv2 . waitKey ( 1 ) visualize_semantic_segmentation ( cls , semantic_segmetation ) classmethod \u00a4 Parameters: Name Type Description Default semantic_segmetation Width x Height x 3 array with white = obstacles, black = ground, blue = sky required Returns: Type Description None None Source code in ROAR/roar_autonomous_system/visualization_module/visualizer.py 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 @classmethod @deprecated ( reason = \"will no longer support single semantic segmentation visualization\" ) def visualize_semantic_segmentation ( cls , semantic_segmetation ) -> None : \"\"\" Args: semantic_segmetation: Width x Height x 3 array with white = obstacles, black = ground, blue = sky Returns: None \"\"\" if semantic_segmetation is not None : cv2 . imshow ( \"Semantic Segmentation\" , semantic_segmetation ) cv2 . waitKey ( 1 ) visualize_waypoint ( self , waypoint_transform ) \u00a4 Source code in ROAR/roar_autonomous_system/visualization_module/visualizer.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 @deprecated ( reason = \"Will no longer support seperate graph visualization\" ) def visualize_waypoint ( self , waypoint_transform : Transform ): coord = self . calculate_img_pos ( waypoint_transform = waypoint_transform , camera = self . agent . front_depth_camera ) img = self . agent . front_rgb_camera . data . copy () img = cv2 . arrowedLine ( img , ( 400 , 600 ), ( coord [ 0 ], coord [ 1 ]), ( 0 , 255 , 0 ), 2 ) cv2 . imshow ( \"Next Waypoint\" , img ) cv2 . waitKey ( 1 ) world_to_img_transform ( self , xyz ) \u00a4 Calculate the 2D image coordinate from 3D world space Parameters: Name Type Description Default xyz ndarray (Nx3) array representing X, Y, Z in world coord required Returns: Type Description ndarray Array if integers [u, v, f] Source code in ROAR/roar_autonomous_system/visualization_module/visualizer.py 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 def world_to_img_transform ( self , xyz : np . ndarray ) -> np . ndarray : \"\"\" Calculate the 2D image coordinate from 3D world space Args: xyz: (Nx3) array representing X, Y, Z in world coord Returns: Array if integers [u, v, f] \"\"\" xyz1 = np . append ( xyz , np . ones ( shape = ( len ( xyz ), 1 )), axis = 1 ) veh_cam_matrix = self . agent . front_depth_camera . transform . get_matrix () # 4 x 4 world_veh_matrix = self . agent . vehicle . transform . get_matrix () # 4 x 4 world_cam_matrix = np . linalg . inv ( np . dot ( world_veh_matrix , veh_cam_matrix )) cords_xyz1 = world_cam_matrix @ xyz1 . T cords_y_minus_z_x = np . array ([ cords_xyz1 [ 1 , :], - cords_xyz1 [ 2 , :], cords_xyz1 [ 0 , :]]) raw_p2d = self . agent . front_depth_camera . intrinsics_matrix @ cords_y_minus_z_x cam_cords = np . array ( [ raw_p2d [ 0 , :] / raw_p2d [ 2 , :], raw_p2d [ 1 , :] / raw_p2d [ 2 , :], raw_p2d [ 2 , :]] ) . T return np . round ( cam_cords , 0 ) . astype ( np . int64 )","title":"Visualization"},{"location":"code_documentations/roar_autonomous_system/visualizations/#ROAR.roar_autonomous_system.visualization_module.visualizer.Visualizer","text":"","title":"Visualizer"},{"location":"code_documentations/roar_autonomous_system/visualizations/#ROAR.roar_autonomous_system.visualization_module.visualizer.Visualizer.GREEN","text":"","title":"GREEN"},{"location":"code_documentations/roar_autonomous_system/visualizations/#ROAR.roar_autonomous_system.visualization_module.visualizer.Visualizer.GROUND","text":"","title":"GROUND"},{"location":"code_documentations/roar_autonomous_system/visualizations/#ROAR.roar_autonomous_system.visualization_module.visualizer.Visualizer.__init__","text":"Source code in ROAR/roar_autonomous_system/visualization_module/visualizer.py 20 21 22 23 24 25 26 27 28 29 def __init__ ( self , agent : Agent , occupancy_grid_map : Optional [ OccupancyGridMap ] = None , semantic_segmentation_detector : Optional [ SemanticSegmentationDetector ] = None , point_cloud_detector : Optional [ PointCloudDetector ] = None ): self . logger = logging . getLogger ( __name__ ) self . agent = agent self . occupancy_grid_map = occupancy_grid_map self . semantic_segmentation_detector = semantic_segmentation_detector self . point_cloud_detector = point_cloud_detector","title":"__init__()"},{"location":"code_documentations/roar_autonomous_system/visualizations/#ROAR.roar_autonomous_system.visualization_module.visualizer.Visualizer.calculate_img_pos","text":"Calculate the 2D image coordinate from 3D world space Parameters: Name Type Description Default camera Camera required waypoint_transform Transform Desired point in 3D world space required Returns: Type Description ndarray Array if integers [X, Y, depth] Source code in ROAR/roar_autonomous_system/visualization_module/visualizer.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 @deprecated ( reason = \"Will no longer support single image to world calculation.\" ) def calculate_img_pos ( self , waypoint_transform : Transform , camera : Camera ) -> np . ndarray : \"\"\" Calculate the 2D image coordinate from 3D world space Args: camera: waypoint_transform: Desired point in 3D world space Returns: Array if integers [X, Y, depth] \"\"\" waypoint_location = waypoint_transform . location . to_array () # [x, y, z] waypoint_location = np . concatenate ( [ waypoint_location , [ 1 ]] ) # 4 x 1 array [X, Y, Z, 1] veh_cam_matrix = camera . transform . get_matrix () # 4 x 4 world_veh_matrix = self . agent . vehicle . transform . get_matrix () # 4 x 4 world_cam_matrix = np . linalg . inv ( np . dot ( world_veh_matrix , veh_cam_matrix )) cords_xyz = world_cam_matrix @ waypoint_location cords_y_minus_z_x = np . array ([ cords_xyz [ 1 ], - cords_xyz [ 2 ], cords_xyz [ 0 ]]) raw_p2d = camera . intrinsics_matrix @ cords_y_minus_z_x cam_cords = np . array ( [ raw_p2d [ 0 ] / raw_p2d [ 2 ], raw_p2d [ 1 ] / raw_p2d [ 2 ], raw_p2d [ 2 ]] ) return np . round ( cam_cords , 0 ) . astype ( np . int64 )","title":"calculate_img_pos()"},{"location":"code_documentations/roar_autonomous_system/visualizations/#ROAR.roar_autonomous_system.visualization_module.visualizer.Visualizer.show_birds_eye_visualization","text":"Source code in ROAR/roar_autonomous_system/visualization_module/visualizer.py 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 def show_birds_eye_visualization ( self , focus_on_vehicle : bool = True , view_size : int = 200 ): if self . occupancy_grid_map is None : self . logger . error ( \"No Occupancy Grid Map is connected\" ) else : if focus_on_vehicle : occu_cord = self . occupancy_grid_map . location_to_occu_cord ( location = self . agent . vehicle . transform . location ) map_copy = self . occupancy_grid_map . map . copy () x , y = occu_cord [ 0 ] map_copy [ y - self . occupancy_grid_map . vehicle_height // 2 : y + self . occupancy_grid_map . vehicle_height // 2 , x - self . occupancy_grid_map . vehicle_width // 2 : x + self . occupancy_grid_map . vehicle_width // 2 ] = 0 cv2 . imshow ( \"Occupancy Grid Map\" , map_copy [ y - view_size // 2 : y + view_size // 2 :, x - view_size // 2 : x + view_size // 2 ]) else : cv2 . imshow ( \"Occupancy Grid Map\" , self . occupancy_grid_map . map ) cv2 . waitKey ( 1 )","title":"show_birds_eye_visualization()"},{"location":"code_documentations/roar_autonomous_system/visualizations/#ROAR.roar_autonomous_system.visualization_module.visualizer.Visualizer.show_first_person_visualization","text":"Source code in ROAR/roar_autonomous_system/visualization_module/visualizer.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 def show_first_person_visualization ( self , show_num_waypoints : int = 0 , show_semantic_segmentation_obstacle : bool = False , show_semantic_segmentation_sky : bool = False , show_semantic_segmentation_ground : bool = False , show_point_cloud_ground : bool = False , ground_points : Optional [ np . ndarray ] = None ): rgb_img = self . agent . front_rgb_camera . data . copy () if show_semantic_segmentation_sky or show_semantic_segmentation_obstacle or show_semantic_segmentation_ground : if self . semantic_segmentation_detector is not None and \\ self . semantic_segmentation_detector . curr_segmentation is not None : if show_semantic_segmentation_sky : mask = np . all ( self . semantic_segmentation_detector . curr_segmentation == self . semantic_segmentation_detector . SKY , axis =- 1 ) rgb_img [ mask ] = self . semantic_segmentation_detector . SKY if show_semantic_segmentation_obstacle : mask = np . all ( self . semantic_segmentation_detector . curr_segmentation == self . semantic_segmentation_detector . OBSTACLE , axis =- 1 ) rgb_img [ mask ] = self . semantic_segmentation_detector . OBSTACLE if show_semantic_segmentation_ground : mask = np . all ( self . semantic_segmentation_detector . curr_segmentation == self . semantic_segmentation_detector . GROUND , axis =- 1 ) rgb_img [ mask ] = self . semantic_segmentation_detector . GROUND else : self . logger . error ( \"Semantic Segmentation Detector is not configured\" ) if show_point_cloud_ground and ground_points is not None : img_cords : np . ndarray = self . world_to_img_transform ( ground_points )[:, : 2 ] # ys = [342, 278, 271, 413 ,327 ,169 ,415, 747 ,507 ,311,311,311,311,311,311] # xs = [577, 513 ,531, 522 ,372 ,581, 470 ,484, 587, 523,524,525,526,527,528] # rgb_img[xs, ys] = [0, 0, 0] rgb_img [ img_cords [:, 1 ], img_cords [:, 0 ]] = [ 0 , 0 , 0 ] # TODO this aint working lol if self . agent . local_planner is not None and \\ 0 < show_num_waypoints < len ( self . agent . local_planner . way_points_queue ): img_positions = self . world_to_img_transform ( np . array ( [ self . agent . local_planner . way_points_queue [ i ] . location . to_array () for i in range ( show_num_waypoints )])) for y , x , _ in img_positions : rgb_img [ x - 2 : x + 2 , y - 2 : y + 2 ] = self . GREEN cv2 . imshow ( \"First Person View\" , rgb_img ) cv2 . waitKey ( 1 )","title":"show_first_person_visualization()"},{"location":"code_documentations/roar_autonomous_system/visualizations/#ROAR.roar_autonomous_system.visualization_module.visualizer.Visualizer.visualize","text":"This function will allow multiple objects to be drawn on here. Parameters: Name Type Description Default next_waypoint_transform Transform Next Waypoint's Transform information required Returns: Type Description None None Source code in ROAR/roar_autonomous_system/visualization_module/visualizer.py 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 @deprecated ( reason = \"Will no longer support next waypoint visualization on a single display\" ) def visualize ( self , next_waypoint_transform : Transform ) -> None : \"\"\" This function will allow multiple objects to be drawn on here. Args: next_waypoint_transform: Next Waypoint's Transform information Returns: None \"\"\" next_waypoint_cam_pos = self . calculate_img_pos ( waypoint_transform = next_waypoint_transform , camera = self . agent . front_depth_camera , ) img = self . agent . front_rgb_camera . data . copy () start_point = ( 400 , 600 ) img = cv2 . arrowedLine ( img = img , pt1 = start_point , pt2 = ( next_waypoint_cam_pos [ 0 ], next_waypoint_cam_pos [ 1 ]), color = ( 0 , 255 , 0 ), thickness = 2 , ) cv2 . imshow ( \"Visualization\" , img ) cv2 . waitKey ( 1 )","title":"visualize()"},{"location":"code_documentations/roar_autonomous_system/visualizations/#ROAR.roar_autonomous_system.visualization_module.visualizer.Visualizer.visualize_semantic_segmentation","text":"Parameters: Name Type Description Default semantic_segmetation Width x Height x 3 array with white = obstacles, black = ground, blue = sky required Returns: Type Description None None Source code in ROAR/roar_autonomous_system/visualization_module/visualizer.py 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 @classmethod @deprecated ( reason = \"will no longer support single semantic segmentation visualization\" ) def visualize_semantic_segmentation ( cls , semantic_segmetation ) -> None : \"\"\" Args: semantic_segmetation: Width x Height x 3 array with white = obstacles, black = ground, blue = sky Returns: None \"\"\" if semantic_segmetation is not None : cv2 . imshow ( \"Semantic Segmentation\" , semantic_segmetation ) cv2 . waitKey ( 1 )","title":"visualize_semantic_segmentation()"},{"location":"code_documentations/roar_autonomous_system/visualizations/#ROAR.roar_autonomous_system.visualization_module.visualizer.Visualizer.visualize_waypoint","text":"Source code in ROAR/roar_autonomous_system/visualization_module/visualizer.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 @deprecated ( reason = \"Will no longer support seperate graph visualization\" ) def visualize_waypoint ( self , waypoint_transform : Transform ): coord = self . calculate_img_pos ( waypoint_transform = waypoint_transform , camera = self . agent . front_depth_camera ) img = self . agent . front_rgb_camera . data . copy () img = cv2 . arrowedLine ( img , ( 400 , 600 ), ( coord [ 0 ], coord [ 1 ]), ( 0 , 255 , 0 ), 2 ) cv2 . imshow ( \"Next Waypoint\" , img ) cv2 . waitKey ( 1 )","title":"visualize_waypoint()"},{"location":"code_documentations/roar_autonomous_system/visualizations/#ROAR.roar_autonomous_system.visualization_module.visualizer.Visualizer.world_to_img_transform","text":"Calculate the 2D image coordinate from 3D world space Parameters: Name Type Description Default xyz ndarray (Nx3) array representing X, Y, Z in world coord required Returns: Type Description ndarray Array if integers [u, v, f] Source code in ROAR/roar_autonomous_system/visualization_module/visualizer.py 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 def world_to_img_transform ( self , xyz : np . ndarray ) -> np . ndarray : \"\"\" Calculate the 2D image coordinate from 3D world space Args: xyz: (Nx3) array representing X, Y, Z in world coord Returns: Array if integers [u, v, f] \"\"\" xyz1 = np . append ( xyz , np . ones ( shape = ( len ( xyz ), 1 )), axis = 1 ) veh_cam_matrix = self . agent . front_depth_camera . transform . get_matrix () # 4 x 4 world_veh_matrix = self . agent . vehicle . transform . get_matrix () # 4 x 4 world_cam_matrix = np . linalg . inv ( np . dot ( world_veh_matrix , veh_cam_matrix )) cords_xyz1 = world_cam_matrix @ xyz1 . T cords_y_minus_z_x = np . array ([ cords_xyz1 [ 1 , :], - cords_xyz1 [ 2 , :], cords_xyz1 [ 0 , :]]) raw_p2d = self . agent . front_depth_camera . intrinsics_matrix @ cords_y_minus_z_x cam_cords = np . array ( [ raw_p2d [ 0 , :] / raw_p2d [ 2 , :], raw_p2d [ 1 , :] / raw_p2d [ 2 , :], raw_p2d [ 2 , :]] ) . T return np . round ( cam_cords , 0 ) . astype ( np . int64 )","title":"world_to_img_transform()"},{"location":"code_documentations/roar_autonomous_system/planning/behavior_planners/","text":"behavior_planner \u00a4 BehaviorPlanner \u00a4 run_step ( self , vehicle ) \u00a4 On every step, produce an actionable plan Returns: Type Description Any Source code in ROAR/roar_autonomous_system/planning_module/behavior_planner/behavior_planner.py 13 14 def run_step ( self , vehicle : Vehicle ) -> Any : pass","title":"Behavior Planner"},{"location":"code_documentations/roar_autonomous_system/planning/behavior_planners/#ROAR.roar_autonomous_system.planning_module.behavior_planner.behavior_planner","text":"","title":"behavior_planner"},{"location":"code_documentations/roar_autonomous_system/planning/behavior_planners/#ROAR.roar_autonomous_system.planning_module.behavior_planner.behavior_planner.BehaviorPlanner","text":"","title":"BehaviorPlanner"},{"location":"code_documentations/roar_autonomous_system/planning/behavior_planners/#ROAR.roar_autonomous_system.planning_module.behavior_planner.behavior_planner.BehaviorPlanner.run_step","text":"On every step, produce an actionable plan Returns: Type Description Any Source code in ROAR/roar_autonomous_system/planning_module/behavior_planner/behavior_planner.py 13 14 def run_step ( self , vehicle : Vehicle ) -> Any : pass","title":"run_step()"},{"location":"code_documentations/roar_autonomous_system/planning/local_planners/","text":"local_planner \u00a4 LocalPlanner \u00a4 __init__ ( self , vehicle , controller = None , behavior_planner = None , mission_planner = None ) special \u00a4 Source code in ROAR/roar_autonomous_system/planning_module/local_planner/local_planner.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def __init__ ( self , vehicle : Vehicle , controller : Optional [ Controller ] = None , behavior_planner : Optional [ BehaviorPlanner ] = None , mission_planner : Optional [ MissionPlanner ] = None , ): super () . __init__ ( vehicle ) self . controller = ( Controller ( vehicle = vehicle ) if controller is None else controller ) self . behavior_planner = ( BehaviorPlanner ( vehicle = vehicle ) if behavior_planner is None else behavior_planner ) self . mission_planner = ( MissionPlanner ( vehicle = vehicle ) if mission_planner is None else mission_planner ) self . way_points_queue = deque () run_step ( self , vehicle ) \u00a4 On every step, produce an actionable plan Returns: Type Description VehicleControl Source code in ROAR/roar_autonomous_system/planning_module/local_planner/local_planner.py 46 47 48 @abstractmethod def run_step ( self , vehicle : Vehicle ) -> VehicleControl : return VehicleControl () semantic_segmentation_detector \u00a4 SemanticSegmentationOnlyPlanner \u00a4 __init__ ( self , vehicle , controller , gpd_detector , next_waypoint_distance = 10 , max_turn_degree = 10 ) special \u00a4 Source code in ROAR/roar_autonomous_system/planning_module/local_planner/semantic_segmentation_detector.py 18 19 20 21 22 23 24 25 26 27 28 29 30 def __init__ ( self , vehicle : Vehicle , controller : Controller , gpd_detector : SemanticSegmentationDetector , next_waypoint_distance : float = 10 , max_turn_degree : int = 10 , ): super () . __init__ ( vehicle , controller ) self . gpd_detector = gpd_detector self . _next_waypoint_distance = next_waypoint_distance self . _max_turn_degree = max_turn_degree self . _carla_distance_to_pixel_scaling = 10 is_done ( self ) \u00a4 Source code in ROAR/roar_autonomous_system/planning_module/local_planner/semantic_segmentation_detector.py 75 76 def is_done ( self ): return False is_front_clear ( self ) \u00a4 Take a block of 10 x 10 in next_waypoint_distance front and see if they are all NOT white. Returns: Type Description bool True if the block is all None white, false otherwise Source code in ROAR/roar_autonomous_system/planning_module/local_planner/semantic_segmentation_detector.py 84 85 86 87 88 89 90 91 92 93 94 95 def is_front_clear ( self ) -> bool : \"\"\" Take a block of 10 x 10 in next_waypoint_distance front and see if they are all NOT white. Returns: True if the block is all None white, false otherwise \"\"\" # center_pixel = self._next_waypoint_distance * self._carla_distance_to_pixel_scaling # this variable is guessing # Y, X, _ = np.shape(self.gpd_detector.curr_depth.data) X , Y = 400 , 324 factor = 10 ground_section = self . gpd_detector . curr_ground [ 320 : 600 , X - factor : X + factor ] return np . all ( ground_section ) is_left_clear ( self ) \u00a4 Take a block of 10 x 10 to degree left, and next_waypoint_distance and see if they are all NOT white. Returns: Type Description bool True if the block is all None white, false otherwise Source code in ROAR/roar_autonomous_system/planning_module/local_planner/semantic_segmentation_detector.py 97 98 99 100 101 102 103 104 105 106 def is_left_clear ( self ) -> bool : \"\"\" Take a block of 10 x 10 to degree left, and next_waypoint_distance and see if they are all NOT white. Returns: True if the block is all None white, false otherwise \"\"\" X , Y = 200 , 324 factor = 10 ground_section = self . gpd_detector . curr_ground [ 330 : 600 , X - factor : X + factor ] return np . all ( ground_section ) is_right_clear ( self ) \u00a4 Take a block of 10 x 10 to degree right, and next_waypoint_distance and see if they are all NOT white. Returns: Type Description bool True if the block is all None white, false otherwise Source code in ROAR/roar_autonomous_system/planning_module/local_planner/semantic_segmentation_detector.py 108 109 110 111 112 113 114 115 116 117 118 def is_right_clear ( self ) -> bool : \"\"\" Take a block of 10 x 10 to degree right, and next_waypoint_distance and see if they are all NOT white. Returns: True if the block is all None white, false otherwise \"\"\" X , Y = 600 , 324 factor = 10 ground_section = self . gpd_detector . curr_ground [ 320 : 600 , X - factor : X + factor ] return np . all ( ground_section ) run_step ( self , vehicle ) \u00a4 Get data from GPD_Detector if front is clear put a waypoint in front of the vehicle if front is blocked, both left and right are clear, put a point at random to the left or right of the vehicle if front is blocked, left is blocked, right is clear put a point to the right of the vehicle if front is blocked, right is blocked, left is clear put a point to the left of the vehicle if front, right, and left are all blocked stop (return a control that does nothing) Returns: Type Description VehicleControl VehicleControl object Source code in ROAR/roar_autonomous_system/planning_module/local_planner/semantic_segmentation_detector.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 def run_step ( self , vehicle : Vehicle ) -> VehicleControl : \"\"\" Get data from GPD_Detector if front is clear put a waypoint in front of the vehicle if front is blocked, both left and right are clear, put a point at random to the left or right of the vehicle if front is blocked, left is blocked, right is clear put a point to the right of the vehicle if front is blocked, right is blocked, left is clear put a point to the left of the vehicle if front, right, and left are all blocked stop (return a control that does nothing) Returns: VehicleControl object \"\"\" super ( SemanticSegmentationOnlyPlanner , self ) . run_step ( vehicle = vehicle ) if self . gpd_detector . curr_ground is None : return VehicleControl () curr_location = self . vehicle . transform . location is_front_clear = self . is_front_clear () is_left_clear = self . is_left_clear () is_right_clear = self . is_right_clear () copy_depth = self . gpd_detector . semantic_segmentation . copy () copy_depth [ 320 : 600 , 200 - 10 : 200 + 10 ] = 255 # left copy_depth [ 330 : 600 , 400 - 10 : 400 + 10 ] = 255 # straight copy_depth [ 320 : 600 , 600 - 10 : 600 + 10 ] = 255 # right next_way_point = None if is_front_clear : # generate front waypoint # print(\"Going Straight\") return VehicleControl ( throttle = 0.75 , steering = 0 ) elif is_right_clear : # print(\"Turning Right\") return VehicleControl ( throttle = 0.5 , steering = 0.2 ) elif is_left_clear : # print(\"Turning Left\") return VehicleControl ( throttle = 0.5 , steering =- 0.2 ) else : # print(\"I am stucked\") return VehicleControl () set_mission_plan ( self ) \u00a4 Source code in ROAR/roar_autonomous_system/planning_module/local_planner/semantic_segmentation_detector.py 78 79 def set_mission_plan ( self ): pass sync ( self ) \u00a4 Source code in ROAR/roar_autonomous_system/planning_module/local_planner/semantic_segmentation_detector.py 81 82 def sync ( self ): pass simple_waypoint_following_local_planner \u00a4 SimpleWaypointFollowingLocalPlanner \u00a4 __init__ ( self , vehicle , controller , mission_planner , behavior_planner , closeness_threshold = 0.5 ) special \u00a4 Initialize Simple Waypoint Following Planner Parameters: Name Type Description Default vehicle Vehicle Vehicle information required controller Controller Control module used required mission_planner MissionPlanner mission planner used required behavior_planner BehaviorPlanner behavior planner used required closeness_threshold how close can a waypoint be with the vehicle 0.5 Source code in ROAR/roar_autonomous_system/planning_module/local_planner/simple_waypoint_following_local_planner.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def __init__ ( self , vehicle : Vehicle , controller : Controller , mission_planner : MissionPlanner , behavior_planner : BehaviorPlanner , closeness_threshold = 0.5 , ): \"\"\" Initialize Simple Waypoint Following Planner Args: vehicle: Vehicle information controller: Control module used mission_planner: mission planner used behavior_planner: behavior planner used closeness_threshold: how close can a waypoint be with the vehicle \"\"\" super () . __init__ ( vehicle = vehicle , controller = controller , mission_planner = mission_planner , behavior_planner = behavior_planner , ) self . logger = logging . getLogger ( \"SimplePathFollowingLocalPlanner\" ) self . set_mission_plan () self . logger . debug ( \"Simple Path Following Local Planner Initiated\" ) self . closeness_threshold = closeness_threshold is_done ( self ) \u00a4 If there are nothing in self.way_points_queue, that means you have finished a lap, you are done Returns: Type Description bool True if Done, False otherwise Source code in ROAR/roar_autonomous_system/planning_module/local_planner/simple_waypoint_following_local_planner.py 69 70 71 72 73 74 75 76 77 def is_done ( self ) -> bool : \"\"\" If there are nothing in self.way_points_queue, that means you have finished a lap, you are done Returns: True if Done, False otherwise \"\"\" return len ( self . way_points_queue ) == 0 run_step ( self , vehicle ) \u00a4 Procedure Sync data get the correct look ahead for current speed get the correct next waypoint feed waypoint into controller return result from controller Parameters: Name Type Description Default vehicle Vehicle current vehicle state required Returns: Type Description VehicleControl next control that the local think the agent should execute. Source code in ROAR/roar_autonomous_system/planning_module/local_planner/simple_waypoint_following_local_planner.py 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 def run_step ( self , vehicle : Vehicle ) -> VehicleControl : \"\"\" Run step for the local planner Procedure: 1. Sync data 2. get the correct look ahead for current speed 3. get the correct next waypoint 4. feed waypoint into controller 5. return result from controller Args: vehicle: current vehicle state Returns: next control that the local think the agent should execute. \"\"\" self . sync_data ( vehicle = vehicle ) # on every run step, sync first if ( len ( self . mission_planner . mission_plan ) == 0 and len ( self . way_points_queue ) == 0 ): return VehicleControl () # get vehicle's location vehicle_transform : Union [ Transform , None ] = self . vehicle . transform if vehicle_transform is None : raise AgentException ( \"I do not know where I am, I cannot proceed forward\" ) # redefine closeness level based on speed curr_speed = Vehicle . get_speed ( self . vehicle ) if curr_speed < 60 : self . closeness_threshold = 5 elif curr_speed < 80 : self . closeness_threshold = 15 elif curr_speed < 120 : self . closeness_threshold = 20 else : self . closeness_threshold = 50 # print(f\"Curr closeness threshold = {self.closeness_threshold}\") # get current waypoint curr_closest_dist = float ( \"inf\" ) while True : if len ( self . way_points_queue ) == 0 : self . logger . info ( \"Destination reached\" ) return VehicleControl () waypoint : Transform = self . way_points_queue [ 0 ] curr_dist = vehicle_transform . location . distance ( waypoint . location ) if curr_dist < curr_closest_dist : # if i find a waypoint that is closer to me than before # note that i will always enter here to start the calculation for curr_closest_dist curr_closest_dist = curr_dist elif curr_dist < self . closeness_threshold : # i have moved onto a waypoint, remove that waypoint from the queue self . way_points_queue . popleft () else : break target_waypoint = self . way_points_queue [ 0 ] # target_waypoint = Transform.average(self.way_points_queue[0], self.way_points_queue[1]) # target_waypoint = Transform.average(self.way_points_queue[2], target_waypoint) control : VehicleControl = self . controller . run_step ( vehicle = vehicle , next_waypoint = target_waypoint ) # self.logger.debug( # f\"Target_Location {target_waypoint.location} \" # f\"| Curr_Location {vehicle_transform.location} \" # f\"| Distance {int(curr_closest_dist)}\") return control set_mission_plan ( self ) \u00a4 clears current waypoints, and reset mission plan from start I am simply transfering the mission plan into my waypoint queue. Assuming that this current run will run all the way to the end Returns: Type Description None None Source code in ROAR/roar_autonomous_system/planning_module/local_planner/simple_waypoint_following_local_planner.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 def set_mission_plan ( self ) -> None : \"\"\" clears current waypoints, and reset mission plan from start I am simply transfering the mission plan into my waypoint queue. Assuming that this current run will run all the way to the end Returns: None \"\"\" self . way_points_queue . clear () while ( self . mission_planner . mission_plan ): # this actually clears the mission plan!! self . way_points_queue . append ( self . mission_planner . mission_plan . popleft ())","title":"Local Planner"},{"location":"code_documentations/roar_autonomous_system/planning/local_planners/#ROAR.roar_autonomous_system.planning_module.local_planner.local_planner","text":"","title":"local_planner"},{"location":"code_documentations/roar_autonomous_system/planning/local_planners/#ROAR.roar_autonomous_system.planning_module.local_planner.local_planner.LocalPlanner","text":"","title":"LocalPlanner"},{"location":"code_documentations/roar_autonomous_system/planning/local_planners/#ROAR.roar_autonomous_system.planning_module.local_planner.local_planner.LocalPlanner.__init__","text":"Source code in ROAR/roar_autonomous_system/planning_module/local_planner/local_planner.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def __init__ ( self , vehicle : Vehicle , controller : Optional [ Controller ] = None , behavior_planner : Optional [ BehaviorPlanner ] = None , mission_planner : Optional [ MissionPlanner ] = None , ): super () . __init__ ( vehicle ) self . controller = ( Controller ( vehicle = vehicle ) if controller is None else controller ) self . behavior_planner = ( BehaviorPlanner ( vehicle = vehicle ) if behavior_planner is None else behavior_planner ) self . mission_planner = ( MissionPlanner ( vehicle = vehicle ) if mission_planner is None else mission_planner ) self . way_points_queue = deque ()","title":"__init__()"},{"location":"code_documentations/roar_autonomous_system/planning/local_planners/#ROAR.roar_autonomous_system.planning_module.local_planner.local_planner.LocalPlanner.run_step","text":"On every step, produce an actionable plan Returns: Type Description VehicleControl Source code in ROAR/roar_autonomous_system/planning_module/local_planner/local_planner.py 46 47 48 @abstractmethod def run_step ( self , vehicle : Vehicle ) -> VehicleControl : return VehicleControl ()","title":"run_step()"},{"location":"code_documentations/roar_autonomous_system/planning/local_planners/#ROAR.roar_autonomous_system.planning_module.local_planner.semantic_segmentation_detector","text":"","title":"semantic_segmentation_detector"},{"location":"code_documentations/roar_autonomous_system/planning/local_planners/#ROAR.roar_autonomous_system.planning_module.local_planner.semantic_segmentation_detector.SemanticSegmentationOnlyPlanner","text":"","title":"SemanticSegmentationOnlyPlanner"},{"location":"code_documentations/roar_autonomous_system/planning/local_planners/#ROAR.roar_autonomous_system.planning_module.local_planner.semantic_segmentation_detector.SemanticSegmentationOnlyPlanner.__init__","text":"Source code in ROAR/roar_autonomous_system/planning_module/local_planner/semantic_segmentation_detector.py 18 19 20 21 22 23 24 25 26 27 28 29 30 def __init__ ( self , vehicle : Vehicle , controller : Controller , gpd_detector : SemanticSegmentationDetector , next_waypoint_distance : float = 10 , max_turn_degree : int = 10 , ): super () . __init__ ( vehicle , controller ) self . gpd_detector = gpd_detector self . _next_waypoint_distance = next_waypoint_distance self . _max_turn_degree = max_turn_degree self . _carla_distance_to_pixel_scaling = 10","title":"__init__()"},{"location":"code_documentations/roar_autonomous_system/planning/local_planners/#ROAR.roar_autonomous_system.planning_module.local_planner.semantic_segmentation_detector.SemanticSegmentationOnlyPlanner.is_done","text":"Source code in ROAR/roar_autonomous_system/planning_module/local_planner/semantic_segmentation_detector.py 75 76 def is_done ( self ): return False","title":"is_done()"},{"location":"code_documentations/roar_autonomous_system/planning/local_planners/#ROAR.roar_autonomous_system.planning_module.local_planner.semantic_segmentation_detector.SemanticSegmentationOnlyPlanner.is_front_clear","text":"Take a block of 10 x 10 in next_waypoint_distance front and see if they are all NOT white. Returns: Type Description bool True if the block is all None white, false otherwise Source code in ROAR/roar_autonomous_system/planning_module/local_planner/semantic_segmentation_detector.py 84 85 86 87 88 89 90 91 92 93 94 95 def is_front_clear ( self ) -> bool : \"\"\" Take a block of 10 x 10 in next_waypoint_distance front and see if they are all NOT white. Returns: True if the block is all None white, false otherwise \"\"\" # center_pixel = self._next_waypoint_distance * self._carla_distance_to_pixel_scaling # this variable is guessing # Y, X, _ = np.shape(self.gpd_detector.curr_depth.data) X , Y = 400 , 324 factor = 10 ground_section = self . gpd_detector . curr_ground [ 320 : 600 , X - factor : X + factor ] return np . all ( ground_section )","title":"is_front_clear()"},{"location":"code_documentations/roar_autonomous_system/planning/local_planners/#ROAR.roar_autonomous_system.planning_module.local_planner.semantic_segmentation_detector.SemanticSegmentationOnlyPlanner.is_left_clear","text":"Take a block of 10 x 10 to degree left, and next_waypoint_distance and see if they are all NOT white. Returns: Type Description bool True if the block is all None white, false otherwise Source code in ROAR/roar_autonomous_system/planning_module/local_planner/semantic_segmentation_detector.py 97 98 99 100 101 102 103 104 105 106 def is_left_clear ( self ) -> bool : \"\"\" Take a block of 10 x 10 to degree left, and next_waypoint_distance and see if they are all NOT white. Returns: True if the block is all None white, false otherwise \"\"\" X , Y = 200 , 324 factor = 10 ground_section = self . gpd_detector . curr_ground [ 330 : 600 , X - factor : X + factor ] return np . all ( ground_section )","title":"is_left_clear()"},{"location":"code_documentations/roar_autonomous_system/planning/local_planners/#ROAR.roar_autonomous_system.planning_module.local_planner.semantic_segmentation_detector.SemanticSegmentationOnlyPlanner.is_right_clear","text":"Take a block of 10 x 10 to degree right, and next_waypoint_distance and see if they are all NOT white. Returns: Type Description bool True if the block is all None white, false otherwise Source code in ROAR/roar_autonomous_system/planning_module/local_planner/semantic_segmentation_detector.py 108 109 110 111 112 113 114 115 116 117 118 def is_right_clear ( self ) -> bool : \"\"\" Take a block of 10 x 10 to degree right, and next_waypoint_distance and see if they are all NOT white. Returns: True if the block is all None white, false otherwise \"\"\" X , Y = 600 , 324 factor = 10 ground_section = self . gpd_detector . curr_ground [ 320 : 600 , X - factor : X + factor ] return np . all ( ground_section )","title":"is_right_clear()"},{"location":"code_documentations/roar_autonomous_system/planning/local_planners/#ROAR.roar_autonomous_system.planning_module.local_planner.semantic_segmentation_detector.SemanticSegmentationOnlyPlanner.run_step","text":"Get data from GPD_Detector if front is clear put a waypoint in front of the vehicle if front is blocked, both left and right are clear, put a point at random to the left or right of the vehicle if front is blocked, left is blocked, right is clear put a point to the right of the vehicle if front is blocked, right is blocked, left is clear put a point to the left of the vehicle if front, right, and left are all blocked stop (return a control that does nothing) Returns: Type Description VehicleControl VehicleControl object Source code in ROAR/roar_autonomous_system/planning_module/local_planner/semantic_segmentation_detector.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 def run_step ( self , vehicle : Vehicle ) -> VehicleControl : \"\"\" Get data from GPD_Detector if front is clear put a waypoint in front of the vehicle if front is blocked, both left and right are clear, put a point at random to the left or right of the vehicle if front is blocked, left is blocked, right is clear put a point to the right of the vehicle if front is blocked, right is blocked, left is clear put a point to the left of the vehicle if front, right, and left are all blocked stop (return a control that does nothing) Returns: VehicleControl object \"\"\" super ( SemanticSegmentationOnlyPlanner , self ) . run_step ( vehicle = vehicle ) if self . gpd_detector . curr_ground is None : return VehicleControl () curr_location = self . vehicle . transform . location is_front_clear = self . is_front_clear () is_left_clear = self . is_left_clear () is_right_clear = self . is_right_clear () copy_depth = self . gpd_detector . semantic_segmentation . copy () copy_depth [ 320 : 600 , 200 - 10 : 200 + 10 ] = 255 # left copy_depth [ 330 : 600 , 400 - 10 : 400 + 10 ] = 255 # straight copy_depth [ 320 : 600 , 600 - 10 : 600 + 10 ] = 255 # right next_way_point = None if is_front_clear : # generate front waypoint # print(\"Going Straight\") return VehicleControl ( throttle = 0.75 , steering = 0 ) elif is_right_clear : # print(\"Turning Right\") return VehicleControl ( throttle = 0.5 , steering = 0.2 ) elif is_left_clear : # print(\"Turning Left\") return VehicleControl ( throttle = 0.5 , steering =- 0.2 ) else : # print(\"I am stucked\") return VehicleControl ()","title":"run_step()"},{"location":"code_documentations/roar_autonomous_system/planning/local_planners/#ROAR.roar_autonomous_system.planning_module.local_planner.semantic_segmentation_detector.SemanticSegmentationOnlyPlanner.set_mission_plan","text":"Source code in ROAR/roar_autonomous_system/planning_module/local_planner/semantic_segmentation_detector.py 78 79 def set_mission_plan ( self ): pass","title":"set_mission_plan()"},{"location":"code_documentations/roar_autonomous_system/planning/local_planners/#ROAR.roar_autonomous_system.planning_module.local_planner.semantic_segmentation_detector.SemanticSegmentationOnlyPlanner.sync","text":"Source code in ROAR/roar_autonomous_system/planning_module/local_planner/semantic_segmentation_detector.py 81 82 def sync ( self ): pass","title":"sync()"},{"location":"code_documentations/roar_autonomous_system/planning/local_planners/#ROAR.roar_autonomous_system.planning_module.local_planner.simple_waypoint_following_local_planner","text":"","title":"simple_waypoint_following_local_planner"},{"location":"code_documentations/roar_autonomous_system/planning/local_planners/#ROAR.roar_autonomous_system.planning_module.local_planner.simple_waypoint_following_local_planner.SimpleWaypointFollowingLocalPlanner","text":"","title":"SimpleWaypointFollowingLocalPlanner"},{"location":"code_documentations/roar_autonomous_system/planning/local_planners/#ROAR.roar_autonomous_system.planning_module.local_planner.simple_waypoint_following_local_planner.SimpleWaypointFollowingLocalPlanner.__init__","text":"Initialize Simple Waypoint Following Planner Parameters: Name Type Description Default vehicle Vehicle Vehicle information required controller Controller Control module used required mission_planner MissionPlanner mission planner used required behavior_planner BehaviorPlanner behavior planner used required closeness_threshold how close can a waypoint be with the vehicle 0.5 Source code in ROAR/roar_autonomous_system/planning_module/local_planner/simple_waypoint_following_local_planner.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def __init__ ( self , vehicle : Vehicle , controller : Controller , mission_planner : MissionPlanner , behavior_planner : BehaviorPlanner , closeness_threshold = 0.5 , ): \"\"\" Initialize Simple Waypoint Following Planner Args: vehicle: Vehicle information controller: Control module used mission_planner: mission planner used behavior_planner: behavior planner used closeness_threshold: how close can a waypoint be with the vehicle \"\"\" super () . __init__ ( vehicle = vehicle , controller = controller , mission_planner = mission_planner , behavior_planner = behavior_planner , ) self . logger = logging . getLogger ( \"SimplePathFollowingLocalPlanner\" ) self . set_mission_plan () self . logger . debug ( \"Simple Path Following Local Planner Initiated\" ) self . closeness_threshold = closeness_threshold","title":"__init__()"},{"location":"code_documentations/roar_autonomous_system/planning/local_planners/#ROAR.roar_autonomous_system.planning_module.local_planner.simple_waypoint_following_local_planner.SimpleWaypointFollowingLocalPlanner.is_done","text":"If there are nothing in self.way_points_queue, that means you have finished a lap, you are done Returns: Type Description bool True if Done, False otherwise Source code in ROAR/roar_autonomous_system/planning_module/local_planner/simple_waypoint_following_local_planner.py 69 70 71 72 73 74 75 76 77 def is_done ( self ) -> bool : \"\"\" If there are nothing in self.way_points_queue, that means you have finished a lap, you are done Returns: True if Done, False otherwise \"\"\" return len ( self . way_points_queue ) == 0","title":"is_done()"},{"location":"code_documentations/roar_autonomous_system/planning/local_planners/#ROAR.roar_autonomous_system.planning_module.local_planner.simple_waypoint_following_local_planner.SimpleWaypointFollowingLocalPlanner.run_step","text":"Procedure Sync data get the correct look ahead for current speed get the correct next waypoint feed waypoint into controller return result from controller Parameters: Name Type Description Default vehicle Vehicle current vehicle state required Returns: Type Description VehicleControl next control that the local think the agent should execute. Source code in ROAR/roar_autonomous_system/planning_module/local_planner/simple_waypoint_following_local_planner.py 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 def run_step ( self , vehicle : Vehicle ) -> VehicleControl : \"\"\" Run step for the local planner Procedure: 1. Sync data 2. get the correct look ahead for current speed 3. get the correct next waypoint 4. feed waypoint into controller 5. return result from controller Args: vehicle: current vehicle state Returns: next control that the local think the agent should execute. \"\"\" self . sync_data ( vehicle = vehicle ) # on every run step, sync first if ( len ( self . mission_planner . mission_plan ) == 0 and len ( self . way_points_queue ) == 0 ): return VehicleControl () # get vehicle's location vehicle_transform : Union [ Transform , None ] = self . vehicle . transform if vehicle_transform is None : raise AgentException ( \"I do not know where I am, I cannot proceed forward\" ) # redefine closeness level based on speed curr_speed = Vehicle . get_speed ( self . vehicle ) if curr_speed < 60 : self . closeness_threshold = 5 elif curr_speed < 80 : self . closeness_threshold = 15 elif curr_speed < 120 : self . closeness_threshold = 20 else : self . closeness_threshold = 50 # print(f\"Curr closeness threshold = {self.closeness_threshold}\") # get current waypoint curr_closest_dist = float ( \"inf\" ) while True : if len ( self . way_points_queue ) == 0 : self . logger . info ( \"Destination reached\" ) return VehicleControl () waypoint : Transform = self . way_points_queue [ 0 ] curr_dist = vehicle_transform . location . distance ( waypoint . location ) if curr_dist < curr_closest_dist : # if i find a waypoint that is closer to me than before # note that i will always enter here to start the calculation for curr_closest_dist curr_closest_dist = curr_dist elif curr_dist < self . closeness_threshold : # i have moved onto a waypoint, remove that waypoint from the queue self . way_points_queue . popleft () else : break target_waypoint = self . way_points_queue [ 0 ] # target_waypoint = Transform.average(self.way_points_queue[0], self.way_points_queue[1]) # target_waypoint = Transform.average(self.way_points_queue[2], target_waypoint) control : VehicleControl = self . controller . run_step ( vehicle = vehicle , next_waypoint = target_waypoint ) # self.logger.debug( # f\"Target_Location {target_waypoint.location} \" # f\"| Curr_Location {vehicle_transform.location} \" # f\"| Distance {int(curr_closest_dist)}\") return control","title":"run_step()"},{"location":"code_documentations/roar_autonomous_system/planning/local_planners/#ROAR.roar_autonomous_system.planning_module.local_planner.simple_waypoint_following_local_planner.SimpleWaypointFollowingLocalPlanner.set_mission_plan","text":"clears current waypoints, and reset mission plan from start I am simply transfering the mission plan into my waypoint queue. Assuming that this current run will run all the way to the end Returns: Type Description None None Source code in ROAR/roar_autonomous_system/planning_module/local_planner/simple_waypoint_following_local_planner.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 def set_mission_plan ( self ) -> None : \"\"\" clears current waypoints, and reset mission plan from start I am simply transfering the mission plan into my waypoint queue. Assuming that this current run will run all the way to the end Returns: None \"\"\" self . way_points_queue . clear () while ( self . mission_planner . mission_plan ): # this actually clears the mission plan!! self . way_points_queue . append ( self . mission_planner . mission_plan . popleft ())","title":"set_mission_plan()"},{"location":"code_documentations/roar_autonomous_system/planning/mission_planners/","text":"__init__ ( self , vehicle ) special \u00a4 Source code in ROAR/roar_autonomous_system/planning_module/mission_planner/mission_planner.py 16 17 18 19 def __init__ ( self , vehicle : Vehicle ): super () . __init__ ( vehicle = vehicle ) self . logger = logging . getLogger ( __name__ ) self . mission_plan : deque = deque () run_step ( self , vehicle ) \u00a4 Abstract run step function for Mission Planner Parameters: Name Type Description Default vehicle Vehicle new vehicle state required Returns: Type Description List[ROAR.roar_autonomous_system.utilities_module.data_structures_models.Transform] Plan for next steps Source code in ROAR/roar_autonomous_system/planning_module/mission_planner/mission_planner.py 21 22 23 24 25 26 27 28 29 30 31 32 def run_step ( self , vehicle : Vehicle ) -> List [ Transform ]: \"\"\" Abstract run step function for Mission Planner Args: vehicle: new vehicle state Returns: Plan for next steps \"\"\" return [] A mission planner that takes in a file that contains x,y,z coordinates, formulate into carla.Transform __init__ ( self , vehicle , file_path ) special \u00a4 Source code in ROAR/roar_autonomous_system/planning_module/mission_planner/waypoint_following_mission_planner.py 39 40 41 42 43 44 def __init__ ( self , vehicle : Vehicle , file_path : Path ): super () . __init__ ( vehicle = vehicle ) self . logger = logging . getLogger ( __name__ ) self . file_path = file_path self . mission_plan = self . produce_mission_plan () self . logger . debug ( \"Path Following Mission Planner Initiated.\" ) produce_mission_plan ( self ) \u00a4 Generates a list of waypoints based on the input file path :return a list of waypoint Source code in ROAR/roar_autonomous_system/planning_module/mission_planner/waypoint_following_mission_planner.py 46 47 48 49 50 51 52 53 54 55 56 57 def produce_mission_plan ( self ) -> deque : \"\"\" Generates a list of waypoints based on the input file path :return a list of waypoint \"\"\" mission_plan = deque () raw_path : List [ List [ float ]] = self . _read_data_file () for coord in raw_path : if len ( coord ) == 3 or len ( coord ) == 6 : mission_plan . append ( self . _raw_coord_to_transform ( coord )) self . logger . debug ( f \"Computed Mission path of length { len ( mission_plan ) } \" ) return mission_plan run_step ( self , vehicle ) \u00a4 Regenerate waypoints from file Find the waypoint that is closest to the current vehicle location. return a mission plan starting from that waypoint Parameters: Name Type Description Default vehicle Vehicle current state of the vehicle required Returns: Type Description deque mission plan that start from the current vehicle location Source code in ROAR/roar_autonomous_system/planning_module/mission_planner/waypoint_following_mission_planner.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 def run_step ( self , vehicle : Vehicle ) -> deque : \"\"\" Regenerate waypoints from file Find the waypoint that is closest to the current vehicle location. return a mission plan starting from that waypoint Args: vehicle: current state of the vehicle Returns: mission plan that start from the current vehicle location \"\"\" super ( WaypointFollowingMissionPlanner , self ) . run_step ( vehicle = vehicle ) self . logger . debug ( \"TO BE IMPLEMENTED\" ) return self . produce_mission_plan ()","title":"Mission Planner"},{"location":"code_documentations/roar_autonomous_system/planning/mission_planners/#ROAR.roar_autonomous_system.planning_module.mission_planner.mission_planner.MissionPlanner.__init__","text":"Source code in ROAR/roar_autonomous_system/planning_module/mission_planner/mission_planner.py 16 17 18 19 def __init__ ( self , vehicle : Vehicle ): super () . __init__ ( vehicle = vehicle ) self . logger = logging . getLogger ( __name__ ) self . mission_plan : deque = deque ()","title":"__init__()"},{"location":"code_documentations/roar_autonomous_system/planning/mission_planners/#ROAR.roar_autonomous_system.planning_module.mission_planner.mission_planner.MissionPlanner.run_step","text":"Abstract run step function for Mission Planner Parameters: Name Type Description Default vehicle Vehicle new vehicle state required Returns: Type Description List[ROAR.roar_autonomous_system.utilities_module.data_structures_models.Transform] Plan for next steps Source code in ROAR/roar_autonomous_system/planning_module/mission_planner/mission_planner.py 21 22 23 24 25 26 27 28 29 30 31 32 def run_step ( self , vehicle : Vehicle ) -> List [ Transform ]: \"\"\" Abstract run step function for Mission Planner Args: vehicle: new vehicle state Returns: Plan for next steps \"\"\" return [] A mission planner that takes in a file that contains x,y,z coordinates, formulate into carla.Transform","title":"run_step()"},{"location":"code_documentations/roar_autonomous_system/planning/mission_planners/#ROAR.roar_autonomous_system.planning_module.mission_planner.waypoint_following_mission_planner.WaypointFollowingMissionPlanner.__init__","text":"Source code in ROAR/roar_autonomous_system/planning_module/mission_planner/waypoint_following_mission_planner.py 39 40 41 42 43 44 def __init__ ( self , vehicle : Vehicle , file_path : Path ): super () . __init__ ( vehicle = vehicle ) self . logger = logging . getLogger ( __name__ ) self . file_path = file_path self . mission_plan = self . produce_mission_plan () self . logger . debug ( \"Path Following Mission Planner Initiated.\" )","title":"__init__()"},{"location":"code_documentations/roar_autonomous_system/planning/mission_planners/#ROAR.roar_autonomous_system.planning_module.mission_planner.waypoint_following_mission_planner.WaypointFollowingMissionPlanner.produce_mission_plan","text":"Generates a list of waypoints based on the input file path :return a list of waypoint Source code in ROAR/roar_autonomous_system/planning_module/mission_planner/waypoint_following_mission_planner.py 46 47 48 49 50 51 52 53 54 55 56 57 def produce_mission_plan ( self ) -> deque : \"\"\" Generates a list of waypoints based on the input file path :return a list of waypoint \"\"\" mission_plan = deque () raw_path : List [ List [ float ]] = self . _read_data_file () for coord in raw_path : if len ( coord ) == 3 or len ( coord ) == 6 : mission_plan . append ( self . _raw_coord_to_transform ( coord )) self . logger . debug ( f \"Computed Mission path of length { len ( mission_plan ) } \" ) return mission_plan","title":"produce_mission_plan()"},{"location":"code_documentations/roar_autonomous_system/planning/mission_planners/#ROAR.roar_autonomous_system.planning_module.mission_planner.waypoint_following_mission_planner.WaypointFollowingMissionPlanner.run_step","text":"Regenerate waypoints from file Find the waypoint that is closest to the current vehicle location. return a mission plan starting from that waypoint Parameters: Name Type Description Default vehicle Vehicle current state of the vehicle required Returns: Type Description deque mission plan that start from the current vehicle location Source code in ROAR/roar_autonomous_system/planning_module/mission_planner/waypoint_following_mission_planner.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 def run_step ( self , vehicle : Vehicle ) -> deque : \"\"\" Regenerate waypoints from file Find the waypoint that is closest to the current vehicle location. return a mission plan starting from that waypoint Args: vehicle: current state of the vehicle Returns: mission plan that start from the current vehicle location \"\"\" super ( WaypointFollowingMissionPlanner , self ) . run_step ( vehicle = vehicle ) self . logger . debug ( \"TO BE IMPLEMENTED\" ) return self . produce_mission_plan ()","title":"run_step()"},{"location":"code_documentations/roar_autonomous_system/utilities/cameras/","text":"Camera pydantic-model \u00a4 data: ndarray pydantic-field \u00a4 fov: int pydantic-field \u00a4 image_size_x: int pydantic-field \u00a4 image_size_y: int pydantic-field \u00a4 intrinsics_matrix: ndarray pydantic-field \u00a4 transform: Transform pydantic-field \u00a4 __config__ \u00a4 Config \u00a4 __json_encoder__ ( obj ) special staticmethod \u00a4 calculate_intrinsic_matrix ( self ) \u00a4 Calculate intrinsics matrix Will set the attribute intrinsic matrix so that re-calculation is not necessary. https://github.com/carla-simulator/carla/issues/56 [ ax, 0, cx, 0, ay, cy, 0 , 0, 1 ] Returns: Type Description ndarray Intrinsics_matrix Source code in ROAR/roar_autonomous_system/utilities_module/camera_models.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def calculate_intrinsic_matrix ( self ) -> np . ndarray : \"\"\" Calculate intrinsics matrix Will set the attribute intrinsic matrix so that re-calculation is not necessary. https://github.com/carla-simulator/carla/issues/56 [ ax, 0, cx, 0, ay, cy, 0 , 0, 1 ] Returns: Intrinsics_matrix \"\"\" intrinsics_matrix = np . identity ( 3 ) intrinsics_matrix [ 0 , 2 ] = self . image_size_x / 2.0 intrinsics_matrix [ 1 , 2 ] = self . image_size_y / 2.0 intrinsics_matrix [ 0 , 0 ] = self . image_size_x / ( 2.0 * np . tan ( self . fov * np . pi / 360.0 ) ) intrinsics_matrix [ 1 , 1 ] = self . image_size_x / ( 2.0 * np . tan ( self . fov * np . pi / 360.0 ) ) self . intrinsics_matrix = intrinsics_matrix return intrinsics_matrix visualize ( self , title = 'CameraData' , duration = 1 ) \u00a4 Visualize camera data. Parameters: Name Type Description Default title title of cv2 image 'CameraData' duration in milisecond 1 Returns: Type Description None None Source code in ROAR/roar_autonomous_system/utilities_module/camera_models.py 56 57 58 59 60 61 62 63 64 65 66 67 68 def visualize ( self , title = \"CameraData\" , duration = 1 ) -> None : \"\"\" Visualize camera data. Args: title: title of cv2 image duration: in milisecond Returns: None \"\"\" if self . data is not None : cv2 . imshow ( title , self . data . data ) cv2 . waitKey ( duration )","title":"Camera"},{"location":"code_documentations/roar_autonomous_system/utilities/cameras/#ROAR.roar_autonomous_system.utilities_module.camera_models.Camera","text":"","title":"Camera"},{"location":"code_documentations/roar_autonomous_system/utilities/cameras/#ROAR.roar_autonomous_system.utilities_module.camera_models.Camera.data","text":"","title":"data"},{"location":"code_documentations/roar_autonomous_system/utilities/cameras/#ROAR.roar_autonomous_system.utilities_module.camera_models.Camera.fov","text":"","title":"fov"},{"location":"code_documentations/roar_autonomous_system/utilities/cameras/#ROAR.roar_autonomous_system.utilities_module.camera_models.Camera.image_size_x","text":"","title":"image_size_x"},{"location":"code_documentations/roar_autonomous_system/utilities/cameras/#ROAR.roar_autonomous_system.utilities_module.camera_models.Camera.image_size_y","text":"","title":"image_size_y"},{"location":"code_documentations/roar_autonomous_system/utilities/cameras/#ROAR.roar_autonomous_system.utilities_module.camera_models.Camera.intrinsics_matrix","text":"","title":"intrinsics_matrix"},{"location":"code_documentations/roar_autonomous_system/utilities/cameras/#ROAR.roar_autonomous_system.utilities_module.camera_models.Camera.transform","text":"","title":"transform"},{"location":"code_documentations/roar_autonomous_system/utilities/cameras/#ROAR.roar_autonomous_system.utilities_module.camera_models.Camera.__config__","text":"","title":"__config__"},{"location":"code_documentations/roar_autonomous_system/utilities/cameras/#ROAR.roar_autonomous_system.utilities_module.camera_models.Camera.Config","text":"","title":"Config"},{"location":"code_documentations/roar_autonomous_system/utilities/cameras/#ROAR.roar_autonomous_system.utilities_module.camera_models.Camera.__json_encoder__","text":"","title":"__json_encoder__()"},{"location":"code_documentations/roar_autonomous_system/utilities/cameras/#ROAR.roar_autonomous_system.utilities_module.camera_models.Camera.calculate_intrinsic_matrix","text":"Calculate intrinsics matrix Will set the attribute intrinsic matrix so that re-calculation is not necessary. https://github.com/carla-simulator/carla/issues/56 [ ax, 0, cx, 0, ay, cy, 0 , 0, 1 ] Returns: Type Description ndarray Intrinsics_matrix Source code in ROAR/roar_autonomous_system/utilities_module/camera_models.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def calculate_intrinsic_matrix ( self ) -> np . ndarray : \"\"\" Calculate intrinsics matrix Will set the attribute intrinsic matrix so that re-calculation is not necessary. https://github.com/carla-simulator/carla/issues/56 [ ax, 0, cx, 0, ay, cy, 0 , 0, 1 ] Returns: Intrinsics_matrix \"\"\" intrinsics_matrix = np . identity ( 3 ) intrinsics_matrix [ 0 , 2 ] = self . image_size_x / 2.0 intrinsics_matrix [ 1 , 2 ] = self . image_size_y / 2.0 intrinsics_matrix [ 0 , 0 ] = self . image_size_x / ( 2.0 * np . tan ( self . fov * np . pi / 360.0 ) ) intrinsics_matrix [ 1 , 1 ] = self . image_size_x / ( 2.0 * np . tan ( self . fov * np . pi / 360.0 ) ) self . intrinsics_matrix = intrinsics_matrix return intrinsics_matrix","title":"calculate_intrinsic_matrix()"},{"location":"code_documentations/roar_autonomous_system/utilities/cameras/#ROAR.roar_autonomous_system.utilities_module.camera_models.Camera.visualize","text":"Visualize camera data. Parameters: Name Type Description Default title title of cv2 image 'CameraData' duration in milisecond 1 Returns: Type Description None None Source code in ROAR/roar_autonomous_system/utilities_module/camera_models.py 56 57 58 59 60 61 62 63 64 65 66 67 68 def visualize ( self , title = \"CameraData\" , duration = 1 ) -> None : \"\"\" Visualize camera data. Args: title: title of cv2 image duration: in milisecond Returns: None \"\"\" if self . data is not None : cv2 . imshow ( title , self . data . data ) cv2 . waitKey ( duration )","title":"visualize()"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/","text":"DepthData pydantic-model \u00a4 data: ndarray pydantic-field required \u00a4 Array of size (WIDTH, HEIGHT, 3) __config__ \u00a4 Config \u00a4 __json_encoder__ ( obj ) special staticmethod \u00a4 IMUData pydantic-model \u00a4 accelerometer: Vector3D pydantic-field \u00a4 Linear acceleration in m/s^2 gyroscope: Vector3D pydantic-field \u00a4 Angular velocity in rad/sec __config__ \u00a4 __json_encoder__ ( obj ) special staticmethod \u00a4 Location pydantic-model \u00a4 x: float pydantic-field required \u00a4 Distance in meters from origin to spot on X axis y: float pydantic-field required \u00a4 Distance in meters from origin to spot on Y axis z: float pydantic-field required \u00a4 Distance in meters from origin to spot on Z axis __config__ \u00a4 __add__ ( self , other ) special \u00a4 Source code in ROAR/roar_autonomous_system/utilities_module/data_structures_models.py 31 32 33 def __add__ ( self , other ): \"\"\"\"\"\" return Location ( x = self . x + other . x , y = self . y + other . y , z = self . z + other . z ) __json_encoder__ ( obj ) special staticmethod \u00a4 __str__ ( self ) special \u00a4 Return str(self). Source code in ROAR/roar_autonomous_system/utilities_module/data_structures_models.py 35 36 def __str__ ( self ): return f \" { self . x : .3 } , { self . y : .3 } , { self . z : .3 } \" distance ( self , other_location ) \u00a4 Euclidean distance between current location and other location Source code in ROAR/roar_autonomous_system/utilities_module/data_structures_models.py 24 25 26 27 28 29 def distance ( self , other_location ): \"\"\"Euclidean distance between current location and other location\"\"\" return distance . euclidean ( ( self . x , self . y , self . z ), ( other_location . x , other_location . y , other_location . z ), ) to_array ( self ) \u00a4 Source code in ROAR/roar_autonomous_system/utilities_module/data_structures_models.py 38 39 def to_array ( self ) -> np . array : return np . array ([ self . x , self . y , self . z ]) RGBData pydantic-model \u00a4 data: ndarray pydantic-field required \u00a4 Array of size (WIDTH, HEIGHT, 3) __config__ \u00a4 Config \u00a4 __json_encoder__ ( obj ) special staticmethod \u00a4 Rotation pydantic-model \u00a4 pitch: float pydantic-field required \u00a4 Degree around the Y-axis roll: float pydantic-field required \u00a4 Degree around the X-axis yaw: float pydantic-field required \u00a4 Degree around the Z-axis __config__ \u00a4 __json_encoder__ ( obj ) special staticmethod \u00a4 __str__ ( self ) special \u00a4 Return str(self). Source code in ROAR/roar_autonomous_system/utilities_module/data_structures_models.py 47 48 def __str__ ( self ): return f \" { self . pitch } , { self . yaw } , { self . roll } \" to_array ( self ) \u00a4 Source code in ROAR/roar_autonomous_system/utilities_module/data_structures_models.py 50 51 def to_array ( self ) -> np . array : return np . array ([ self . pitch , self . yaw , self . roll ]) SensorsData pydantic-model \u00a4 front_depth: DepthData pydantic-field \u00a4 front_rgb: RGBData pydantic-field \u00a4 imu_data: IMUData pydantic-field \u00a4 rear_rgb: RGBData pydantic-field \u00a4 __config__ \u00a4 __json_encoder__ ( obj ) special staticmethod \u00a4 Transform pydantic-model \u00a4 location: Location pydantic-field \u00a4 rotation: Rotation pydantic-field \u00a4 __config__ \u00a4 __json_encoder__ ( obj ) special staticmethod \u00a4 __str__ ( self ) special \u00a4 Return str(self). Source code in ROAR/roar_autonomous_system/utilities_module/data_structures_models.py 91 92 93 def __str__ ( self ): return f \" { self . location . x } , { self . location . y } , { self . location . z } ,\" \\ f \" { self . rotation . pitch } , { self . rotation . yaw } , { self . rotation . roll } \" get_matrix ( self ) \u00a4 Calculate extrinsics matrix with respect to parent object http://planning.cs.uiuc.edu/node104.html Returns: Type Description ndarray Extrinsics matrix Source code in ROAR/roar_autonomous_system/utilities_module/data_structures_models.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def get_matrix ( self ) -> np . ndarray : \"\"\" Calculate extrinsics matrix with respect to parent object http://planning.cs.uiuc.edu/node104.html Returns: Extrinsics matrix \"\"\" location = self . location rotation = self . rotation yaw , pitch , roll = rotation . yaw , rotation . pitch , rotation . roll c_y = np . cos ( np . radians ( yaw )) s_y = np . sin ( np . radians ( yaw )) c_r = np . cos ( np . radians ( roll )) s_r = np . sin ( np . radians ( roll )) c_p = np . cos ( np . radians ( pitch )) s_p = np . sin ( np . radians ( pitch )) matrix = np . identity ( 4 ) matrix [ 0 , 3 ] = location . x matrix [ 1 , 3 ] = location . y matrix [ 2 , 3 ] = location . z matrix [ 0 , 0 ] = c_p * c_y matrix [ 0 , 1 ] = c_y * s_p * s_r - s_y * c_r matrix [ 0 , 2 ] = - c_y * s_p * c_r - s_y * s_r matrix [ 1 , 0 ] = s_y * c_p matrix [ 1 , 1 ] = s_y * s_p * s_r + c_y * c_r matrix [ 1 , 2 ] = - s_y * s_p * c_r + c_y * s_r matrix [ 2 , 0 ] = s_p matrix [ 2 , 1 ] = - c_p * s_r matrix [ 2 , 2 ] = c_p * c_r return matrix Vector3D pydantic-model \u00a4 x: float pydantic-field \u00a4 y: float pydantic-field \u00a4 z: float pydantic-field \u00a4 __config__ \u00a4 __json_encoder__ ( obj ) special staticmethod \u00a4","title":"Data Structures"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.DepthData","text":"","title":"DepthData"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.DepthData.data","text":"Array of size (WIDTH, HEIGHT, 3)","title":"data"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.DepthData.__config__","text":"","title":"__config__"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.DepthData.Config","text":"","title":"Config"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.DepthData.__json_encoder__","text":"","title":"__json_encoder__()"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.IMUData","text":"","title":"IMUData"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.IMUData.accelerometer","text":"Linear acceleration in m/s^2","title":"accelerometer"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.IMUData.gyroscope","text":"Angular velocity in rad/sec","title":"gyroscope"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.IMUData.__config__","text":"","title":"__config__"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.IMUData.__json_encoder__","text":"","title":"__json_encoder__()"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Location","text":"","title":"Location"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Location.x","text":"Distance in meters from origin to spot on X axis","title":"x"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Location.y","text":"Distance in meters from origin to spot on Y axis","title":"y"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Location.z","text":"Distance in meters from origin to spot on Z axis","title":"z"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Location.__config__","text":"","title":"__config__"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Location.__add__","text":"Source code in ROAR/roar_autonomous_system/utilities_module/data_structures_models.py 31 32 33 def __add__ ( self , other ): \"\"\"\"\"\" return Location ( x = self . x + other . x , y = self . y + other . y , z = self . z + other . z )","title":"__add__()"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Location.__json_encoder__","text":"","title":"__json_encoder__()"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Location.__str__","text":"Return str(self). Source code in ROAR/roar_autonomous_system/utilities_module/data_structures_models.py 35 36 def __str__ ( self ): return f \" { self . x : .3 } , { self . y : .3 } , { self . z : .3 } \"","title":"__str__()"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Location.distance","text":"Euclidean distance between current location and other location Source code in ROAR/roar_autonomous_system/utilities_module/data_structures_models.py 24 25 26 27 28 29 def distance ( self , other_location ): \"\"\"Euclidean distance between current location and other location\"\"\" return distance . euclidean ( ( self . x , self . y , self . z ), ( other_location . x , other_location . y , other_location . z ), )","title":"distance()"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Location.to_array","text":"Source code in ROAR/roar_autonomous_system/utilities_module/data_structures_models.py 38 39 def to_array ( self ) -> np . array : return np . array ([ self . x , self . y , self . z ])","title":"to_array()"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.RGBData","text":"","title":"RGBData"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.RGBData.data","text":"Array of size (WIDTH, HEIGHT, 3)","title":"data"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.RGBData.__config__","text":"","title":"__config__"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.RGBData.Config","text":"","title":"Config"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.RGBData.__json_encoder__","text":"","title":"__json_encoder__()"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Rotation","text":"","title":"Rotation"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Rotation.pitch","text":"Degree around the Y-axis","title":"pitch"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Rotation.roll","text":"Degree around the X-axis","title":"roll"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Rotation.yaw","text":"Degree around the Z-axis","title":"yaw"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Rotation.__config__","text":"","title":"__config__"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Rotation.__json_encoder__","text":"","title":"__json_encoder__()"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Rotation.__str__","text":"Return str(self). Source code in ROAR/roar_autonomous_system/utilities_module/data_structures_models.py 47 48 def __str__ ( self ): return f \" { self . pitch } , { self . yaw } , { self . roll } \"","title":"__str__()"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Rotation.to_array","text":"Source code in ROAR/roar_autonomous_system/utilities_module/data_structures_models.py 50 51 def to_array ( self ) -> np . array : return np . array ([ self . pitch , self . yaw , self . roll ])","title":"to_array()"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.SensorsData","text":"","title":"SensorsData"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.SensorsData.front_depth","text":"","title":"front_depth"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.SensorsData.front_rgb","text":"","title":"front_rgb"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.SensorsData.imu_data","text":"","title":"imu_data"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.SensorsData.rear_rgb","text":"","title":"rear_rgb"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.SensorsData.__config__","text":"","title":"__config__"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.SensorsData.__json_encoder__","text":"","title":"__json_encoder__()"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Transform","text":"","title":"Transform"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Transform.location","text":"","title":"location"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Transform.rotation","text":"","title":"rotation"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Transform.__config__","text":"","title":"__config__"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Transform.__json_encoder__","text":"","title":"__json_encoder__()"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Transform.__str__","text":"Return str(self). Source code in ROAR/roar_autonomous_system/utilities_module/data_structures_models.py 91 92 93 def __str__ ( self ): return f \" { self . location . x } , { self . location . y } , { self . location . z } ,\" \\ f \" { self . rotation . pitch } , { self . rotation . yaw } , { self . rotation . roll } \"","title":"__str__()"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Transform.get_matrix","text":"Calculate extrinsics matrix with respect to parent object http://planning.cs.uiuc.edu/node104.html Returns: Type Description ndarray Extrinsics matrix Source code in ROAR/roar_autonomous_system/utilities_module/data_structures_models.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def get_matrix ( self ) -> np . ndarray : \"\"\" Calculate extrinsics matrix with respect to parent object http://planning.cs.uiuc.edu/node104.html Returns: Extrinsics matrix \"\"\" location = self . location rotation = self . rotation yaw , pitch , roll = rotation . yaw , rotation . pitch , rotation . roll c_y = np . cos ( np . radians ( yaw )) s_y = np . sin ( np . radians ( yaw )) c_r = np . cos ( np . radians ( roll )) s_r = np . sin ( np . radians ( roll )) c_p = np . cos ( np . radians ( pitch )) s_p = np . sin ( np . radians ( pitch )) matrix = np . identity ( 4 ) matrix [ 0 , 3 ] = location . x matrix [ 1 , 3 ] = location . y matrix [ 2 , 3 ] = location . z matrix [ 0 , 0 ] = c_p * c_y matrix [ 0 , 1 ] = c_y * s_p * s_r - s_y * c_r matrix [ 0 , 2 ] = - c_y * s_p * c_r - s_y * s_r matrix [ 1 , 0 ] = s_y * c_p matrix [ 1 , 1 ] = s_y * s_p * s_r + c_y * c_r matrix [ 1 , 2 ] = - s_y * s_p * c_r + c_y * s_r matrix [ 2 , 0 ] = s_p matrix [ 2 , 1 ] = - c_p * s_r matrix [ 2 , 2 ] = c_p * c_r return matrix","title":"get_matrix()"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Vector3D","text":"","title":"Vector3D"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Vector3D.x","text":"","title":"x"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Vector3D.y","text":"","title":"y"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Vector3D.z","text":"","title":"z"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Vector3D.__config__","text":"","title":"__config__"},{"location":"code_documentations/roar_autonomous_system/utilities/data_structures/#ROAR.roar_autonomous_system.utilities_module.data_structures_models.Vector3D.__json_encoder__","text":"","title":"__json_encoder__()"},{"location":"code_documentations/roar_autonomous_system/utilities/vehicles/","text":"Vehicle pydantic-model \u00a4 Encodes the Vehicle's state at the last tick control: VehicleControl pydantic-field \u00a4 transform: Transform pydantic-field \u00a4 velocity: Vector3D pydantic-field \u00a4 wheel_base: float pydantic-field \u00a4 Default to tesla model 3's wheel base __config__ \u00a4 __json_encoder__ ( obj ) special staticmethod \u00a4 get_speed ( vehicle ) staticmethod \u00a4 Compute speed of a vehicle in Km/h. :param vehicle: the vehicle for which speed is calculated :return: speed as a float in Km/h Source code in ROAR/roar_autonomous_system/utilities_module/vehicle_models.py 43 44 45 46 47 48 49 50 51 52 @staticmethod def get_speed ( vehicle ): \"\"\" Compute speed of a vehicle in Km/h. :param vehicle: the vehicle for which speed is calculated :return: speed as a float in Km/h \"\"\" vel = vehicle . velocity return 3.6 * math . sqrt ( vel . x ** 2 + vel . y ** 2 + vel . z ** 2 ) VehicleControl pydantic-model \u00a4 steering: float pydantic-field \u00a4 throttle: float pydantic-field \u00a4 __config__ \u00a4 __json_encoder__ ( obj ) special staticmethod \u00a4 clamp ( n , minn , maxn ) staticmethod \u00a4 Source code in ROAR/roar_autonomous_system/utilities_module/vehicle_models.py 14 15 16 @staticmethod def clamp ( n , minn , maxn ): return max ( min ( maxn , n ), minn ) get_steering ( self ) \u00a4 Source code in ROAR/roar_autonomous_system/utilities_module/vehicle_models.py 25 26 def get_steering ( self ) -> float : return self . clamp ( self . steering , - 1 , 1 ) get_throttle ( self ) \u00a4 Cap it between -1 and 1 :return: Source code in ROAR/roar_autonomous_system/utilities_module/vehicle_models.py 18 19 20 21 22 23 def get_throttle ( self ) -> float : \"\"\" Cap it between -1 and 1 :return: \"\"\" return self . clamp ( self . throttle , - 1 , 1 )","title":"Vehicle"},{"location":"code_documentations/roar_autonomous_system/utilities/vehicles/#ROAR.roar_autonomous_system.utilities_module.vehicle_models.Vehicle","text":"Encodes the Vehicle's state at the last tick","title":"Vehicle"},{"location":"code_documentations/roar_autonomous_system/utilities/vehicles/#ROAR.roar_autonomous_system.utilities_module.vehicle_models.Vehicle.control","text":"","title":"control"},{"location":"code_documentations/roar_autonomous_system/utilities/vehicles/#ROAR.roar_autonomous_system.utilities_module.vehicle_models.Vehicle.transform","text":"","title":"transform"},{"location":"code_documentations/roar_autonomous_system/utilities/vehicles/#ROAR.roar_autonomous_system.utilities_module.vehicle_models.Vehicle.velocity","text":"","title":"velocity"},{"location":"code_documentations/roar_autonomous_system/utilities/vehicles/#ROAR.roar_autonomous_system.utilities_module.vehicle_models.Vehicle.wheel_base","text":"Default to tesla model 3's wheel base","title":"wheel_base"},{"location":"code_documentations/roar_autonomous_system/utilities/vehicles/#ROAR.roar_autonomous_system.utilities_module.vehicle_models.Vehicle.__config__","text":"","title":"__config__"},{"location":"code_documentations/roar_autonomous_system/utilities/vehicles/#ROAR.roar_autonomous_system.utilities_module.vehicle_models.Vehicle.__json_encoder__","text":"","title":"__json_encoder__()"},{"location":"code_documentations/roar_autonomous_system/utilities/vehicles/#ROAR.roar_autonomous_system.utilities_module.vehicle_models.Vehicle.get_speed","text":"Compute speed of a vehicle in Km/h. :param vehicle: the vehicle for which speed is calculated :return: speed as a float in Km/h Source code in ROAR/roar_autonomous_system/utilities_module/vehicle_models.py 43 44 45 46 47 48 49 50 51 52 @staticmethod def get_speed ( vehicle ): \"\"\" Compute speed of a vehicle in Km/h. :param vehicle: the vehicle for which speed is calculated :return: speed as a float in Km/h \"\"\" vel = vehicle . velocity return 3.6 * math . sqrt ( vel . x ** 2 + vel . y ** 2 + vel . z ** 2 )","title":"get_speed()"},{"location":"code_documentations/roar_autonomous_system/utilities/vehicles/#ROAR.roar_autonomous_system.utilities_module.vehicle_models.VehicleControl","text":"","title":"VehicleControl"},{"location":"code_documentations/roar_autonomous_system/utilities/vehicles/#ROAR.roar_autonomous_system.utilities_module.vehicle_models.VehicleControl.steering","text":"","title":"steering"},{"location":"code_documentations/roar_autonomous_system/utilities/vehicles/#ROAR.roar_autonomous_system.utilities_module.vehicle_models.VehicleControl.throttle","text":"","title":"throttle"},{"location":"code_documentations/roar_autonomous_system/utilities/vehicles/#ROAR.roar_autonomous_system.utilities_module.vehicle_models.VehicleControl.__config__","text":"","title":"__config__"},{"location":"code_documentations/roar_autonomous_system/utilities/vehicles/#ROAR.roar_autonomous_system.utilities_module.vehicle_models.VehicleControl.__json_encoder__","text":"","title":"__json_encoder__()"},{"location":"code_documentations/roar_autonomous_system/utilities/vehicles/#ROAR.roar_autonomous_system.utilities_module.vehicle_models.VehicleControl.clamp","text":"Source code in ROAR/roar_autonomous_system/utilities_module/vehicle_models.py 14 15 16 @staticmethod def clamp ( n , minn , maxn ): return max ( min ( maxn , n ), minn )","title":"clamp()"},{"location":"code_documentations/roar_autonomous_system/utilities/vehicles/#ROAR.roar_autonomous_system.utilities_module.vehicle_models.VehicleControl.get_steering","text":"Source code in ROAR/roar_autonomous_system/utilities_module/vehicle_models.py 25 26 def get_steering ( self ) -> float : return self . clamp ( self . steering , - 1 , 1 )","title":"get_steering()"},{"location":"code_documentations/roar_autonomous_system/utilities/vehicles/#ROAR.roar_autonomous_system.utilities_module.vehicle_models.VehicleControl.get_throttle","text":"Cap it between -1 and 1 :return: Source code in ROAR/roar_autonomous_system/utilities_module/vehicle_models.py 18 19 20 21 22 23 def get_throttle ( self ) -> float : \"\"\" Cap it between -1 and 1 :return: \"\"\" return self . clamp ( self . throttle , - 1 , 1 )","title":"get_throttle()"},{"location":"project_overview/code_layout/","text":"ROAR bridges - Sync data between different sources and Agent carla_client - Custimized Module responsible for initializing and communicating with the Carla Server roar_autonomous_system agent_module - Declaration and implementation of different Agents control_module - Declaration and implementation of different Controllers perception_module - Declaration and implementation of different Detectors planning_module - Declaration and implementation of different Planning algorithms utilities_module - Declaration of useful data structures visualization_module - Centralized Visualization functions readme.md requirements.txt runner.py","title":"Code Layout"},{"location":"project_overview/project_module_TADs/","text":"ROAR Carla Overall Architecture \u00a4 Environment Maps \u00a4 Environmental Perception \u00a4 Motion Planning \u00a4 Vehicle Controller \u00a4","title":"Project Module TAD"},{"location":"project_overview/project_module_TADs/#roar-carla-overall-architecture","text":"","title":"ROAR Carla Overall Architecture"},{"location":"project_overview/project_module_TADs/#environment-maps","text":"","title":"Environment Maps"},{"location":"project_overview/project_module_TADs/#environmental-perception","text":"","title":"Environmental Perception"},{"location":"project_overview/project_module_TADs/#motion-planning","text":"","title":"Motion Planning"},{"location":"project_overview/project_module_TADs/#vehicle-controller","text":"","title":"Vehicle Controller"}]}